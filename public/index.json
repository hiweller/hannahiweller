[{"authors":null,"categories":null,"content":"I want to know how to interpret organisms in the light of their evolutionary history. We often assume every trait on an organism has been \u0026ldquo;optimized\u0026rdquo; under natural selection, but this is almost never true: evolution wanders.\nI find it helpful to think about every living thing as being like a very, very old house. Some of the parts are there because they\u0026rsquo;ve always been useful (walls), and some of the parts are new additions for new functions (solar panels); but a lot of parts are there because it was easier to modify what existed than it was to build something from scratch, especially if the house needs to be habitable the whole time (and the available changes are random). And, like houses, I think we can learn a lot about organisms by understanding them as the outcomes of their history.\n  View my CV.\n  See what I\u0026rsquo;m up to lately.\n  Get in touch!\n","date":1620345600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1620396986,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/hannah-weller/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/hannah-weller/","section":"authors","summary":"I want to know how to interpret organisms in the light of their evolutionary history. We often assume every trait on an organism has been \u0026ldquo;optimized\u0026rdquo; under natural selection, but this is almost never true: evolution wanders.","tags":null,"title":"Hannah Weller","type":"authors"},{"authors":null,"categories":null,"content":"   Table of Contents  What you will learn Program overview Courses in this program Meet your instructor FAQs    What you will learn  Fundamental Python programming skills Statistical concepts and how to apply them in practice Gain experience with the Scikit, including data visualization with Plotly and data wrangling with Pandas  Program overview The demand for skilled data science practitioners is rapidly growing. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi.\nCourses in this program  Python basics Build a foundation in Python.   Visualization Learn how to visualize data with Plotly.   Statistics Introduction to statistics for data science.   Meet your instructor Hannah Weller FAQs Are there prerequisites? There are no prerequisites for the first course.\n How often do the courses run? Continuously, at your own pace.\n  Begin the course   ","date":1611446400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611446400,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"An example of using Wowchemy's Book layout for publishing online courses.","tags":null,"title":"📊 Learn Data Science","type":"book"},{"authors":null,"categories":null,"content":"Build a foundation in Python.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz What is the difference between lists and tuples? Lists\n Lists are mutable - they can be changed Slower than tuples Syntax: a_list = [1, 2.0, 'Hello world']  Tuples\n Tuples are immutable - they can\u0026rsquo;t be changed Tuples are faster than lists Syntax: a_tuple = (1, 2.0, 'Hello world')   Is Python case-sensitive? Yes\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"17a31b92253d299002593b7491eedeea","permalink":"/courses/example/python/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/python/","section":"courses","summary":"Build a foundation in Python.\n","tags":null,"title":"Python basics","type":"book"},{"authors":null,"categories":null,"content":"Learn how to visualize data with Plotly.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz When is a heatmap useful? Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n Write Plotly code to render a bar chart import plotly.express as px data_canada = px.data.gapminder().query(\u0026quot;country == 'Canada'\u0026quot;) fig = px.bar(data_canada, x='year', y='pop') fig.show()  ","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"1b341b3479c8c6b1f807553b77e21b7c","permalink":"/courses/example/visualization/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/visualization/","section":"courses","summary":"Learn how to visualize data with Plotly.\n","tags":null,"title":"Visualization","type":"book"},{"authors":null,"categories":null,"content":"Introduction to statistics for data science.\n  1-2 hours per week, for 8 weeks\nLearn The general form of the normal probability density function is:\n$$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi} } e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2} $$\n The parameter $\\mu$ is the mean or expectation of the distribution. $\\sigma$ is its standard deviation. The variance of the distribution is $\\sigma^{2}$.   Quiz What is the parameter $\\mu$? The parameter $\\mu$ is the mean or expectation of the distribution.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"6f4078728d71b1b791d39f218bf2bdb1","permalink":"/courses/example/stats/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/stats/","section":"courses","summary":"Introduction to statistics for data science.\n","tags":null,"title":"Statistics","type":"book"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Hannah Weller","Steven Van Belleghem"],"categories":["recolorize"],"content":"This tutorial will go through the process of combining patternize and recolorize tools to produce a PCA quantifying color pattern variation in wasp faces (Polistes fuscatus). This subset of 20 images (and workflow) is excerpted from \u0026lsquo;Evidence for a selective link between cooperation and individual recognition\u0026rsquo; (Tumulty et al. 2021), with permission from the lead author. (Thanks James!)\nThe patternize package is an excellent tool for quantifying variation in color patterns. I use it frequently, because it\u0026rsquo;s a consistent, scaleable method for quantification that works for almost any organism, and it allows you to control for variation in shape, orientation, and size by first aligning all of your color patterns to a RasterStack—analogous to the Procrustes fit step of geometric morphometrics. It also helps that the package author, Steven Van Belleghem, is extremely friendly!\nIn practice, the most difficult step of using patternize is often the color segmentation: like several other color analysis packages and tools, patternize frequently relies on k-means clustering to extract color patches from images (especially for batch processing). That\u0026rsquo;s where recolorize comes in. In order to use recolorize to do the segmentation step for patternize, we have to follow three steps:\n Align original images as RasterStacks using alignLan() in patternize Segment the list of aligned images using recolorize Convert list of segmented images back into the patternize format  Let\u0026rsquo;s do it!\nExample files All the data and code used in this tutorial can be found here: https://github.com/hiweller/recolorize_examples/tree/main/wasps\nStep 1: Image alignment in patternize Note: Make sure you have installed the development version of patternize (e.g. by running devtools::install_github(\u0026quot;StevenVB12/patternize\u0026quot;)).\nWe\u0026rsquo;re starting with a folder of unaltered images of wasp faces. These images have been color-corrected and cropped to the wasp\u0026rsquo;s face, but the background hasn\u0026rsquo;t been masked out, since patternize will do that when we do the alignment.\nNote that even on this dataset—which is highly standardized—the images have slight variations in the size, shape, and angle of the head, making it difficult to differentiate variation due to color pattern differences from that due to other factors.\nTo use the alignLan() function, we need to provide XY coordinates of landmarks (one set per image). I did these in ImageJ using the multi-point tool, but really you just need a two-column, tab-delimited text file with X coordinates on the left and Y coordinates on the right, and no header. Our landmarking scheme for the wasp faces only had 8 points: So, I opened up each image in ImageJ, selected those landmarks using the multi-point tool, then saved those pixel coordinates as a plain text file with the same suffix. For example, the pixel coordinates for polistes_01.jpg is called polites_01_landmarks.txt (you can see it here).\nI also made a mask for the images using the polygon selection tool in ImageJ, which will allow us to do the batch background masking. In this case, we only want to retain the frons and clypeus of the head (masking out the eyes and antennae openings), so I outlined them in a representative image (polistes_05) and saved those as XY coordinates as well (here). Because we\u0026rsquo;re aligning using landmarks, we only need to make one outline which will be applied to all images in the dataset—much faster than masking each image manually!\nOnce you have all those files (original images, XY landmark coordinates, and masking outline coordinates), we can combine them using patternize. I organized my files into separate folders (images in the original_images/ folder, landmark text files in the landmarks folder, etc), but you don\u0026rsquo;t have to do that so long as your files are organized and named in a way that works with the makeList() function.\n# load library library(patternize) ### Align set of 20 images ### # set of specimen IDs IDlist \u0026lt;- tools::file_path_sans_ext(dir(\u0026quot;original_images/\u0026quot;, \u0026quot;.jpg\u0026quot;)) # make list with images imageList \u0026lt;- makeList(IDlist, type = \u0026quot;image\u0026quot;, prepath = \u0026quot;original_images/\u0026quot;, extension = \u0026quot;.jpg\u0026quot;) # make list with landmarks landmarkList \u0026lt;- makeList(IDlist, type = \u0026quot;landmark\u0026quot;, prepath = \u0026quot;landmarks/\u0026quot;, extension = \u0026quot;_landmarks.txt\u0026quot;) # Set target as polistes 05 target \u0026lt;- landmarkList[['polistes_05']] # Set up mask, which excludes eyes/mandibles and antenna holes mask1 \u0026lt;- read.table(\u0026quot;masks/polistes_05_mask.txt\u0026quot;, header = FALSE) mask2 \u0026lt;- read.table(\u0026quot;masks/polistes_05_Lantenna.txt\u0026quot;, header = FALSE) mask3 \u0026lt;- read.table(\u0026quot;masks/polistes_05_Rantenna.txt\u0026quot;, header = FALSE) ### Alignment ### # this takes ~1 minute on a 16Gb RAM laptop running Ubuntu imageList_aligned \u0026lt;- alignLan(imageList, landmarkList, transformRef = target, adjustCoords = TRUE, plotTransformed = T, resampleFactor = 5, cartoonID = 'polistes_05', maskOutline = list(mask1, mask2, mask3), inverse = list(FALSE, TRUE, TRUE))  The resulting imageList_aligned object is a list of aligned RasterBrick objects, one per image, with everything but the region of interest (frons and clypeus) removed.\nTip: I usually save this list as an .RDS file so I can load it back in at my convenience without having to do the alignment step again:\n# save RDS file saveRDS(imageList_aligned, \u0026quot;rds_files/imageList_aligned.rds\u0026quot;) # read it in: imageList_aligned \u0026lt;- readRDS(\u0026quot;rds_files/imageList_aligned.rds\u0026quot;)  Step 2: Segment images in recolorize The wonky step in this workflow is that patternize works with raster images, and recolorize works with arrays, so we have to convert from raster objects to arrays before using recolorize. The brick_to_array() function makes that fairly straightforward:\n# load library library(recolorize) # convert from RasterBricks to image arrays using the brick_to_array function: imgs \u0026lt;- lapply(imageList_aligned, brick_to_array) names(imgs) \u0026lt;- names(imageList_aligned) # save raster extents for later conversion: extent_list \u0026lt;- lapply(imageList_aligned, extent)  Now we have a list of image arrays. Plotting them using plotImageArray() helps us to see what the alignLan() step did for our original images:\n(Note that it also flipped the images upside because the y coordinate systems are reversed–this is annoying, but doesn\u0026rsquo;t affect our results, so we\u0026rsquo;ll leave it for now.)\nWe want to map each of these wasp faces to the same set of three colors: dark brown, reddish brown, and yellow. K-means clustering could work in theory for this problem (we would fit n = 3 colors for each image), but in practice, we get the colors back in a random order—and they\u0026rsquo;re not actually the same color. Here\u0026rsquo;s what it looks like if we try to do that:\nfor (i in 1:length(imgs)) { rc \u0026lt;- recolorize(imgs[i], method = \u0026quot;k\u0026quot;, n = 3, plotting = FALSE) plotColorPalette(rc$centers) }  These colors are definitely similar across images, but they\u0026rsquo;re not consistent, especially since not all wasps have all three colors present. Maybe most intractably, they\u0026rsquo;re not in the same order: yellow is color 1, 2, or 3 depending on the image, and sometimes it\u0026rsquo;s not there at all.\nInstead, we\u0026rsquo;ll come up with our list of 3 colors by combining color palettes across images, and then use the imposeColors() function in recolorize to map each of our images to the same color palette. First, generate a color palette for each image:\n# make an empty list for storing the recolorize objects rc_list \u0026lt;- vector(\u0026quot;list\u0026quot;, length(imgs)) names(rc_list) \u0026lt;- names(imgs) # for every image, run the same recolorize2 function to fit a recolorize object: for (i in 1:length(imgs)) { rc_list[[i]] \u0026lt;- recolorize2(imgs[[i]], bins = 3, cutoff = 35, plotting = FALSE) }  I kept it pretty simple for this example (we\u0026rsquo;re just calling recolorize2() with the same parameters for each image), but you could get more complicated with what you put in the for loop. (You could even choose to use k-means clustering as the method here by setting method = \u0026quot;k\u0026quot; and specifying the number of colors, since we\u0026rsquo;re just using it as a starting point, but since k-means is not deterministic that poses problems for repeatability.)\nNext you can combine the color palettes from all of the recolorize objects in rc_list and use hclust_color to plot them and return a list of which colors to group together:\n# get a dataframe of all colors: all_palettes \u0026lt;- do.call(rbind, lapply(rc_list, function(i) i$centers)) # and for cluster sizes (as a proportion of their original image): all_sizes \u0026lt;- do.call(c, lapply(rc_list, function(i) i$sizes)) # plot colors using hclust and return grouping list: par(mar = rep(2, 4)) cluster_list \u0026lt;- hclust_color(all_palettes, n_final = 3)  The cluster_list object is a list, each element of which is a vector of which of the original colors should be clustered together. See the rest of the hclust_color() options to various ways to combine colors by similarity—by default, it calculates the Euclidean distance matrix between all provided color centers in CIE Lab color space. We can use that list to combine all the colors and come up with our universal palette:\n# make an empty matrix for storing the new palette wasp_palette \u0026lt;- matrix(NA, ncol = 3, nrow = length(cluster_list)) # for every color in cluster_list... for (i in 1:length(cluster_list)) { # get the center indices idx \u0026lt;- cluster_list[[i]] # get the average value for each channel, using cluster size to get a weighted average ctr \u0026lt;- apply(all_palettes, 2, function(j) weighted.mean(j[idx], w = all_sizes[idx])) # store in the palette matrix wasp_palette[i, ] \u0026lt;- ctr } # check that our colors seem reasonable par(mar = rep(0, 4)) plotColorPalette(wasp_palette)  And now, we can use imposeColors() to map every image to the same set of three colors:\nimpose_list \u0026lt;- lapply(imgs, function(i) imposeColors(i, wasp_palette, adjust_centers = FALSE, plotting = FALSE)) # let's look at our palettes! layout(matrix(1:20, nrow = 4)) par(mar = rep(0, 4)) for (i in impose_list) { plotColorPalette(i$centers, i$sizes) }  Although the proportions of each color vary by image, the order/value of the colors does not (unlike with k-means). This is the key step. As long as you can provide a color palette to which all of your images should be mapped, you can use imposeColors() to map every image to those colors. The earlier portion where we did an initial fit and used hclust_color is a good option when you want to come up with a color palette intrinsic to your original images, but it may still take some toying around before you find a palette that works.\nThe last step is to convert each recolorize fit in back to a patternize format, which we can do with the recolorize_to_patternize() function:\n# convert to patternize: patternize_list \u0026lt;- lapply(impose_list, recolorize_to_patternize) # and set extents again: for (i in 1:length(patternize_list)) { for (j in 1:length(patternize_list[[1]])) { raster::extent(patternize_list[[i]][[j]]) \u0026lt;- extent_list[[i]] } }  This is a list of lists: there is one element per sample ID in patternize_list (20 total), and each of those elements is a list of RasterLayer objects, one per color class (3 per sample ID). You may need to reshuffle these depending on what you want to do.\nNow, back to patternize!\nStep 3: Color pattern analyses in patternize Since we now have the images segmented in the way that patternize needs, we can run any of the regular patternize functions on it (see the methods paper and examples repository). Here, we\u0026rsquo;ll use a custom function based on code that Steven sent me for running a PCA on the entire color pattern (all three colors simultaneously, rather than one color class at a time). You can see the full function here. If you\u0026rsquo;ve downloaded the wasp example dataset, the easiest thing to do is to just source it and run the function on the list we made earlier:\nsource(\u0026quot;patPCA_total.R\u0026quot;) wasp_pca \u0026lt;- patPCA_total(patternize_list, quietly = FALSE)  ## Summing raster lists...  ## Making dataframe from rasters...  ## Running PCA on 3 colors and 20 images...  ## done  That\u0026rsquo;s it! The wasp_pca object is a prcomp object (the standard class for principal components analysis in R).\nBonus: visualization It can be hard to tell whether the PCA is capturing relevant axes of color pattern variation from a scatterplot; I find it more intuitive to plot some version the actual images. The add_image() function is an easy way to do that:\n# first, make a blank plot PCx \u0026lt;- 1; PCy \u0026lt;- 2 pca_summary \u0026lt;- summary(wasp_pca) limits \u0026lt;- apply(wasp_pca$x[ , c(PCx, PCy)], 2, range) par(mar = c(4, 4, 2, 1)) plot(wasp_pca$x[ , c(PCx, PCy)], type = \u0026quot;n\u0026quot;, asp = 1, xlim = limits[ , 1] + c(-5, 5), ylim = limits[ , 2] + c(-10, 10), xlab=paste0('PC1 (', round(pca_summary$importance[2, PCx]*100, 1), ' %)'), ylab=paste0('PC2 (', round(pca_summary$importance[2, PCy]*100, 1), ' %)')) # then add images: for (i in 1:length(impose_list)) { add_image(impose_list[[i]]$original_img, x = wasp_pca$x[i, PCx], y = wasp_pca$x[i, PCy], width = 20) }  You could also plot images from a folder on your computer:\nplot(wasp_pca$x[ , c(PCx, PCy)], type = \u0026quot;n\u0026quot;, asp = 1, xlim = limits[ , 1] + c(-5, 5), ylim = limits[ , 2] + c(-10, 10), xlab=paste0('PC1 (', round(pca_summary$importance[2, PCx]*100, 1), ' %)'), ylab=paste0('PC2 (', round(pca_summary$importance[2, PCy]*100, 1), ' %)')) # read in images from the original folder: images \u0026lt;- lapply(dir(\u0026quot;original_images/\u0026quot;, full.names = TRUE), readImage) # and plot: for (i in 1:length(images)) { add_image(images[[i]], x = wasp_pca$x[i, PCx], y = wasp_pca$x[i, PCy], width = 20) }  (If I were to use these images for a paper figure, though, I would go through and mask out the background using transparencies—these are a little hard to see on a white background.)\nThat\u0026rsquo;s it for the tutorial. I would recommend downloading the example code and files from the linked GitHub repository if you want to try it out: there are a few steps involved, but ultimately it\u0026rsquo;s a reasonably simple procedure. I\u0026rsquo;d love to be able to write a one-and-done version of this process, but if you\u0026rsquo;ve been reading the other recolorize documentation, you\u0026rsquo;ll be familiar with my perspective on this. Basically, if I try to impose a general structure for how to do this every time, that\u0026rsquo;s not going to be flexible enough to encompass many use cases, and I prefer to keep things modular. Still, if you have any ideas for how to make this a more friendly process, I\u0026rsquo;m all ears!\n","date":1643241600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643310262,"objectID":"dd275337967fce679313bfd67eec6b63","permalink":"/post/recolorize-patternize-workflow/","publishdate":"2022-01-27T00:00:00Z","relpermalink":"/post/recolorize-patternize-workflow/","section":"post","summary":"How to combine the recolorize and patternize packages to perform quantitative color pattern analyses.","tags":["color","r","recolorize","r packages"],"title":"Recolorize \u0026 patternize workflow","type":"post"},{"authors":["Hannah Weller"],"categories":[],"content":"One of the most direct ways to tell whether or not your image analysis is working is to plot your images themselves as points in your result plots, which is usually easier said than done. Lots of packages in R will allow you to do some form of this, but I usually run into two problems: 1) I have to download a (sometimes pretty hefty) package for a single function, and 2) that function often only works in a specific context, which means it\u0026rsquo;s not very flexible. In practice, I usually end up defining functions for this as-needed, in a sort of ad-hoc dirtbag fashion. This post will outline the basics of doing just that.\nFirst, let\u0026rsquo;s take a look at our images:\nThis is a lovely set of 40 images of jewel beetles, taken by my collaborator Nathan P. Lord. Not only are they all nicely uniform and centered, but the backgrounds are transparent \u0026ndash; this almost always makes for nicer plotting, because you don\u0026rsquo;t get big white corners when the images overlap. Although if you\u0026rsquo;re just using these plots as diagnostics instead of figures, it doesn\u0026rsquo;t really matter as long as it helps you understand your data better.\nAs an example of the kind of thing we might want to plot, we\u0026rsquo;ll use colordistance to generate a distance matrix of color similarity for the forty images above:\nlibrary(colordistance) # in my case, I have a folder called 'images' which contains the 40 images, # so 'images' is a vector of 40 paths images \u0026lt;- dir(\u0026quot;images/\u0026quot;, full.names = TRUE) # generate a distance matrix using all the package defaults cdm \u0026lt;- imageClusterPipeline(images, sample.size = FALSE)  The idea of this analysis is to cluster the images with the most similar color palettes together. So, we want to know if the clusters produced by this distance matrix represent images that actually are the most similar-looking.\nBy default, colordistance generates a heatmap representing the pairwise color distances between each image, where darker blue indicates that two images are more similar, and brighter pink indicates that they are less similar. You might notice that this graphic is kind of useless for diagnostics. The image names are just printed as labels, and their names are not indicative of their contents\u0026ndash;so I have no idea if this analysis has lumped together the green-and-shiny beetles separate from the black-and-yellow beetles, or if I need to try different settings, and sitting here looking up image names is not a quick way to check.\nA better solution is to plot the images at the tips of the hierarchical clustering tree shown on the top and left of the heatmap:\nTo make this plot, I used the ape package to plot a neighbor-joining tree of the distance matrix, then defined a function for plotting images at the tips. First, let\u0026rsquo;s make the neighbor-joining tree:\nlibrary(ape) tree \u0026lt;- nj(as.dist(cdm)) plot(tree, direction = \u0026quot;upwards\u0026quot;, cex = 0.5)  Next, we can define a function, add_image, which adds an image to a plot at a given set of XY coordinates. It\u0026rsquo;s sort of analogous to the points function, which lets you add points to an existing base R plot.\nThis is more complicated than just plotting an image as an image, because we have to play nice with existing plotting parameters (aspect ratio, range of the X- and Y-axes, etc).\n# define add_image function: add_image \u0026lt;- function(obj, # an object interpretable by rasterImage x = NULL, # x \u0026amp; y coordinates for the center of the image y = NULL, width = NULL, # width of the image interpolate = TRUE, # method for resizing angle = 0) { # get current plotting window parameters: usr \u0026lt;- graphics::par()$usr # extremes of user coordinates in the plotting region pin \u0026lt;- graphics::par()$pin # plot dimensions (in inches) # image dimensions and scaling factor: imdim \u0026lt;- dim(obj) sf \u0026lt;- imdim[1] / imdim[2] # set the width of the image (relative to x-axis) w \u0026lt;- width / (usr[2] - usr[1]) * pin[1] h \u0026lt;- w * sf # height is proportional to width hu \u0026lt;- h / pin[2] * (usr[4] - usr[3]) # scale height to y-axis range # plot the image graphics::rasterImage(image = obj, xleft = x - (width / 2), xright = x + (width / 2), ybottom = y - (hu / 2), ytop = y + (hu/2), interpolate = interpolate, angle = angle) }  Note that if you just want to plot an image as an image, you can use rasterImage from the graphics package, and almost any other image analysis package will come with a plotting method (for example, in recolorize you can use plotImageArray).\nWe can use this function to plot the images on a regular XY plot:\nX \u0026lt;- runif(40) Y \u0026lt;- runif(40) plot(X, Y) for (i in 1:length(images)) { # read the image into R: img \u0026lt;- png::readPNG(images[i]) # add the image: add_image(img, x = X[i], y = Y[i], width = 0.05) }  If we wanted to actually plot the distance matrix as a bivariate plot, we could use non-metric multidimensional scaling (NMDS), as described in this post, to represent the distance matrix with a set of 2D coordinates:\n# explaining NMDS is beyond the scope of this post (and is probably best left to the ecologists) # see this link for more: # https://cougrstats.wordpress.com/2019/12/11/non-metric-multidimensional-scaling-nmds-in-r/ # for now, we'll just do it in two lines! library(vegan) nmds_scores \u0026lt;- scores(metaMDS(comm = as.dist(cdm)))  ## Run 0 stress 0.1158626 ## Run 1 stress 0.1139447 ## ... New best solution ## ... Procrustes: rmse 0.01705616 max resid 0.09840254 ## Run 2 stress 0.1140722 ## ... Procrustes: rmse 0.007575743 max resid 0.03447679 ## Run 3 stress 0.1159785 ## Run 4 stress 0.1158626 ## Run 5 stress 0.1139448 ## ... Procrustes: rmse 0.0001779728 max resid 0.0006533518 ## ... Similar to previous best ## Run 6 stress 0.1158627 ## Run 7 stress 0.115814 ## Run 8 stress 0.1158626 ## Run 9 stress 0.1139447 ## ... New best solution ## ... Procrustes: rmse 6.912601e-05 max resid 0.0002514859 ## ... Similar to previous best ## Run 10 stress 0.1139447 ## ... Procrustes: rmse 5.642976e-05 max resid 0.0001733153 ## ... Similar to previous best ## Run 11 stress 0.1140719 ## ... Procrustes: rmse 0.007496018 max resid 0.03406593 ## Run 12 stress 0.1139448 ## ... Procrustes: rmse 9.99557e-05 max resid 0.000494275 ## ... Similar to previous best ## Run 13 stress 0.1139447 ## ... Procrustes: rmse 9.345179e-05 max resid 0.0004509194 ## ... Similar to previous best ## Run 14 stress 0.1139447 ## ... Procrustes: rmse 6.492366e-05 max resid 0.0003038437 ## ... Similar to previous best ## Run 15 stress 0.1140722 ## ... Procrustes: rmse 0.007604775 max resid 0.03440036 ## Run 16 stress 0.1158141 ## Run 17 stress 0.1158141 ## Run 18 stress 0.1158142 ## Run 19 stress 0.1139447 ## ... Procrustes: rmse 5.046786e-05 max resid 0.0002452231 ## ... Similar to previous best ## Run 20 stress 0.1158141 ## *** Solution reached  plot(nmds_scores) for (i in 1:length(images)) { # read the image into R: img \u0026lt;- png::readPNG(images[i]) # add the image: add_image(img, x = nmds_scores[i, 1], y = nmds_scores[i, 2], width = 0.05) }  If this were a presentation-quality figure, I would probably bump out the X- and Y-axis ranges a bit so none of the images got cut off, but this looks pretty good!\nHowever, I did promise plotting images at the tips of trees, and that turns out to be pretty easy once you\u0026rsquo;ve got a plotted tree and a set of tips. This mostly comes from this post on Liam Revell\u0026rsquo;s Phytools blog, which shows how to extract the XY coordinates of the tree tips from a plotted phylogeny; once we have those XY coordinates, we can plot images at those coordinates just as we would for a regular bivariate plot:\n# plot the tree plot(tree, show.tip.label = FALSE, direction = \u0026quot;upward\u0026quot;) # get the parameters from the plotting environment lastPP \u0026lt;- get(\u0026quot;last_plot.phylo\u0026quot;, envir = .PlotPhyloEnv) # get the xy coordinates of the tips ntip \u0026lt;- lastPP$Ntip # first n values are the tips, remaining values are the coordinates of the # nodes: xy \u0026lt;- data.frame(x = lastPP$xx[1:ntip], y = lastPP$yy[1:ntip]) # we can add points to the tree pretty easily using generic functions: points(xy[ , 1], xy[ , 2], col = viridisLite::viridis(40), pch = 19, cex = 2)  Putting it all together, all we have to do is plot the tree, then plot the images. One crucial thing here\u0026ndash;and familiar to anyone working with trees\u0026ndash;make sure your images are in the same order as your tips. This will save you a lot of head-scratching later.\n# get image names imnames \u0026lt;- tools::file_path_sans_ext(basename(images)) # get tip labels tipnames \u0026lt;- tree$tip.label # in my case, the tip labels are identical to the image names, so I can # use these to check that my images are in the right order: image_order \u0026lt;- match(tipnames, imnames) images \u0026lt;- images[image_order] # and plot! par(mar = rep(0, 4)) plot(tree, show.tip.label = FALSE, direction = \u0026quot;upward\u0026quot;) # get the parameters from the plotting environment lastPP \u0026lt;- get(\u0026quot;last_plot.phylo\u0026quot;, envir = .PlotPhyloEnv) # get the xy coordinates of the tips ntip \u0026lt;- lastPP$Ntip xy \u0026lt;- data.frame(x = lastPP$xx[1:ntip], y = lastPP$yy[1:ntip]) for (i in 1:length(images)) { add_image(png::readPNG(images[i]), x = xy[i, 1], y = xy[i, 2], width = 3) }  At this point, I usually write a wrapper function to do all of this for me, so I can plot an image tree from a tree and a list of image paths. I also add a bit of trickery to fix the x-axis scaling; phylogenies typically have weird axis scaling.\nimage_tree \u0026lt;- function(tree, # a phylo object image_paths, # a vector of image paths (in order) image_width = 0.1, # image width (as a proportion of the x-axis) tip_label = FALSE, # whether to draw the tip labels ...) { require(ape) # plot the tree plot.phylo(tree, show.tip.label = tip_label, ...) # this is the weird part: we get the phylo plot parameters from the active # graphics device lastPP \u0026lt;- get(\u0026quot;last_plot.phylo\u0026quot;, envir = .PlotPhyloEnv) # get the xy coordinates of the tips ntip \u0026lt;- lastPP$Ntip xy \u0026lt;- data.frame(x = lastPP$xx[1:ntip], y = lastPP$yy[1:ntip]) # scale image width according to plot width image_width \u0026lt;- diff(range(lastPP$x.lim)) * image_width # add the images using the add_image function for (i in 1:length(image_paths)) { img \u0026lt;- recolorize::readImage(image_paths[i]) add_image(img, xy[i, 1], xy[i, 2], width = image_width) } }  I\u0026rsquo;ll save that function and the add_image function in a script file (typically called image_tree.R or similar) and source that for the relevant project, so in practice my actual workflow looks like this:\nlibrary(ape) library(colordistance) # get images images \u0026lt;- dir(\u0026quot;images/\u0026quot;, full.names = TRUE) # get distance matrix cdm \u0026lt;- imageClusterPipeline(images, plot.heatmap = FALSE, sample.size = NULL) # make neighbor-joining tree tree \u0026lt;- nj(as.dist(cdm)) # plot image tree par(mar = rep(0, 4)) image_tree(tree, images, direction = \u0026quot;upward\u0026quot;, y.lim = c(0, 0.7))  So it\u0026rsquo;s actually pretty straightforward!\nOne question I would have after reading this post is: \u0026ldquo;Why don\u0026rsquo;t you just add this function to your R packages, instead of the crummy-looking default?\u0026rdquo; This is a good question, and there are two answers.\nFirst, I didn\u0026rsquo;t know how to do this when I first wrote the colordistance package, but I did know how to make heatmaps. I assumed that anyone using the package would take a quick look at the heatmap and then export the distance matrix for further analysis and plotting to emphasize whatever was most important about their results, and it didn\u0026rsquo;t occur to me that people are pretty likely to use the default visualization because they assume that\u0026rsquo;s what the package author intended. If I ever get the time and incentive to update the package, I hope to do so.\nSecond, I find myself redefining or tweaking this function so much for specific use cases (for instance, in this case we just use the readPNG function because all the images are PNGs, but you would need to change this if that\u0026rsquo;s not true of your images) that I didn\u0026rsquo;t see the point of including a static version in any one package. There\u0026rsquo;s so much variability in how plots are displayed and in how images are stored and displayed that a post explaining the details of the function was more helpful than creating a static version that would be out of date or too specific in scope. For instance, the image_tree function above doesn\u0026rsquo;t try to match your image list to your tree tips, because that would require assuming your images are named the same way as your tree tips, which probably won\u0026rsquo;t usually be the case.\nAnyways, there is probably a happier middle ground than what I\u0026rsquo;ve included here. Hopefully this post provides enough detail for other people to modify it for their needs!\n","date":1620345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620396986,"objectID":"a7ffb1135a8879d74b6cf032f2c23379","permalink":"/post/image-trees/","publishdate":"2021-05-07T00:00:00Z","relpermalink":"/post/image-trees/","section":"post","summary":"One of the most direct ways to tell whether or not your image analysis is working is to plot your images themselves as points in your result plots, which is usually easier said than done.","tags":["color","r"],"title":"Image trees","type":"post"},{"authors":["Hannah Weller"],"categories":[],"content":"A quick reference gallery for what the most broadly useful functions do.\nLoading and pre-processing images  readImage: Reads in a PNG or JPEG image, optionally resizing and/or rotating it.  img \u0026lt;- system.file(\u0026quot;extdata/corbetti.png\u0026quot;, package = \u0026quot;recolorize\u0026quot;) loaded_image \u0026lt;- readImage(img_path = img, resize = NULL, rotate = NULL)   blurImage: Applies one of several blurring filters from the imager package to a loaded image. Helpful for dealing with variation from textures (e.g. scales, reflections, hairs, etc).  blurred_image \u0026lt;- blurImage(loaded_image, blur_function = \u0026quot;medianblur\u0026quot;, n = 3, threshold = 5)  Initial segmentation  recolorize: The major function of the package. Segments colors using color binning (method = \u0026quot;hist\u0026quot;) or k-means clustering (method = \u0026quot;k\u0026quot;), in several color spaces.  rc_hist \u0026lt;- recolorize(img, method = \u0026quot;hist\u0026quot;, bins = 2, color_space = \u0026quot;sRGB\u0026quot;) #\u0026gt; #\u0026gt; Using 2^3 = 8 total bins  rc_k \u0026lt;- recolorize(img, method = \u0026quot;k\u0026quot;, n = 8, color_space = \u0026quot;sRGB\u0026quot;)   recolorize2: Runs recolorize and recluster (see next section) in sequence. I have found this to be an effective, fast combination for very many kinds of images, so if you\u0026rsquo;re going to pick one function to start with, pick this one!  rc \u0026lt;- recolorize2(img, cutoff = 45) #\u0026gt; #\u0026gt; Using 2^3 = 8 total bins   imposeColors: Imposes colors from one image onto another image (useful for batch processing).  colors \u0026lt;- c(\u0026quot;tomato\u0026quot;, \u0026quot;limegreen\u0026quot;, \u0026quot;dodgerblue\u0026quot;, \u0026quot;cornsilk\u0026quot;, \u0026quot;black\u0026quot;) colors \u0026lt;- t(col2rgb(colors)) / 255 imposed \u0026lt;- imposeColors(img, centers = colors)  Refining initial results  recluster: Combines existing clusters based on either a cutoff for color similarity or a target number of colors.  recluster_fit \u0026lt;- recluster(rc_hist, similarity_cutoff = 45)   thresholdRecolor: Drops the smallest clusters from a recolorize fit and refits the original image.  rc_thresh \u0026lt;- thresholdRecolor(rc_hist, pct = 0.01)   wernerColor: Remaps a recolorize object to the colors in Werner\u0026rsquo;s Nomenclature of Colors by Patrick Syme (1821), one of the first attempts at an objective color reference in western science, notably used by Charles Darwin. This one is mostly just for fun.  rc_werner \u0026lt;- wernerColor(recluster_fit)  Minor edits  absorbLayer: \u0026ldquo;Absorbs\u0026rdquo; all or part of a layer into the surrounding colors, optionally according to a size or location condition.  absorb_red \u0026lt;- absorbLayer(recluster_fit, layer_idx = 3, size_condition = function(s) s \u0026lt;= 100, highlight_color = \u0026quot;cyan\u0026quot;)   editLayer/editLayers: Applies one of several morphological operations from imager to a layer (or layers) of a recolorize object. This can be used to despeckle, fill in holes, or uniformly grow or shrink a color patch.  rc_edit \u0026lt;- editLayer(absorb_red, layer_idx = 3, operation = \u0026quot;fill\u0026quot;, px_size = 2)   mergeLayers: Merges specified layers together, with options for setting the new color.  merged_rc \u0026lt;- mergeLayers(rc_hist, merge_list = list(c(4, 7), c(3, 5), c(6, 8)))  Visualization  plotImageArray: Plots a 1D or 3D array as an RGB image.  layout(matrix(1:4, nrow = 1)) plotImageArray(loaded_image, main = \u0026quot;original\u0026quot;) plotImageArray(loaded_image[ , , 1], main = \u0026quot;red\u0026quot;) plotImageArray(loaded_image[ , , 2], main = \u0026quot;green\u0026quot;) plotImageArray(loaded_image[ , , 3], main = \u0026quot;blue\u0026quot;)   imDist | imHeatmap: Compares two versions of the same image by calculating the color distance between the colors of each pair of pixels (imDist), and gives you a few more options for plotting the results (imHeatmap).  layout(matrix(1:2, nrow = 1)) par(mar = rep(0, 4)) im_dist \u0026lt;- imDist(im1 = raster_to_array(recluster_fit$original_img), im2 = recoloredImage(recluster_fit), color_space = \u0026quot;Lab\u0026quot;) imHeatmap(im_dist, palette = viridisLite::viridis(100), legend = FALSE)   plotColorClusters: Plots color clusters in a 3D color space.  par(mar = rep(1, 4)) plotColorClusters(recluster_fit$centers, recluster_fit$sizes, color_space = \u0026quot;sRGB\u0026quot;, xlab = \u0026quot;red\u0026quot;, ylab = \u0026quot;green\u0026quot;, zlab = \u0026quot;blue\u0026quot;)   plotColorPalette: Alternatively, just plot as a color palette.  par(mar = rep(0, 4)) plotColorPalette(recluster_fit$centers, recluster_fit$sizes)  Exporting to other packages or files  splitByColor: Separates color clusters into individual layers (binary masks).  layout(matrix(1:6, nrow = 1)) plotImageArray(rc_edit$original_img) corbetti_layers \u0026lt;- splitByColor(rc_edit, plot_method = \u0026quot;over\u0026quot;)    classify_recolorize: Converts a recolorize object to a classify object in the pavo package for linking with spectral data.\n  recolorize_adjacency: Converts to a classify object using the above function, then runs the adjacency and boundary strength analysis function using values for human perceptual similarity.\n  recolorizeVector: Converts a bitmap (i.e. pixel) image to a vector image.\n  rc_vector \u0026lt;- recolorizeVector(recluster_fit, size_filter = 0.15, smoothness = 5)  ","date":1618272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618349229,"objectID":"6e384bde14a838a46df235e779e0354c","permalink":"/post/function-gallery-for-recolorize/","publishdate":"2021-04-13T00:00:00Z","relpermalink":"/post/function-gallery-for-recolorize/","section":"post","summary":"A copy of the recolorize function gallery vignette.","tags":["recolorize","color","r packages"],"title":"Function gallery for recolorize","type":"post"},{"authors":["Hannah Weller"],"categories":[],"content":"color-based image segmentation (for people with other things to do)  You can also tour the functions in the function gallery.\n The recolorize package is a toolbox for making color maps, essentially color-based image segmentation, using a combination of automatic, semi-automatic, and manual procedures. It has four major goals:\n  Provide a middle ground between automatic segmentation methods (which are hard to modify when they don\u0026rsquo;t work well) and manual methods (which can be slow and subjective).\n  Be deterministic whenever possible, so that you always get the same results from the same code.\n  Be modular and modifiable, so that you can tailor it for your purposes.\n  Play nice with other color analysis tools.\n  The color map above, for example, was generated using a single function which runs in a few seconds (and is deterministic):\nlibrary(recolorize) # get the path to the image (comes with the package, so we use system.file): img \u0026lt;- system.file(\u0026quot;extdata/corbetti.png\u0026quot;, package = \u0026quot;recolorize\u0026quot;) # fit a color map (only provided parameter is a color similarity cutoff) recolorize_obj \u0026lt;- recolorize2(img, cutoff = 45)  Notice what we didn’t have to input: we didn’t have to declare how many colors we expected (5), what we expect those colors to be (red, green, blue, black, and white), which pixels to include in each color patch, or where the boundaries of those patches are.\nThis introduction is intended to get you up and running with the recolorize package. Ideally, after reading it, you will have enough information to start to play around with the set of tools that it provides in a way that suits what you need it to do.\nI have tried not to assume too much about the reader\u0026rsquo;s background knowledge and needs, except that you are willing to use R and you have a color segmentation problem you have to solve before you can do something interesting with images. I primarily work with images of animals (beetles, fish, lizards, butterflies, snakes, birds, etc), and that will probably come through in the documentation. But it should work just as well for other kinds of images. Maybe better!\nI hope that this package will be helpful to you, and that if it is, you will share it with others who might find it helpful too. I had a lot of fun discussions with a lot of interesting people while I was making it, for which I\u0026rsquo;m very grateful.\nIf something is unclear or you find a bug, please get in touch or file an issue on the GitHub page. Suggestions for improvements are always welcome!\nQuick start  The bare minimum to start toying around with the package.\n The basic recolorize workflow is initial clustering step \\(\\rightarrow\\) refinement step \\(\\rightarrow\\) manual tweaks.\n  Images should first be color-corrected and have any background masked out, ideally with transparency, as in the image above, for example (Chrysochroa corbetti, taken by Nathan P. Lord, used with permission and egregiously downsampled to ~250x150 pixels by me).\n  In the initial clustering step, we bin all of the pixels into (in this case) 8 total clusters:\n  init_fit \u0026lt;- recolorize(img, method = \u0026quot;hist\u0026quot;, bins = 2, color_space = \u0026quot;sRGB\u0026quot;) #\u0026gt; #\u0026gt; Using 2^3 = 8 total bins  Followed by a refinement step where we combine clusters by their similarity:  refined_fit \u0026lt;- recluster(init_fit, similarity_cutoff = 45)  # pretty big improvement!  The recolorize2 function above calls these functions in sequence, since they tend to be pretty effective in combination.\nFinally, we can do manual refinements to clean up the different color layers, for example absorbing the red speckles into the surrounding color patches:  absorb_red \u0026lt;- absorbLayer(refined_fit, layer_idx = 3, size_condition = function(s) s \u0026lt;= 15, highlight_color = \u0026quot;cyan\u0026quot;)  Or performing simple morphological operations on individual layers:\nfinal_fit \u0026lt;- editLayer(absorb_red, 3, operation = \u0026quot;fill\u0026quot;, px_size = 4)  You can also batch process images using the same parameters, although recolorize functions only deal with one image at a time, so you will have to use a for loop or define a new function to call the appropriate functions in the right order:\n# get all 5 beetle images: images \u0026lt;- dir(system.file(\u0026quot;extdata\u0026quot;, package = \u0026quot;recolorize\u0026quot;), \u0026quot;png\u0026quot;, full.names = TRUE) # make an empty list to store the results: rc_list \u0026lt;- vector(\u0026quot;list\u0026quot;, length = length(images)) # run `recolorize2` on each image # you would probably want to add more sophisticated steps in here as well, but you get the idea for (i in 1:length(images)) { rc_list[[i]] \u0026lt;- suppressMessages(recolorize2(images[i], bins = 2, cutoff = 30, plotting = FALSE)) } # plot for comparison: layout(matrix(1:10, nrow = 2)) for (i in rc_list) { plotImageArray(i$original_img) plotImageArray(recoloredImage(i)) }  # given the variety of colors in the dataset, not too bad, # although you might go in and refine these individually  Once you have a color map you\u0026rsquo;re happy with, you can export to a variety of formats. For instance, if I wanted to run Endler\u0026rsquo;s adjacency and boundary strength analysis in the pavo package, using human perception:\nadj \u0026lt;- recolorize_adjacency(rc_list[[1]], coldist = \u0026quot;default\u0026quot;, hsl = \u0026quot;default\u0026quot;) #\u0026gt; Using single set of coldists for all images. #\u0026gt; Using single set of hsl values for all images. print(adj[ , c(57:62)]) # just print the chromatic and achromatic boundary strength values #\u0026gt; m_dS s_dS cv_dS m_dL s_dL cv_dL #\u0026gt; 36.33178 11.90417 0.3276517 24.88669 17.80173 0.7153115  If you\u0026rsquo;d like a deeper explanation of each of these steps, as well as how to modify them to suit your needs, along with what else the package can do: read on!\nBefore you start Color segmentation can be a real rabbit hole—that is, it can be pretty easy to become fixated on getting perfect results, or on trying to define some objective standard for what correct segmentation looks like. The problem with this mindset is that there’s no set of universal parameters that will give you perfect segmentation results for every image, because images alone don’t always contain all the relevant information: color variation due to poor lighting in one image could be just as distinct as color variation due to pattern striations in another.\nThe correct output for color segmentation depends on your goal: are you concerned with identifying regions of structural vs. pigmented color? Does the intensity of the stain on your slide matter, or just presence/absence? If you have a few dozen stray pixels of the wrong color in an image with hundreds of thousands of correctly categorized pixels, will that meaningfully affect your calculations?\nLet\u0026rsquo;s take the jewel beetle (family Buprestidae) images that come with the package as an example. If I want to segment the lefthand image (Chrysochroa fulgidissima), the solution depends on my question. If my question is \u0026ldquo;How does the placement and size of these red bands compare to that of closely related beetles?\u0026rdquo; then I really just want to separate the red bands from the rest of the body, so I would want the color map in the middle. If my question is \u0026ldquo;How much do these red bands stand out from the iridescent green base of the beetle?\u0026rdquo; then I care about the brighter orange borders of the bands, because these increase the boundary strength and overall contrast in the beetle\u0026rsquo;s visual appearance—so I would go with map 2 on the right. So before you start, I highly recommend writing down precisely what you want to measure at the end of your analysis, to avoid becoming weighed down by details that may not matter. It will save you a lot of time.\nStep 0: Image acquisition \u0026amp; preparation  What to do before you use recolorize.\n Before we attempt image segmentation, we need segmentable images. recolorize doesn’t process your images for you beyond a few basic things like resizing, rotating, and blurring (which can help with segmentation). You should do all image processing steps which are usually necessary for getting quantitative color data, like white balance correction, gradient correction, or background removal, before inputting them to recolorize.\nThere are lots of software tools available for making these kinds of corrections: GIMP, FIJI/ImageJ, and even the imager package will provide options for some or all of these. If you really want to get pipeline-y, Python has a much more robust set of image processing libraries that will help with automatic color correction and background masking, which is well beyond the scope of this intro.\nIf you are at all concerned with sensory biology and animal vision, I highly recommend micaToolbox, which is a well-documented and comprehensive toolkit for creating images as animals see them (rather than as cameras and computers see them); see especially the instructions for creating false color cone-mapped images.\nThe corrections you have to make really depend on what you’re trying to do. If you just care about the regions but don’t really care about the final colors they end up being assigned, you probably don’t need to worry too much about color correction; if you’re working with histology slides, you probably don’t need to mask the background; if you have a really even and diffuse lighting setup, you probably won’t have to deal with shadows or gradients.\nBackground masking with transparencies If you’re masking the background, use transparencies. This is pretty easy to do in GIMP, Photoshop, or ImageJ. The transparency layer (or alpha channel) is the fourth channel of an image (the other three being the R, G, and B channels), and recolorize treats it like a binary mask: any pixel with an alpha value of 1 is retained, and any pixel with an alpha value of \u0026lt; 1 is ignored. This means you don’t have to worry about finding a uniform background color that is sufficiently different from your foreground object in every image, which can otherwise be a real pain.\nUsing transparency is unambiguous, and has the bonus benefit of making for nicer plots, too, since you don’t have to worry about the corners of your images overlapping and blocking each other. All the images in this demo have transparent backgrounds. However, you can use the lower and upper arguments to set boundaries for excluding pixels as background based on their color (see documentation). Just know that these will be set to transparent internally.\nStep 1: Loading \u0026amp; processing images  How to get images into R.\n We can read in an image by passing the filepath to the readImage function. This is a pretty generic function (almost every image processing package in R has something similar); the recolorize version doesn\u0026rsquo;t even assign the output to a special class (so don\u0026rsquo;t try to print it).\n# define image path - we're using an image that comes with the package img_path \u0026lt;- system.file(\u0026quot;extdata/corbetti.png\u0026quot;, package = \u0026quot;recolorize\u0026quot;) # load image img \u0026lt;- readImage(img_path, resize = NULL, rotate = NULL) # it's just an array with 4 channels: dim(img) #\u0026gt; [1] 243 116 4  An image is a numeric array with either 3 or 4 channels (R, G, B, and optionally alpha for transparency). JPG images will only have 3 channels; PNG images will have 4. This is quite a small image (243x116 pixels) with 4 channels.\nWe can plot the whole array as an image, or plot one channel at a time. Notice that the red patches are bright in the R channel, same for blue-B channel, green-G channel, etc—and that the off-white patch is bright for all channels, while the black patches are dark in all channels. The alpha channel is essentially just a mask that tells us which parts of the image to ignore when processing it further.\nlayout(matrix(1:5, nrow = 1)) plotImageArray(img, main = \u0026quot;RGB image\u0026quot;) plotImageArray(img[ , , 1], main = \u0026quot;R channel\u0026quot;) plotImageArray(img[ , , 2], main = \u0026quot;G channel\u0026quot;) plotImageArray(img[ , , 3], main = \u0026quot;B channel\u0026quot;) plotImageArray(img[ , , 4], main = \u0026quot;Alpha channel\u0026quot;)  Optionally, when you load the image, you can resize it (highly recommended for large images) and rotate it. Image processing is computationally intensive, and R is not especially good at it, so downsampling it usually a good idea. A good rule of thumb for downsampling is that you want the smallest details you care about in the image (say, spots on a ladybug) to be about 5 pixels in diameter (so if your spots have a 20 pixel diameter, you can set resize = 0.25).\nThe only other thing you might do to your images before sending them to the main recolorize functions is blurImage. This is really useful for minimizing color variation due to texture (e.g. scales on a lizard, feathers on a bird, sensory hairs on an insect), and you can apply one of several smoothing algorithms from the imager package, including edge-preserving blurs:\nblurred_img \u0026lt;- blurImage(img, blur_function = \u0026quot;blur_anisotropic\u0026quot;, amplitude = 10, sharpness = 0.2)  This step is optional: most of the recolorize functions will accept a path to an image as well as an image array. But once you\u0026rsquo;re happy here, we can start defining color regions!\nStep 2: Initial clustering  Go from thousands of colors to a manageable number for further refinement.\n The color clustering in recolorize usually starts with an initial clustering step which produces more color clusters than the final color map will have, which are then edited and combined to form the final color map. We start with an over-clustering step because it is a quick way to go from an overwhelming number of colors (256^3 unique RGB colors) to a manageable number that can be manually inspected or automatically re-clustered. You’ll usually do this using the recolorize function, which is the core of the package (go figure!):\ncorbetti \u0026lt;- system.file(\u0026quot;extdata/corbetti.png\u0026quot;, package = \u0026quot;recolorize\u0026quot;) recolorize_defaults \u0026lt;- recolorize(img = corbetti) #\u0026gt; #\u0026gt; Using 2^3 = 8 total bins  This function does a lot under the hood: we read in the image as an array, binned every pixel in the image into one of eight bins in RGB color space, calculated the average color of all the pixels assigned to a given bin, recolored the image to show which pixel was assigned to which color center, and returned all of that information in the recolorize_defaults object. Pretty much everything beyond this step will be a modification of one of those elements, so we\u0026rsquo;ll take a second to examine the contents of that output.\nThe recolorize class Objects of S3 class recolorize are lists with several elements:\nattributes(recolorize_defaults) #\u0026gt; $names #\u0026gt; [1] \u0026quot;original_img\u0026quot; \u0026quot;centers\u0026quot; \u0026quot;sizes\u0026quot; #\u0026gt; [4] \u0026quot;pixel_assignments\u0026quot; #\u0026gt; #\u0026gt; $class #\u0026gt; [1] \u0026quot;recolorize\u0026quot;    original_img is a a raster matrix, essentially a matrix of hex color codes. This is a more lightweight version of the 3D/4D color image array we loaded earlier, and can be plotted easily by running plot(recolorize_defaults$original_img).\n  centers is a matrix of RGB centers (0-1 range) for each of the color patches. Their order matches the index values in the pixel_assignments matrix.\n  sizes is a vector of patch sizes, whose order matches the row order of centers.\n  pixel_assignments is a paint-by-numbers matrix, where each pixel is coded as the color center to which it was assigned. For example, cells with a 1 have been assigned to the color represented by row 1 of centers. Background pixels are marked as 0.\n  If you plot the whole recolorize object, you\u0026rsquo;ll get back the plot you see above: the original image, the color map (where each pixel has been recolored), and the color palette. You can also plot each of these individually:\nlayout(matrix(1:3, nrow = 1), widths = c(0.45, 0.45, 0.1)) par(mar = rep(0, 4)) plot(recolorize_defaults$original_img) plotImageArray(recolorize_defaults$pixel_assignments / 8) plotColorPalette(recolorize_defaults$centers, recolorize_defaults$sizes, horiz = FALSE)  You\u0026rsquo;ll notice this doesn\u0026rsquo;t look exactly like the function output above. Aside from some wonky scaling issues, the pixel assignment matrix plotted as a grayscale image (and we had to divide it by the number of colors in the image so it was in a 0-1 range). That\u0026rsquo;s because we didn\u0026rsquo;t tell R which colors to make each of those values, so layer 1 is the darkest color and layer 8 is the brightest color in the image.\nYou can get the recolored image by calling recoloredImage:\n# type = raster gets you a raster (like original_img); type = array gets you an # image array recolored_img \u0026lt;- recoloredImage(recolorize_defaults, type = \u0026quot;array\u0026quot;) plotImageArray(recolored_img)  recoloredImage is just a shortcut function for constructImage, which lets you decide which colors to assign to each category in case you want to swap out the palette:\ncolors \u0026lt;- c(\u0026quot;navy\u0026quot;, \u0026quot;lightblue\u0026quot;, \u0026quot;blueviolet\u0026quot;, \u0026quot;turquoise\u0026quot;, \u0026quot;slateblue\u0026quot;, \u0026quot;royalblue\u0026quot;, \u0026quot;aquamarine\u0026quot;, \u0026quot;dodgerblue\u0026quot;) blue_beetle \u0026lt;- constructImage(recolorize_defaults$pixel_assignments, centers = t(col2rgb(colors) / 255)) # a very blue beetle indeed: plotImageArray(blue_beetle)  Now that you have a better understanding of what these objects contain and what to do with them, we can start to unpack exactly what this function is doing.\nThe recolorize function The main recolorize function has a simple goal: to take your image from a huge number of colors to a manageable number of color clusters. This falls under a category of methods for color quantization, although we have a slightly different goal here. The typical reason for doing color quantization is to simplify an image while making it look as visually similar as possible to the original; our goal is not to represent the original image, but to create a set of building blocks to combine and clean up so we can refer to whole color patches easily.\nIf you look at the documentation for the recolorize function, you’ll see a lot of user-specifiable parameters. There are only really 3 major ones:\n the color space in which the clustering is done (color_space) the clustering method (the method argument) the number of color clusters (bins for method = hist and n for method = kmeans)  You can also map an image to an externally imposed set of colors using another function, imposeColors, which can be useful for batch processing images.\nWe\u0026rsquo;ll go over each of these parameters and what they do. I\u0026rsquo;ll give mild advice about how to navigate these options, but there\u0026rsquo;s a reason I\u0026rsquo;ve included all of theme here, which is that I think any combination of these parameters can be useful depending on the context.\nColor spaces Color spaces are ways to represent colors as points in multi-dimensional spaces, where each axis corresponds to some aspect of the color. You\u0026rsquo;re probably familiar with RGB (red-green-blue) color space and HSV (hue-saturation-value) color space. In RGB space, colors vary by the amount of red, green, and blue they have, where a coordinate of [0, 0, 1] would be pure blue (no red or green), [1, 1, 1] would be white, [0, 1, 1] would be cyan, etc. This is how most images are stored and displayed on computers, although it\u0026rsquo;s not always very intuitive.\nThe recolorize package gives you a variety of options for color spaces, but by far the two most commonly used are RGB (color_space = sRGB) and CIE Lab (color_space = Lab). CIE Lab is popular because it approximates perceptual uniformity, which means that the distances between colors in CIE Lab space are proportional to how different they actually seem to human beings. The axes represent luminance (L, 0 = black and 100 = white), red-green (a, negative values = more green and positive values = more red), and blue-yellow (b, negative values = more blue and positive values = more yellow). The idea is that something can be greenish-blue, or reddish-yellow, but not reddish-green, etc. This can be a little confusing, but the results it provides are really intuitive. For example, in RGB space, red is as similar to yellow as it is to black. In CIE Lab, red and yellow are close together, and are about equally far from black.\nI\u0026rsquo;ve written in more detail about color spaces for another package here, which I would recommend reading for a more detailed overview, but let\u0026rsquo;s see what happens if we plot all of the non-background pixels from our C. corbetti example in RGB compared to CIE Lab color space (forgive the crummy plotting):\nWe can identify green, red, blue, black, and white pixels in both sets of plots, but their distributions are very different.\nIn practice, I find myself toggling between these two color spaces depending on the color distributions in my images. For example, when dealing with C. corbetti, I would use RGB, because the beetle is literally red, green, and blue. When dealing with the red and green C. fulgidissima above, I found that CIE Lab produced better results, because it separates red and green pixels by much more distance. But in general, especially as you increase the number of initial clusters, this matters less at this stage than at the refinement stage (where you can switch between color spaces again). Because CIE Lab is not evenly distributed on all axes (i.e. is not a cube), you may need to use more bins in CIE Lab space than in RGB. (Try fitting the C. corbetti image with CIE Lab space and see what happens for an idea of how much the choice of color space can matter.)\nClustering methods The two clustering methods in recolorize are color histogram binning (fast, consistent, and deterministic) and k-means clustering (comparatively slower and heuristic, but more intuitive). The bins argument is accessed by the histogram method, and n goes with the kmeans method. I highly recommend the histogram binning unless you have a good reason not to use it, but there are good reasons to use k-means clustering sometimes.\nThe histogram binning method is essentially just a 3-dimensional color histogram: we divide up each channel of a color space into a predetermined number of bins, then count the number of pixels that fall into that bin and calculate their average color. So, when we divide each of 3 color channels into 2 bins, we end up with \\(2^3 = 8\\) total bins (which is why setting bins = 2 will produce 8 colors as above).\nk-means clustering, on the other hand, is a well-known method for partitioning data into n clusters. You just provide the number of clusters you want, and it will try to find the best locations for them, where ‘best’ means minimizing the squared Euclidean distances between pixels and color centers within each cluster.\nTo appreciate these differences, we can fit the same number of colors (64) using the histogram method and the k-means method on the same image, then view the resulting color distributions:\n# fit 64 colors, both ways r_hist \u0026lt;- recolorize(img_path, method = \u0026quot;hist\u0026quot;, bins = 4, plotting = FALSE) #\u0026gt; #\u0026gt; Using 4^3 = 64 total bins r_k \u0026lt;- recolorize(img_path, method = \u0026quot;k\u0026quot;, n = 64, plotting = FALSE) plotColorClusters(r_hist$centers, r_hist$sizes, plus = .5, xlab = \u0026quot;red\u0026quot;, ylab = \u0026quot;green\u0026quot;, zlab = \u0026quot;blue\u0026quot;, mar = c(3, 3, 2, 2), main = \u0026quot;Histogram method\u0026quot;)  plotColorClusters(r_k$centers, r_k$sizes, plus = .5, xlab = \u0026quot;red\u0026quot;, ylab = \u0026quot;green\u0026quot;, zlab = \u0026quot;blue\u0026quot;, mar = c(3, 3, 2, 2), main = \u0026quot;k-means clustering\u0026quot;)  The histogram method produced a lot of tiny, nearly-empty clusters that are evenly distributed in the color space, with only a few large clusters (like the black and white ones). The k-means clustering method, on the other hand, produced a lot more medium-sized clusters, as well as splitting the black and white patches across multiple clusters.\nA lot of color segmentation tools will only use k-means clustering (or a similar method), because it’s relatively easy to implement and does produce good results if your images have clear color boundaries and very different colors (i.e. the pixels are far apart in color space). If you were going to stop at the initial clustering step, this would probably be a better option than the histogram binning for that reason. The main reason I recommend against it is that it is not deterministic: you will get different colors, and in a different order, every time you run it. For example, if we fit 10 colors three separate times, we get the following color palettes:\nk_list \u0026lt;- lapply(1:3, function(i) recolorize(img_path, \u0026quot;k\u0026quot;, n = 10, plotting = F)) layout(1:3) par(mar = rep(1, 4)) lapply(k_list, function(i) plotColorPalette(i$centers, i$sizes))  #\u0026gt; [[1]] #\u0026gt; NULL #\u0026gt; #\u0026gt; [[2]] #\u0026gt; NULL #\u0026gt; #\u0026gt; [[3]] #\u0026gt; NULL  The colors are similar, but not identical, and they are returned in an arbitrary order. If you run this code one day and pull out all the red clusters by their index, or merge the multiple green clusters, those values will change the next time you run the code. That and the need to specify cluster numbers for each image are more or less why I recommend not using this method unless you have a reason.\nBinning the colors (histograms) is usually more viable as a first step. It’s quite fast, since we’re not really doing any clustering; the bins we assign the pixels to will be the same for every image, and we’re not calculating the distances between the pixels and their assigned color. It’s also deterministic, which means you get the same result every single time you run it. The downside is that makes this approach almost guaranteed to over-split colors, since your color regions will rarely fall cleanly within the boundaries of these bins, and many of the bins you end up with will be empty or have very few pixels.\nNumber of clusters Unlike the color space and binning method, this parameter is pretty intuitive: the more clusters you fit, the more the colors in your image will be split up. It’s convenient to use the same scheme for every image in your dataset, so you might end up using whatever values are needed for your most complex image and over-splitting most of your other images. That’s usually fine, because the next set of steps will try to lump colors together or remove minor details. You want to be just granular enough to capture the details you care about, and it’s okay if some colors are split up.\nOne thing to note is that the bins argument allows for a different number of bins for each channel. Setting bins = 2 will divide each channel into 2 bins, but you can also set bins = c(5, 2, 2) to divide up the red channel into 5 bins and the blue and green channels into 2 bins (if in RGB space). This can be convenient if you have a lot of color diversity on only one axis, e.g. you have photographs of mammals which are shades of reddish-brown, and don\u0026rsquo;t need to waste computational time dividing up the blue channel.\n# we can go from an unacceptable to an acceptable color map in # CIE Lab space by adding a single additional bin in the luminance channel: r_hist_2 \u0026lt;- recolorize(img_path, method = \u0026quot;hist\u0026quot;, color_space = \u0026quot;Lab\u0026quot;, bins = 2) #\u0026gt; #\u0026gt; Using 2^3 = 8 total bins  r_hist_322 \u0026lt;- recolorize(img_path, method = \u0026quot;hist\u0026quot;, bins = c(3, 2, 2)) #\u0026gt; #\u0026gt; Using 3*2*2 = 12 bins  imposeColors() Another option is to impose colors on an image, rather than using intrinsic image colors. Every pixel is assigned to the color it is closest to in some specified color space. Usually, this is useful for batch processing: you get colors from one image, then map them onto another image, so that the color centers correspond across all your images.\nim1 \u0026lt;- system.file(\u0026quot;extdata/ocellata.png\u0026quot;, package = \u0026quot;recolorize\u0026quot;) im2 \u0026lt;- system.file(\u0026quot;extdata/ephippigera.png\u0026quot;, package = \u0026quot;recolorize\u0026quot;) # fit the first image fit1 \u0026lt;- recolorize(im1) #\u0026gt; #\u0026gt; Using 2^3 = 8 total bins  # fit the second image using colors from the first # adjust_centers = TRUE would find the average color of all the pixels assigned to # the imposed colors to better match the raw image fit2 \u0026lt;- imposeColors(im2, fit1$centers, adjust_centers = FALSE)  Step 3: Refinement  Using simple rules to improve the initial results.\n Once we’ve reduced an image down to a tractable number of colors, we can define simple procedures for how to combine them based on similarity. recolorize (currently) comes with two of these: recluster, which merges colors by perceived similarity, and thresholdRecolor, which drops minor colors. Both are simple, but surprisingly effective. They’re also built on top of some really simple functions we’ll see in a bit, so if you need to, you can build out a similar procedure tailored to your dataset—for example, combining layers based only on their brightness values, or only combining green layers.\nrecluster() and recolorize2() This is the one I use the most often, and its implementation is really simple. This function calculates the Euclidean distances between all the color centers in a recolorize object, clusters them hierarchically using hclust, then uses a user-specified cutoff to combine the most similar colors. As with recolorize, you can choose your color space, and that will make a big difference. Let’s see this in action:\nrecluster_results \u0026lt;- recluster(recolorize_defaults, similarity_cutoff = 45)  Notice the color dendrogram: it lumped together clusters 4 \u0026amp; 7, clusters 3 \u0026amp; 5, and clusters 6 \u0026amp; 8, because their distance was less than 45. This is in CIE Lab space; if we use RGB space, the range of distances is 0-1:\nrecluster_rgb \u0026lt;- recluster(recolorize_defaults, color_space = \u0026quot;sRGB\u0026quot;, similarity_cutoff = 0.5)  In this case, we get the same results, but this is always worth playing around with. Despite its simplicity, this function is highly effective at producing intuitive results. This is partly because, in only using color similarity to combine clusters, it does not penalize smaller color clusters that can still retain important details. I find myself using it so often that I included a wrapper function, recolorize2, to run recolorize and recluster sequentially in a single step:\n# let's use a different image: img \u0026lt;- system.file(\u0026quot;extdata/chongi.png\u0026quot;, package = \u0026quot;recolorize\u0026quot;) # this is identical to running: # fit1 \u0026lt;- recolorize(img, bins = 3) # fit2 \u0026lt;- recluster(fit1, similarity_cutoff = 50) chongi_fit \u0026lt;- recolorize2(img, bins = 3, cutoff = 45) #\u0026gt; #\u0026gt; Using 3^3 = 27 total bins  There’s also a lot of room for modification here: this is a pretty unsophisticated rule for combining color clusters (ignoring, for example, cluster size, proximity, geometry, and boundary strength), but it’s pretty simple to write better rules if you can think of them, because the functions that are called to implement this are also exported by the package.\nthresholdRecolor() An even simpler rule: drop the smallest color clusters whose cumulative sum (as a proportion of total pixels assigned) is lower than some threshold, like 5% of the image. I thought this would be too simple to be useful, but every once in a while it’s just the thing, especially if you always end up with weird spurious details.\nchongi_threshold \u0026lt;- thresholdRecolor(chongi_fit, pct = 0.1)  Step 4: Minor edits  Cleaning up the details.\n These are functions that can be called individually to address problem areas in specific images, or strung together as building blocks to do more complicated operations.\nabsorbLayer \u0026ldquo;Absorbs\u0026rdquo; all or part of a layer into the surrounding colors, optionally according to a size or location condition.\nimg \u0026lt;- system.file(\u0026quot;extdata/fulgidissima.png\u0026quot;, package = \u0026quot;recolorize\u0026quot;) ful_init \u0026lt;- recolorize2(img, bins = 3, cutoff = 60, plotting = F) #\u0026gt; #\u0026gt; Using 3^3 = 27 total bins ful_absorb \u0026lt;- absorbLayer(ful_init, layer_idx = 3, function(s) s \u0026lt;= 250, y_range = c(0, 0.8), highlight_color = \u0026quot;cyan\u0026quot;)  This function is really useful, but fair warning: it can be quite slow. It works by finding the color patch with which each highlighted component shares the longest border and switching the highlighted component to that color, which is more sophisticated than simply switching the patch color, but requires many more calculations. If you find yourself using this a lot, it\u0026rsquo;s a good idea to make sure you\u0026rsquo;ve downsampled your images using the resize argument.\neditLayer/editLayers Applies one of several morphological operations from imager to a layer (or layers) of a recolorize object. This can be used to despeckle, fill in holes, or uniformly grow or shrink a color patch. In practice, this is mostly only useful for fixing small imperfections; anything too drastic tends to alter the overall shape of the patch.\n# cleans up some of the speckles in the above output ful_clean \u0026lt;- editLayers(ful_absorb, layer_idx = c(2, 5), operations = \u0026quot;fill\u0026quot;, px_sizes = 3, plotting = T)  This function is also easy to modify. Internally, it splits the color map into individual masks using splitByColor() (another recolorize function), then converts those to pixsets for use in imager before slotting them back in with the unchanged layers.\nmergeLayers Sometimes, you don’t want to define fancy rules for deciding which layers to combine; you just want to combine layers. That’s what this function is for. It takes in a list of numeric vectors for layers to combine (layers in the same vector are combined; those in different list elements are kept separate).\nmerge_fit \u0026lt;- mergeLayers(recolorize_defaults, merge_list = list(1, 2, c(3, 5), c(4, 7), c(6, 8)))  You might notice this is a bit different than our recluster results above. That’s because internally, recluster actually uses imposeColors to refit the color map, rather than just merging layers; I have found this often produces slightly nicer results, because pixels that were on the border of one cutoff or another don’t get stranded in the wrong layer. On the other hand, mergeLayers is considerably faster.\nStep 4.5: Visualizations Making color maps is an obviously visual process, so it’s good to use visual feedback as much as possible. We’ve already seen a few of these functions in action, specifically plotColorPalette and plotImageArray, which are used in almost every function that produces a recolorize object. I’ll point out three others that I think are quite useful: imDist, plotColorClusters, and splitByColor (which also doubles as an export function).\nimDist Compares two versions of the same image by calculating the color distance between the colors of each pair of pixels (imDist), and gives you a few more options for plotting the results (imHeatmap). You can use it to get the distances between the original image and the color map:\nlayout(matrix(1:2, nrow = 1)) # calculates the distance matrix and plots the results dist_original \u0026lt;- imDist(readImage(img), recoloredImage(ful_clean), color_space = \u0026quot;sRGB\u0026quot;) # more plotting options - setting the range is important for comparing # across images (max is sqrt(3) in sRGB space, ~120 in Lab) imHeatmap(dist_original, viridisLite::inferno(100), range = c(0, sqrt(3)))  The resulting object is a simple matrix of distances between each pair of pixels in the given color space. These are essentially residuals:\nhist(dist_original, main = \u0026quot;sRGB distances\u0026quot;, xlab = \u0026quot;Distance\u0026quot;)  A word of warning here: it is easy to look at this and decide to come up with a procedure for automatically fitting color maps using a kind of AIC metric, trying to get the lowest SSE with the minimum set of color centers. You’re welcome to try that, but given that this is discarding spatial information, it is probably not a general solution (I haven’t had much luck with it). But there is probably some room to play here.\nsplitByColor This is a dual-use function: by splitting up the color map into individual layers, you not only can examine the individual layers and decide whether they need any editing or merging, but you also get out a binary mask representing each layer, so you can export individual patches.\nlayout(matrix(1:10, nrow = 2, byrow = TRUE)) # 'overlay' is not always the clearest option, but it is usually the prettiest: layers \u0026lt;- splitByColor(recluster_results, plot_method = \u0026quot;overlay\u0026quot;) # layers is a list of matrices, which we can just plot: lapply(layers, plotImageArray)  #\u0026gt; [[1]] #\u0026gt; [[1]]$mar #\u0026gt; [1] 0 0 2 0 #\u0026gt; #\u0026gt; #\u0026gt; [[2]] #\u0026gt; [[2]]$mar #\u0026gt; [1] 0 0 2 0 #\u0026gt; #\u0026gt; #\u0026gt; [[3]] #\u0026gt; [[3]]$mar #\u0026gt; [1] 0 0 2 0 #\u0026gt; #\u0026gt; #\u0026gt; [[4]] #\u0026gt; [[4]]$mar #\u0026gt; [1] 0 0 2 0 #\u0026gt; #\u0026gt; #\u0026gt; [[5]] #\u0026gt; [[5]]$mar #\u0026gt; [1] 0 0 2 0  Step 5: Exporting  The whole point of this package is to make it easier to use other methods!\n Exporting to aimges The most direct thing you can do is simply export your recolored images as images, then pass those to whatever other tool you’d like to use, although obviously this doesn’t take full advantage of the format:\n# export color map png::writePNG(recoloredImage(recluster_results), target = \u0026quot;recolored_corbetti.png\u0026quot;) # export individual layers from splitByColor for (i in 1:length(layers)) { png::writePNG(layers[[i]], target = paste0(\u0026quot;layer_\u0026quot;, i, \u0026quot;.png\u0026quot;)) }  pavo package You can also convert a recolorize object to a classify object in the wonderful pavo package and then run an adjacency analysis. Bonus points if you have reflectance spectra for each of your color patches: by combining the spatial information in the color map with the coldist object generated by spectral measurements, you can run adjacency analysis for the visual system(s) of your choice right out of the box!\n# convert to a classify object as_classify \u0026lt;- classify_recolorize(recluster_results, imgname = \u0026quot;corbetti\u0026quot;) adj_analysis \u0026lt;- pavo::adjacent(as_classify, xscale = 10) # run adjacent directly using human perceptual color distances (i.e. no spectral data - proceed with caution) adj_human \u0026lt;- recolorize_adjacency(recluster_results)  You can also run an adjacency analysis with recolorize_adjacency, but only as long as you keep your skeptic hat on. This function works by calculating a coldist object right from the CIE Lab colors in the color maps, which are themselves probably derived from your RGB image, which is at best a very loose representation of how these colors appear to human eyes. The only reason this is at all reasonable is that it’s producing these values for human vision, so you will be able to see if it’s completely unreasonable. This is fine for getting some preliminary results or if you’re working with aggregate data from many sources and you’re content with specifically human (not just non-UV, but only human) vision. Otherwise, it’s probably a last resort.\npatternize Coming soon (pending a patternize update), and with many thanks to Steven van Belleghem for his help in making recolorize and patternize get along!\nSome advice This is a lot of options. How do I choose a procedure? Most things will more or less work; if it looks reasonable, it is. Keep in mind that there is a big difference between getting slightly different color maps and getting qualitatively different results. Keep your final goal in mind. You can also try lots of different things and see if it makes a real difference.\nI wish I could write a single function that would do all of these steps in the correct sequence and produce perfect results; the reason that function does not exist is because I find I have to do experiment a fair amount with every image set, and I often end up with a different order of operations depending on the problem.\nStart with recolorize2 and identify the common problems you\u0026rsquo;re encountering. Does it make sense to batch process all of your images, then refine them individually? Is it better to choose a different cutoff for each image? Luckily, these functions are relatively fast, so you can test out different options.\nYou can also get way fancier with cutoffs than I have here. This package is built on some pretty simple scaffolding: you get a starting set of clusters, then you modify them. If you have a better/more refined way of deciding which colors to cluster, then go for it. I will soon be adding some example workflows from collaborators which should be helpful.\nThere is another very tempting option: make a small training set of nice color maps manually with recolorize, then use those to either fit a statistical model for other fits or use machine learning to do the rest. I think this is a really compelling idea; I just haven\u0026rsquo;t tested it yet. Maybe you want to try it out?\nCan you define an optimality condition to do all the segmentation automatically? As far as I can tell, no. This is because of the problem I pointed out at the beginning: the \u0026lsquo;correct\u0026rsquo; segmentation depends on your particular question more than anything else.\nHow should you store the code used to generate a color map? I like to use rlang::enexpr to capture the code I run to generate a color map, and store it as another aspect of the recolorize object, like so:\nlibrary(rlang) # run this code, then capture it in the brackets: steps \u0026lt;- { fit \u0026lt;- recolorize2(img,bins = 3, cutoff = 50) fit2 \u0026lt;- editLayers(fit, c(2, 5), operations = \u0026quot;fill\u0026quot;, px_sizes = 3) } %\u0026gt;% enexprs() fit2$steps \u0026lt;- steps  What about batch processing? Every function in this package operates on a single image at a time. This is because I\u0026rsquo;ve found that there is so much variation in how people go about batch processing anything: if I tried to impose what I considered to be a useful batch processing structure, within a few months I would find that it was too inflexible for some new project structure I needed to use it for. So, instead, the idea is that you can write your own batch processing functions or for loops as needed to suit your data structure. Or maybe you come up with something better than I can think of, in which case, please let me add it to the package!\nWhat about machine learning approaches? Using machine learning could work, but only if you already have segmented images for use in training (which presumably you had to do by hand), and making that training set could be extremely time consuming; and the amount of modification required to get a generic algorithm to work might be unjustifiable given the size of (or variance in) your image set. This problem gets a lot worse the more images we have and the more different they are, especially if you have a lot of variance in a small dataset (pretty typical in comparative biology).\nThat said, I don\u0026rsquo;t have much background in ML of any stripe. If you have a handy idea in this area, I would love to know about it.\nJust for fun There are two fun functions in here: wernerColor and recolorizeVector.\nwernerColor remaps a recolorize object to the colors in Werner\u0026rsquo;s Nomenclature of Colors by Patrick Syme (1821), one of the first attempts at an objective color reference in western science, notably used by Charles Darwin. This is always fun to try out, especially given how many things get tagged as \u0026ldquo;veinous blood red\u0026rdquo; (delightful!):\nrc_werner \u0026lt;- wernerColor(recluster_results)  Finally, recolorizeVector converts a bitmap (i.e. pixel) image to a vector image.\nrc_vector \u0026lt;- recolorizeVector(recluster_fit, size_filter = 0.15, smoothness = 5, plotting = TRUE) # to save as an SVG: svg(filename = \u0026quot;corbett_vector.svg\u0026quot;, width = 2, height = 4) plot(rc_vector) dev.off()  This function is VERY experimental. If it gives you errors or looks too funky, try decreasing the size filter (which absorbs all components below some size to simplify the image) and the smoothness. Then again, sometimes you want things to look funky. If this is the case, recolorizeVector will happily enable you.\n","date":1618272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618349069,"objectID":"e99cbd225ad595d6a216ac0cb259f778","permalink":"/post/introduction-to-recolorize/","publishdate":"2021-04-13T00:00:00Z","relpermalink":"/post/introduction-to-recolorize/","section":"post","summary":"A copy of the recolorize introductory vignette.","tags":["recolorize","color","r packages"],"title":"Introduction to recolorize","type":"post"},{"authors":["Hannah Weller"],"categories":[],"content":"            The plotPixels function in colordistance is pretty inflexible. It was originally meant as a diagnostic tool, and the plots it produces are not exactly beautiful:\nlibrary(colordistance) # image from the 'recolorize' package (github.com/hiweller/recolorize) img \u0026lt;- system.file(\u0026quot;extdata/fulgidissima.png\u0026quot;, package = \u0026quot;recolorize\u0026quot;) # load the image: loaded_img \u0026lt;- loadImage(img) # set the plot layout for opposing pixel plots layout(matrix(1:3, nrow = 1), widths = c(0.46, 0.08, 0.46)) # plot the pixels in RGB color space from two angles: plotPixels(loaded_img) # plot the original image par(mar = rep(0, 4)) # no margin plotImage(loaded_img) # and pixels from the opposite angle: plotPixels(loaded_img, angle = -45)  These plots are certainly fine if you want to scope out the color distribution in the image, but I wouldn’t want to display them for communication: the axis text is too large and some of the tick marks overlap; the axis labels are oddly spaced; and depending on the intention of the graphic, I might not want the grid or the plot frame. The axis label thing in particular has always bothered me.\nSome of those changes are possible to make by passing additional parameters to the plotPixels function itself, but in practice, I often want more flexibility than this provides. Luckily, the function itself has such simple building blocks that it’s pretty easy to unpack them to get more customized plots.\nThis is how plotPixels works:\n It takes a dataframe of RGB colors, where pixels are rows and color channels are columns. It creates a vector of hex codes from the RGB colors to tell R which color to make each point. It uses scatterplot3d to plot in the 3D color space indicated with the color.space argument.  I chose the scatterplot3d package because, of all the 3D plotting packages, it’s the most lightweight, and more or less just extends the base plotting syntax. It was also written in 2003, so there are a lot of newer packages that provide prettier output and more options, like plot3D by Karline Soetaert, or the plotly library.\n# load the plot3D library library(plot3D) # get the RGB pixel matrix pixels \u0026lt;- loaded_img$filtered.rgb.2d # make the hex color vector using the rgb() function color_vector \u0026lt;- rgb(pixels); head(color_vector) # just a bunch of hex codes!  ## [1] \u0026quot;#247872\u0026quot; \u0026quot;#006862\u0026quot; \u0026quot;#006B62\u0026quot; \u0026quot;#00776A\u0026quot; \u0026quot;#00645C\u0026quot; \u0026quot;#007B71\u0026quot;  # use the scatter3D function scatter3D(x = pixels[ , 1], y = pixels[ , 2], z = pixels[ , 3], colvar = 1:nrow(pixels), # \u0026lt;- note we have to make a fake 'variable' to assign each pixel a different color col = color_vector, colkey = FALSE, # gets rid of the (in this case meaningless) legend xlab = \u0026quot;Red\u0026quot;, ylab = \u0026quot;Green\u0026quot;, zlab = \u0026quot;Blue\u0026quot;)  Even the default scatter3D plot looks a lot better to me: the axis labels hug the axes, and the angle is nicer. We can get fancier with a lot of the options, too:\nscatter3D(x = pixels[ , 1], y = pixels[ , 2], z = pixels[ , 3], colvar = 1:nrow(pixels), col = color_vector, colkey = F, xlab = \u0026quot;Red\u0026quot;, ylab = \u0026quot;Green\u0026quot;, zlab = \u0026quot;Blue\u0026quot;, xlim = 0:1, ylim = 0:1, zlim = 0:1, # RGB max and min pch = 19, # filled circles alpha = 0.5, # partially transparent theta = 115, phi = 25, # change viewing angle bty = \u0026quot;bl2\u0026quot;) # black grid background looks sort of cool  What if you want to plot in another color space besides RGB? The only difference is that you have to first convert your pixel matrix to a given color space, for which you have several options.\n# convert pixels to CIE Lab coordinates pixels_lab \u0026lt;- convertColor(pixels, from = \u0026quot;sRGB\u0026quot;, to = \u0026quot;Lab\u0026quot;) # color vector remains the same! color_vector \u0026lt;- rgb(pixels) scatter3D(x = pixels_lab[ , 1], y = pixels_lab[ , 2], z = pixels_lab[ , 3], colvar = 1:nrow(pixels_lab), col = color_vector, colkey = F, xlab = \u0026quot;Luminance\u0026quot;, ylab = \u0026quot;a (red-green)\u0026quot;, zlab = \u0026quot;b (yellow-blue)\u0026quot;, theta = 120, phi = -5, xlim = c(0, 100), pch = 19, # filled circles alpha = 0.5, # partially transparent bty = \u0026quot;b2\u0026quot;)  As an aside, it’s good practice to set the axis limits thoughtfully. This is easy with RGB: all three channels have a 0-1 range. With CIE Lab, this depends on your reference white. The L channel will always be 0-100, and the outer limits for the a and b channels are -127 to 128 each, but for a given reference white converting from sRGB it will be a subset within that range. The axis limits will be set to the range of the data by default, which could be misleading if you’re comparing plots of multiple images.\nIf you’d rather have an interactive plot (especially helpful for data exploration), you can use the plotly package. I find I have to implement more workarounds to get these plots to behave how I’d expect, but once you get out an interactive plot, it’s pretty slick:\nlibrary(plotly, quietly = TRUE) # let's subsample down to 100 pixels just for this example pixel_sub \u0026lt;- as.data.frame(pixels[sample(1:nrow(pixels), 100), ]) plotly_colors \u0026lt;- rgb(pixel_sub) # and plot! plot_ly(data = pixel_sub, x = ~r, y = ~g, z = ~b, type = \u0026quot;scatter3d\u0026quot;, mode = \u0026quot;markers\u0026quot;, color = I(plotly_colors), # this is a bit of a hack and you'll get a warning... colors = plotly_colors)   {\"x\":{\"visdat\":{\"948a74a44f66\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"948a74a44f66\",\"attrs\":{\"948a74a44f66\":{\"x\":{},\"y\":{},\"z\":{},\"mode\":\"markers\",\"color\":[\"#4D272F\",\"#008173\",\"#220C10\",\"#DB4042\",\"#402E2E\",\"#6A2023\",\"#342232\",\"#578900\",\"#31811C\",\"#6B813F\",\"#0092BA\",\"#4B3842\",\"#9F343D\",\"#00AD7B\",\"#52AA23\",\"#51333D\",\"#0B803A\",\"#405D44\",\"#549BC2\",\"#709200\",\"#559864\",\"#67202C\",\"#6E7600\",\"#007E3A\",\"#38A337\",\"#676A20\",\"#55423B\",\"#85C400\",\"#425F46\",\"#009D42\",\"#37833C\",\"#31AC00\",\"#539000\",\"#C43628\",\"#858F00\",\"#9B1F2C\",\"#009C3D\",\"#B9202A\",\"#50512C\",\"#8A8884\",\"#822122\",\"#329D86\",\"#6F661D\",\"#008D3B\",\"#006E45\",\"#006E7A\",\"#861A31\",\"#339000\",\"#427A0F\",\"#BBC4E1\",\"#29A234\",\"#52781E\",\"#049509\",\"#877D00\",\"#78131D\",\"#509B35\",\"#0084D4\",\"#00B27B\",\"#00697F\",\"#7D272B\",\"#44A212\",\"#BA9E00\",\"#6E303B\",\"#325E3D\",\"#288929\",\"#781E21\",\"#638B00\",\"#1A1B20\",\"#E47C00\",\"#832330\",\"#837F41\",\"#546E0D\",\"#611F22\",\"#30822C\",\"#66272E\",\"#7A770C\",\"#6E7600\",\"#3B6E3D\",\"#972931\",\"#009658\",\"#573B39\",\"#1D963C\",\"#00DCBE\",\"#4A5786\",\"#8B8E00\",\"#006A85\",\"#00852E\",\"#4E803E\",\"#006C82\",\"#00972E\",\"#009037\",\"#4C711E\",\"#531C29\",\"#0072A8\",\"#3B262B\",\"#4C9628\",\"#698A35\",\"#658300\",\"#B96612\",\"#9F5918\"],\"colors\":[\"#4D272F\",\"#008173\",\"#220C10\",\"#DB4042\",\"#402E2E\",\"#6A2023\",\"#342232\",\"#578900\",\"#31811C\",\"#6B813F\",\"#0092BA\",\"#4B3842\",\"#9F343D\",\"#00AD7B\",\"#52AA23\",\"#51333D\",\"#0B803A\",\"#405D44\",\"#549BC2\",\"#709200\",\"#559864\",\"#67202C\",\"#6E7600\",\"#007E3A\",\"#38A337\",\"#676A20\",\"#55423B\",\"#85C400\",\"#425F46\",\"#009D42\",\"#37833C\",\"#31AC00\",\"#539000\",\"#C43628\",\"#858F00\",\"#9B1F2C\",\"#009C3D\",\"#B9202A\",\"#50512C\",\"#8A8884\",\"#822122\",\"#329D86\",\"#6F661D\",\"#008D3B\",\"#006E45\",\"#006E7A\",\"#861A31\",\"#339000\",\"#427A0F\",\"#BBC4E1\",\"#29A234\",\"#52781E\",\"#049509\",\"#877D00\",\"#78131D\",\"#509B35\",\"#0084D4\",\"#00B27B\",\"#00697F\",\"#7D272B\",\"#44A212\",\"#BA9E00\",\"#6E303B\",\"#325E3D\",\"#288929\",\"#781E21\",\"#638B00\",\"#1A1B20\",\"#E47C00\",\"#832330\",\"#837F41\",\"#546E0D\",\"#611F22\",\"#30822C\",\"#66272E\",\"#7A770C\",\"#6E7600\",\"#3B6E3D\",\"#972931\",\"#009658\",\"#573B39\",\"#1D963C\",\"#00DCBE\",\"#4A5786\",\"#8B8E00\",\"#006A85\",\"#00852E\",\"#4E803E\",\"#006C82\",\"#00972E\",\"#009037\",\"#4C711E\",\"#531C29\",\"#0072A8\",\"#3B262B\",\"#4C9628\",\"#698A35\",\"#658300\",\"#B96612\",\"#9F5918\"],\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter3d\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"xaxis\":{\"title\":\"r\"},\"yaxis\":{\"title\":\"g\"},\"zaxis\":{\"title\":\"b\"}},\"hovermode\":\"closest\",\"showlegend\":false},\"source\":\"A\",\"config\":{\"showSendToCloud\":false},\"data\":[{\"x\":[0.301960784313725,0,0.133333333333333,0.858823529411765,0.250980392156863,0.415686274509804,0.203921568627451,0.341176470588235,0.192156862745098,0.419607843137255,0,0.294117647058824,0.623529411764706,0,0.32156862745098,0.317647058823529,0.0431372549019608,0.250980392156863,0.329411764705882,0.43921568627451,0.333333333333333,0.403921568627451,0.431372549019608,0,0.219607843137255,0.403921568627451,0.333333333333333,0.52156862745098,0.258823529411765,0,0.215686274509804,0.192156862745098,0.325490196078431,0.768627450980392,0.52156862745098,0.607843137254902,0,0.725490196078431,0.313725490196078,0.541176470588235,0.509803921568627,0.196078431372549,0.435294117647059,0,0,0,0.525490196078431,0.2,0.258823529411765,0.733333333333333,0.16078431372549,0.32156862745098,0.0156862745098039,0.529411764705882,0.470588235294118,0.313725490196078,0,0,0,0.490196078431373,0.266666666666667,0.729411764705882,0.431372549019608,0.196078431372549,0.156862745098039,0.470588235294118,0.388235294117647,0.101960784313725,0.894117647058824,0.513725490196078,0.513725490196078,0.329411764705882,0.380392156862745,0.188235294117647,0.4,0.47843137254902,0.431372549019608,0.231372549019608,0.592156862745098,0,0.341176470588235,0.113725490196078,0,0.290196078431373,0.545098039215686,0,0,0.305882352941176,0,0,0,0.298039215686275,0.325490196078431,0,0.231372549019608,0.298039215686275,0.411764705882353,0.396078431372549,0.725490196078431,0.623529411764706],\"y\":[0.152941176470588,0.505882352941176,0.0470588235294118,0.250980392156863,0.180392156862745,0.125490196078431,0.133333333333333,0.537254901960784,0.505882352941176,0.505882352941176,0.572549019607843,0.219607843137255,0.203921568627451,0.67843137254902,0.666666666666667,0.2,0.501960784313725,0.364705882352941,0.607843137254902,0.572549019607843,0.596078431372549,0.125490196078431,0.462745098039216,0.494117647058824,0.63921568627451,0.415686274509804,0.258823529411765,0.768627450980392,0.372549019607843,0.615686274509804,0.513725490196078,0.674509803921569,0.564705882352941,0.211764705882353,0.56078431372549,0.12156862745098,0.611764705882353,0.125490196078431,0.317647058823529,0.533333333333333,0.129411764705882,0.615686274509804,0.4,0.552941176470588,0.431372549019608,0.431372549019608,0.101960784313725,0.564705882352941,0.47843137254902,0.768627450980392,0.635294117647059,0.470588235294118,0.584313725490196,0.490196078431373,0.0745098039215686,0.607843137254902,0.517647058823529,0.698039215686274,0.411764705882353,0.152941176470588,0.635294117647059,0.619607843137255,0.188235294117647,0.368627450980392,0.537254901960784,0.117647058823529,0.545098039215686,0.105882352941176,0.486274509803922,0.137254901960784,0.498039215686275,0.431372549019608,0.12156862745098,0.509803921568627,0.152941176470588,0.466666666666667,0.462745098039216,0.431372549019608,0.16078431372549,0.588235294117647,0.231372549019608,0.588235294117647,0.862745098039216,0.341176470588235,0.556862745098039,0.415686274509804,0.52156862745098,0.501960784313725,0.423529411764706,0.592156862745098,0.564705882352941,0.443137254901961,0.109803921568627,0.447058823529412,0.149019607843137,0.588235294117647,0.541176470588235,0.513725490196078,0.4,0.349019607843137],\"z\":[0.184313725490196,0.450980392156863,0.0627450980392157,0.258823529411765,0.180392156862745,0.137254901960784,0.196078431372549,0,0.109803921568627,0.247058823529412,0.729411764705882,0.258823529411765,0.23921568627451,0.482352941176471,0.137254901960784,0.23921568627451,0.227450980392157,0.266666666666667,0.76078431372549,0,0.392156862745098,0.172549019607843,0,0.227450980392157,0.215686274509804,0.125490196078431,0.231372549019608,0,0.274509803921569,0.258823529411765,0.235294117647059,0,0,0.156862745098039,0,0.172549019607843,0.23921568627451,0.164705882352941,0.172549019607843,0.517647058823529,0.133333333333333,0.525490196078431,0.113725490196078,0.231372549019608,0.270588235294118,0.47843137254902,0.192156862745098,0,0.0588235294117647,0.882352941176471,0.203921568627451,0.117647058823529,0.0352941176470588,0,0.113725490196078,0.207843137254902,0.831372549019608,0.482352941176471,0.498039215686275,0.168627450980392,0.0705882352941176,0,0.231372549019608,0.23921568627451,0.16078431372549,0.129411764705882,0,0.125490196078431,0,0.188235294117647,0.254901960784314,0.0509803921568627,0.133333333333333,0.172549019607843,0.180392156862745,0.0470588235294118,0,0.23921568627451,0.192156862745098,0.345098039215686,0.223529411764706,0.235294117647059,0.745098039215686,0.525490196078431,0,0.52156862745098,0.180392156862745,0.243137254901961,0.509803921568627,0.180392156862745,0.215686274509804,0.117647058823529,0.16078431372549,0.658823529411765,0.168627450980392,0.156862745098039,0.207843137254902,0,0.0705882352941176,0.0941176470588235],\"mode\":\"markers\",\"type\":\"scatter3d\",\"marker\":{\"color\":[\"rgba(77,39,47,1)\",\"rgba(0,129,115,1)\",\"rgba(34,12,16,1)\",\"rgba(219,64,66,1)\",\"rgba(64,46,46,1)\",\"rgba(106,32,35,1)\",\"rgba(52,34,50,1)\",\"rgba(87,137,0,1)\",\"rgba(49,129,28,1)\",\"rgba(107,129,63,1)\",\"rgba(0,146,186,1)\",\"rgba(75,56,66,1)\",\"rgba(159,52,61,1)\",\"rgba(0,173,123,1)\",\"rgba(82,170,35,1)\",\"rgba(81,51,61,1)\",\"rgba(11,128,58,1)\",\"rgba(64,93,68,1)\",\"rgba(84,155,194,1)\",\"rgba(112,146,0,1)\",\"rgba(85,152,100,1)\",\"rgba(103,32,44,1)\",\"rgba(110,118,0,1)\",\"rgba(0,126,58,1)\",\"rgba(56,163,55,1)\",\"rgba(103,106,32,1)\",\"rgba(85,66,59,1)\",\"rgba(133,196,0,1)\",\"rgba(66,95,70,1)\",\"rgba(0,157,66,1)\",\"rgba(55,131,60,1)\",\"rgba(49,172,0,1)\",\"rgba(83,144,0,1)\",\"rgba(196,54,40,1)\",\"rgba(133,143,0,1)\",\"rgba(155,31,44,1)\",\"rgba(0,156,61,1)\",\"rgba(185,32,42,1)\",\"rgba(80,81,44,1)\",\"rgba(138,136,132,1)\",\"rgba(130,33,34,1)\",\"rgba(50,157,134,1)\",\"rgba(111,102,29,1)\",\"rgba(0,141,59,1)\",\"rgba(0,110,69,1)\",\"rgba(0,110,122,1)\",\"rgba(134,26,49,1)\",\"rgba(51,144,0,1)\",\"rgba(66,122,15,1)\",\"rgba(187,196,225,1)\",\"rgba(41,162,52,1)\",\"rgba(82,120,30,1)\",\"rgba(4,149,9,1)\",\"rgba(135,125,0,1)\",\"rgba(120,19,29,1)\",\"rgba(80,155,53,1)\",\"rgba(0,132,212,1)\",\"rgba(0,178,123,1)\",\"rgba(0,105,127,1)\",\"rgba(125,39,43,1)\",\"rgba(68,162,18,1)\",\"rgba(186,158,0,1)\",\"rgba(110,48,59,1)\",\"rgba(50,94,61,1)\",\"rgba(40,137,41,1)\",\"rgba(120,30,33,1)\",\"rgba(99,139,0,1)\",\"rgba(26,27,32,1)\",\"rgba(228,124,0,1)\",\"rgba(131,35,48,1)\",\"rgba(131,127,65,1)\",\"rgba(84,110,13,1)\",\"rgba(97,31,34,1)\",\"rgba(48,130,44,1)\",\"rgba(102,39,46,1)\",\"rgba(122,119,12,1)\",\"rgba(110,118,0,1)\",\"rgba(59,110,61,1)\",\"rgba(151,41,49,1)\",\"rgba(0,150,88,1)\",\"rgba(87,59,57,1)\",\"rgba(29,150,60,1)\",\"rgba(0,220,190,1)\",\"rgba(74,87,134,1)\",\"rgba(139,142,0,1)\",\"rgba(0,106,133,1)\",\"rgba(0,133,46,1)\",\"rgba(78,128,62,1)\",\"rgba(0,108,130,1)\",\"rgba(0,151,46,1)\",\"rgba(0,144,55,1)\",\"rgba(76,113,30,1)\",\"rgba(83,28,41,1)\",\"rgba(0,114,168,1)\",\"rgba(59,38,43,1)\",\"rgba(76,150,40,1)\",\"rgba(105,138,53,1)\",\"rgba(101,131,0,1)\",\"rgba(185,102,18,1)\",\"rgba(159,89,24,1)\"],\"line\":{\"color\":[\"rgba(77,39,47,1)\",\"rgba(0,129,115,1)\",\"rgba(34,12,16,1)\",\"rgba(219,64,66,1)\",\"rgba(64,46,46,1)\",\"rgba(106,32,35,1)\",\"rgba(52,34,50,1)\",\"rgba(87,137,0,1)\",\"rgba(49,129,28,1)\",\"rgba(107,129,63,1)\",\"rgba(0,146,186,1)\",\"rgba(75,56,66,1)\",\"rgba(159,52,61,1)\",\"rgba(0,173,123,1)\",\"rgba(82,170,35,1)\",\"rgba(81,51,61,1)\",\"rgba(11,128,58,1)\",\"rgba(64,93,68,1)\",\"rgba(84,155,194,1)\",\"rgba(112,146,0,1)\",\"rgba(85,152,100,1)\",\"rgba(103,32,44,1)\",\"rgba(110,118,0,1)\",\"rgba(0,126,58,1)\",\"rgba(56,163,55,1)\",\"rgba(103,106,32,1)\",\"rgba(85,66,59,1)\",\"rgba(133,196,0,1)\",\"rgba(66,95,70,1)\",\"rgba(0,157,66,1)\",\"rgba(55,131,60,1)\",\"rgba(49,172,0,1)\",\"rgba(83,144,0,1)\",\"rgba(196,54,40,1)\",\"rgba(133,143,0,1)\",\"rgba(155,31,44,1)\",\"rgba(0,156,61,1)\",\"rgba(185,32,42,1)\",\"rgba(80,81,44,1)\",\"rgba(138,136,132,1)\",\"rgba(130,33,34,1)\",\"rgba(50,157,134,1)\",\"rgba(111,102,29,1)\",\"rgba(0,141,59,1)\",\"rgba(0,110,69,1)\",\"rgba(0,110,122,1)\",\"rgba(134,26,49,1)\",\"rgba(51,144,0,1)\",\"rgba(66,122,15,1)\",\"rgba(187,196,225,1)\",\"rgba(41,162,52,1)\",\"rgba(82,120,30,1)\",\"rgba(4,149,9,1)\",\"rgba(135,125,0,1)\",\"rgba(120,19,29,1)\",\"rgba(80,155,53,1)\",\"rgba(0,132,212,1)\",\"rgba(0,178,123,1)\",\"rgba(0,105,127,1)\",\"rgba(125,39,43,1)\",\"rgba(68,162,18,1)\",\"rgba(186,158,0,1)\",\"rgba(110,48,59,1)\",\"rgba(50,94,61,1)\",\"rgba(40,137,41,1)\",\"rgba(120,30,33,1)\",\"rgba(99,139,0,1)\",\"rgba(26,27,32,1)\",\"rgba(228,124,0,1)\",\"rgba(131,35,48,1)\",\"rgba(131,127,65,1)\",\"rgba(84,110,13,1)\",\"rgba(97,31,34,1)\",\"rgba(48,130,44,1)\",\"rgba(102,39,46,1)\",\"rgba(122,119,12,1)\",\"rgba(110,118,0,1)\",\"rgba(59,110,61,1)\",\"rgba(151,41,49,1)\",\"rgba(0,150,88,1)\",\"rgba(87,59,57,1)\",\"rgba(29,150,60,1)\",\"rgba(0,220,190,1)\",\"rgba(74,87,134,1)\",\"rgba(139,142,0,1)\",\"rgba(0,106,133,1)\",\"rgba(0,133,46,1)\",\"rgba(78,128,62,1)\",\"rgba(0,108,130,1)\",\"rgba(0,151,46,1)\",\"rgba(0,144,55,1)\",\"rgba(76,113,30,1)\",\"rgba(83,28,41,1)\",\"rgba(0,114,168,1)\",\"rgba(59,38,43,1)\",\"rgba(76,150,40,1)\",\"rgba(105,138,53,1)\",\"rgba(101,131,0,1)\",\"rgba(185,102,18,1)\",\"rgba(159,89,24,1)\"]}},\"textfont\":{\"color\":[\"rgba(77,39,47,1)\",\"rgba(0,129,115,1)\",\"rgba(34,12,16,1)\",\"rgba(219,64,66,1)\",\"rgba(64,46,46,1)\",\"rgba(106,32,35,1)\",\"rgba(52,34,50,1)\",\"rgba(87,137,0,1)\",\"rgba(49,129,28,1)\",\"rgba(107,129,63,1)\",\"rgba(0,146,186,1)\",\"rgba(75,56,66,1)\",\"rgba(159,52,61,1)\",\"rgba(0,173,123,1)\",\"rgba(82,170,35,1)\",\"rgba(81,51,61,1)\",\"rgba(11,128,58,1)\",\"rgba(64,93,68,1)\",\"rgba(84,155,194,1)\",\"rgba(112,146,0,1)\",\"rgba(85,152,100,1)\",\"rgba(103,32,44,1)\",\"rgba(110,118,0,1)\",\"rgba(0,126,58,1)\",\"rgba(56,163,55,1)\",\"rgba(103,106,32,1)\",\"rgba(85,66,59,1)\",\"rgba(133,196,0,1)\",\"rgba(66,95,70,1)\",\"rgba(0,157,66,1)\",\"rgba(55,131,60,1)\",\"rgba(49,172,0,1)\",\"rgba(83,144,0,1)\",\"rgba(196,54,40,1)\",\"rgba(133,143,0,1)\",\"rgba(155,31,44,1)\",\"rgba(0,156,61,1)\",\"rgba(185,32,42,1)\",\"rgba(80,81,44,1)\",\"rgba(138,136,132,1)\",\"rgba(130,33,34,1)\",\"rgba(50,157,134,1)\",\"rgba(111,102,29,1)\",\"rgba(0,141,59,1)\",\"rgba(0,110,69,1)\",\"rgba(0,110,122,1)\",\"rgba(134,26,49,1)\",\"rgba(51,144,0,1)\",\"rgba(66,122,15,1)\",\"rgba(187,196,225,1)\",\"rgba(41,162,52,1)\",\"rgba(82,120,30,1)\",\"rgba(4,149,9,1)\",\"rgba(135,125,0,1)\",\"rgba(120,19,29,1)\",\"rgba(80,155,53,1)\",\"rgba(0,132,212,1)\",\"rgba(0,178,123,1)\",\"rgba(0,105,127,1)\",\"rgba(125,39,43,1)\",\"rgba(68,162,18,1)\",\"rgba(186,158,0,1)\",\"rgba(110,48,59,1)\",\"rgba(50,94,61,1)\",\"rgba(40,137,41,1)\",\"rgba(120,30,33,1)\",\"rgba(99,139,0,1)\",\"rgba(26,27,32,1)\",\"rgba(228,124,0,1)\",\"rgba(131,35,48,1)\",\"rgba(131,127,65,1)\",\"rgba(84,110,13,1)\",\"rgba(97,31,34,1)\",\"rgba(48,130,44,1)\",\"rgba(102,39,46,1)\",\"rgba(122,119,12,1)\",\"rgba(110,118,0,1)\",\"rgba(59,110,61,1)\",\"rgba(151,41,49,1)\",\"rgba(0,150,88,1)\",\"rgba(87,59,57,1)\",\"rgba(29,150,60,1)\",\"rgba(0,220,190,1)\",\"rgba(74,87,134,1)\",\"rgba(139,142,0,1)\",\"rgba(0,106,133,1)\",\"rgba(0,133,46,1)\",\"rgba(78,128,62,1)\",\"rgba(0,108,130,1)\",\"rgba(0,151,46,1)\",\"rgba(0,144,55,1)\",\"rgba(76,113,30,1)\",\"rgba(83,28,41,1)\",\"rgba(0,114,168,1)\",\"rgba(59,38,43,1)\",\"rgba(76,150,40,1)\",\"rgba(105,138,53,1)\",\"rgba(101,131,0,1)\",\"rgba(185,102,18,1)\",\"rgba(159,89,24,1)\"]},\"line\":{\"color\":[\"rgba(77,39,47,1)\",\"rgba(0,129,115,1)\",\"rgba(34,12,16,1)\",\"rgba(219,64,66,1)\",\"rgba(64,46,46,1)\",\"rgba(106,32,35,1)\",\"rgba(52,34,50,1)\",\"rgba(87,137,0,1)\",\"rgba(49,129,28,1)\",\"rgba(107,129,63,1)\",\"rgba(0,146,186,1)\",\"rgba(75,56,66,1)\",\"rgba(159,52,61,1)\",\"rgba(0,173,123,1)\",\"rgba(82,170,35,1)\",\"rgba(81,51,61,1)\",\"rgba(11,128,58,1)\",\"rgba(64,93,68,1)\",\"rgba(84,155,194,1)\",\"rgba(112,146,0,1)\",\"rgba(85,152,100,1)\",\"rgba(103,32,44,1)\",\"rgba(110,118,0,1)\",\"rgba(0,126,58,1)\",\"rgba(56,163,55,1)\",\"rgba(103,106,32,1)\",\"rgba(85,66,59,1)\",\"rgba(133,196,0,1)\",\"rgba(66,95,70,1)\",\"rgba(0,157,66,1)\",\"rgba(55,131,60,1)\",\"rgba(49,172,0,1)\",\"rgba(83,144,0,1)\",\"rgba(196,54,40,1)\",\"rgba(133,143,0,1)\",\"rgba(155,31,44,1)\",\"rgba(0,156,61,1)\",\"rgba(185,32,42,1)\",\"rgba(80,81,44,1)\",\"rgba(138,136,132,1)\",\"rgba(130,33,34,1)\",\"rgba(50,157,134,1)\",\"rgba(111,102,29,1)\",\"rgba(0,141,59,1)\",\"rgba(0,110,69,1)\",\"rgba(0,110,122,1)\",\"rgba(134,26,49,1)\",\"rgba(51,144,0,1)\",\"rgba(66,122,15,1)\",\"rgba(187,196,225,1)\",\"rgba(41,162,52,1)\",\"rgba(82,120,30,1)\",\"rgba(4,149,9,1)\",\"rgba(135,125,0,1)\",\"rgba(120,19,29,1)\",\"rgba(80,155,53,1)\",\"rgba(0,132,212,1)\",\"rgba(0,178,123,1)\",\"rgba(0,105,127,1)\",\"rgba(125,39,43,1)\",\"rgba(68,162,18,1)\",\"rgba(186,158,0,1)\",\"rgba(110,48,59,1)\",\"rgba(50,94,61,1)\",\"rgba(40,137,41,1)\",\"rgba(120,30,33,1)\",\"rgba(99,139,0,1)\",\"rgba(26,27,32,1)\",\"rgba(228,124,0,1)\",\"rgba(131,35,48,1)\",\"rgba(131,127,65,1)\",\"rgba(84,110,13,1)\",\"rgba(97,31,34,1)\",\"rgba(48,130,44,1)\",\"rgba(102,39,46,1)\",\"rgba(122,119,12,1)\",\"rgba(110,118,0,1)\",\"rgba(59,110,61,1)\",\"rgba(151,41,49,1)\",\"rgba(0,150,88,1)\",\"rgba(87,59,57,1)\",\"rgba(29,150,60,1)\",\"rgba(0,220,190,1)\",\"rgba(74,87,134,1)\",\"rgba(139,142,0,1)\",\"rgba(0,106,133,1)\",\"rgba(0,133,46,1)\",\"rgba(78,128,62,1)\",\"rgba(0,108,130,1)\",\"rgba(0,151,46,1)\",\"rgba(0,144,55,1)\",\"rgba(76,113,30,1)\",\"rgba(83,28,41,1)\",\"rgba(0,114,168,1)\",\"rgba(59,38,43,1)\",\"rgba(76,150,40,1)\",\"rgba(105,138,53,1)\",\"rgba(101,131,0,1)\",\"rgba(185,102,18,1)\",\"rgba(159,89,24,1)\"]},\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]} If you play around with this enough, you’ll realize that plotting all of your 3D data on a plot as individual points is kind of cumbersome when you have thousands of points; you can’t really tell which regions of your color space are more or less dense. It may better suit your purposes to cluster the data a bit first, and then plot the clusters:\nclusters \u0026lt;- extractClusters(getKMeanColors(img, color.space = \u0026quot;Lab\u0026quot;, ref.white = \u0026quot;D65\u0026quot;, n = 50, plotting = F)) colnames(clusters) \u0026lt;- c(\u0026quot;L\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;Pct\u0026quot;) # We can do this with a colordistance function... scatter3dclusters(clusters, color.space = \u0026quot;lab\u0026quot;, scaling = 100)  # we can also use scatter3D, with a bit of a hack to get different point sizes col_vector \u0026lt;- rgb(convertColor(clusters[ , 1:3], from = \u0026quot;Lab\u0026quot;, to = \u0026quot;sRGB\u0026quot;)) # make blank plot scatter3D(clusters$L, clusters$a, clusters$b, cex = 0, colkey = F, phi = 35, theta = 60, xlab = \u0026quot;L\u0026quot;, ylab = \u0026quot;a\u0026quot;, zlab = \u0026quot;b\u0026quot;) # set scale multiplier for point sizes scale \u0026lt;- 80 # add one point at a time, setting size with the cex argument for (i in 1:nrow(clusters)) { scatter3D(x = clusters$L[i], y = clusters$a[i], z = clusters$b[i], cex = clusters$Pct[i] * scale, pch = 19, alpha = 0.5, col = col_vector[i], add = TRUE) }  # or, we can just use plotly again plot_ly(data = clusters, x = ~L, y = ~a, z = ~b, type = \u0026quot;scatter3d\u0026quot;, mode = \u0026quot;markers\u0026quot;, color = I(col_vector), # this is a bit of a hack and you'll get a warning... colors = col_vector, size = ~Pct)   {\"x\":{\"visdat\":{\"948a2bab3c7f\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"948a2bab3c7f\",\"attrs\":{\"948a2bab3c7f\":{\"x\":{},\"y\":{},\"z\":{},\"mode\":\"markers\",\"color\":[\"#647933\",\"#732429\",\"#986516\",\"#832128\",\"#232023\",\"#138233\",\"#943E1F\",\"#17AEAB\",\"#0C8864\",\"#499535\",\"#384D39\",\"#573F3B\",\"#9F8008\",\"#047579\",\"#077C6D\",\"#108DB0\",\"#BA2E2C\",\"#06667C\",\"#0DD7B4\",\"#86B20D\",\"#8B8784\",\"#5F780B\",\"#766D2A\",\"#C06012\",\"#1860A9\",\"#62512B\",\"#B1A206\",\"#545D2C\",\"#37CA7A\",\"#22587E\",\"#3A9610\",\"#55BC26\",\"#66242C\",\"#473037\",\"#C34622\",\"#038E51\",\"#1EA43A\",\"#C17C08\",\"#4B8407\",\"#10753B\",\"#758F07\",\"#15AA7C\",\"#265F37\",\"#7E1C32\",\"#119846\",\"#9C212B\",\"#898609\",\"#582531\",\"#5E9706\",\"#3F7624\"],\"size\":{},\"colors\":[\"#647933\",\"#732429\",\"#986516\",\"#832128\",\"#232023\",\"#138233\",\"#943E1F\",\"#17AEAB\",\"#0C8864\",\"#499535\",\"#384D39\",\"#573F3B\",\"#9F8008\",\"#047579\",\"#077C6D\",\"#108DB0\",\"#BA2E2C\",\"#06667C\",\"#0DD7B4\",\"#86B20D\",\"#8B8784\",\"#5F780B\",\"#766D2A\",\"#C06012\",\"#1860A9\",\"#62512B\",\"#B1A206\",\"#545D2C\",\"#37CA7A\",\"#22587E\",\"#3A9610\",\"#55BC26\",\"#66242C\",\"#473037\",\"#C34622\",\"#038E51\",\"#1EA43A\",\"#C17C08\",\"#4B8407\",\"#10753B\",\"#758F07\",\"#15AA7C\",\"#265F37\",\"#7E1C32\",\"#119846\",\"#9C212B\",\"#898609\",\"#582531\",\"#5E9706\",\"#3F7624\"],\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter3d\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"xaxis\":{\"title\":\"L\"},\"yaxis\":{\"title\":\"a\"},\"zaxis\":{\"title\":\"b\"}},\"hovermode\":\"closest\",\"showlegend\":false},\"source\":\"A\",\"config\":{\"showSendToCloud\":false},\"data\":[{\"x\":[47.6470370380395,26.9343668030093,47.1828825841296,29.6773078450699,12.7045820506114,47.424072153912,37.7095435680787,64.3966358719047,50.2170710701797,55.2008575013163,30.5639393862333,29.2352057210328,54.8739847444633,44.21651687503,46.4348311991777,54.3461739170174,42.2864967235475,39.4002815788575,77.246141494701,67.3417368584501,56.4821125357197,46.7293021620499,45.4986153446182,51.5290761538363,40.1338361320406,35.3775725076101,65.7951807953912,37.6049924843794,72.5005589738049,35.5332956130365,54.909869921715,68.0826258130497,24.7407170414244,22.5787090735333,47.2231676738661,51.6978881209399,58.9315019517576,57.9255190148564,49.6384118056201,42.7699221303017,55.5967406937468,61.8862757522115,35.7827664244431,28.3085165518734,55.1722752062099,34.8245048991748,54.4721552035387,22.5158972154844,56.5773369142028,44.269889046976],\"y\":[-19.1560055874448,35.1558839259183,14.2720406280373,41.9759780318741,2.27151473468494,-46.9672270333645,34.3138626384862,-36.1794957895637,-40.2015036246707,-42.360763899665,-13.1006131883921,9.63830700679229,2.01930745644207,-25.3929355968667,-32.9400403387384,-18.7144718129058,55.1505786880039,-16.2512192026847,-52.1150378079515,-35.0058101398964,1.02962325971967,-23.1977287309345,-5.20162909915775,34.3707882925485,6.26556465863796,1.71232485126426,-8.39391101221517,-11.537025012239,-56.2902446947673,-4.37777177199427,-49.6422187683071,-55.1756294819106,30.2241914435395,11.7955865367038,48.1326705218909,-47.3050354036041,-56.1539990811367,19.1817983458343,-37.485801469206,-41.0176083687218,-25.7079300352572,-47.2926881095034,-28.8228745220873,42.6000075381491,-52.123231334113,50.0622436786647,-11.744290691161,24.877420489759,-38.5316644028869,-33.7940092938693],\"z\":[35.0345104570875,15.8418904092597,48.9346846157969,20.9249840908074,-1.78570914036779,33.9657948063168,36.0165415746418,-9.12817187084792,10.7727716382048,42.0852089437363,9.12095630563548,6.53578709802711,58.7122851209248,-10.4896224844523,0.31534768082993,-27.1244338341843,35.7715089466191,-19.564988924393,5.09492563363152,66.8339063421687,1.77215759159408,49.418203672323,37.6199540518151,55.9747127260182,-45.4109435932669,24.7964325796627,67.9103022988535,26.7723537600718,28.8802186644586,-26.5501909597621,54.4569417630617,61.1975442753346,10.9134354860685,-0.242929238594548,46.7112900443923,23.6139098568036,43.9314187088593,62.7749914938315,51.9201408757226,24.0782770255091,57.8980119441862,13.286134167394,17.2635276892329,12.5309090043427,33.8323009989432,26.1273787908098,57.374791997851,4.05616250233049,58.1589172091652,37.9475390129431],\"mode\":\"markers\",\"type\":\"scatter3d\",\"marker\":{\"color\":[\"rgba(100,121,51,1)\",\"rgba(115,36,41,1)\",\"rgba(152,101,22,1)\",\"rgba(131,33,40,1)\",\"rgba(35,32,35,1)\",\"rgba(19,130,51,1)\",\"rgba(148,62,31,1)\",\"rgba(23,174,171,1)\",\"rgba(12,136,100,1)\",\"rgba(73,149,53,1)\",\"rgba(56,77,57,1)\",\"rgba(87,63,59,1)\",\"rgba(159,128,8,1)\",\"rgba(4,117,121,1)\",\"rgba(7,124,109,1)\",\"rgba(16,141,176,1)\",\"rgba(186,46,44,1)\",\"rgba(6,102,124,1)\",\"rgba(13,215,180,1)\",\"rgba(134,178,13,1)\",\"rgba(139,135,132,1)\",\"rgba(95,120,11,1)\",\"rgba(118,109,42,1)\",\"rgba(192,96,18,1)\",\"rgba(24,96,169,1)\",\"rgba(98,81,43,1)\",\"rgba(177,162,6,1)\",\"rgba(84,93,44,1)\",\"rgba(55,202,122,1)\",\"rgba(34,88,126,1)\",\"rgba(58,150,16,1)\",\"rgba(85,188,38,1)\",\"rgba(102,36,44,1)\",\"rgba(71,48,55,1)\",\"rgba(195,70,34,1)\",\"rgba(3,142,81,1)\",\"rgba(30,164,58,1)\",\"rgba(193,124,8,1)\",\"rgba(75,132,7,1)\",\"rgba(16,117,59,1)\",\"rgba(117,143,7,1)\",\"rgba(21,170,124,1)\",\"rgba(38,95,55,1)\",\"rgba(126,28,50,1)\",\"rgba(17,152,70,1)\",\"rgba(156,33,43,1)\",\"rgba(137,134,9,1)\",\"rgba(88,37,49,1)\",\"rgba(94,151,6,1)\",\"rgba(63,118,36,1)\"],\"size\":[55.8780487804878,100,19.8780487804878,68.609756097561,46.8780487804878,56.0975609756098,24.2682926829268,18.5609756097561,57.1951219512195,52.1463414634146,31.5121951219512,50.390243902439,39.6341463414634,60.2682926829268,56.7560975609756,10.6585365853659,48.4146341463415,61.3658536585366,13.5121951219512,21.4146341463415,17.2439024390244,54.5609756097561,50.1707317073171,34.8048780487805,10,33.2682926829268,18.1219512195122,53.2439024390244,11.7560975609756,28.4390243902439,74.3170731707317,24.4878048780488,83.3170731707317,67.9512195121951,42.4878048780488,70.3658536585366,56.5365853658537,26.9024390243902,74.9756097560976,40.9512195121951,59.609756097561,19.4390243902439,29.0975609756098,32.390243902439,75.4146341463415,60.7073170731707,51.0487804878049,49.7317073170732,55.219512195122,52.5853658536585],\"sizemode\":\"area\",\"line\":{\"color\":[\"rgba(100,121,51,1)\",\"rgba(115,36,41,1)\",\"rgba(152,101,22,1)\",\"rgba(131,33,40,1)\",\"rgba(35,32,35,1)\",\"rgba(19,130,51,1)\",\"rgba(148,62,31,1)\",\"rgba(23,174,171,1)\",\"rgba(12,136,100,1)\",\"rgba(73,149,53,1)\",\"rgba(56,77,57,1)\",\"rgba(87,63,59,1)\",\"rgba(159,128,8,1)\",\"rgba(4,117,121,1)\",\"rgba(7,124,109,1)\",\"rgba(16,141,176,1)\",\"rgba(186,46,44,1)\",\"rgba(6,102,124,1)\",\"rgba(13,215,180,1)\",\"rgba(134,178,13,1)\",\"rgba(139,135,132,1)\",\"rgba(95,120,11,1)\",\"rgba(118,109,42,1)\",\"rgba(192,96,18,1)\",\"rgba(24,96,169,1)\",\"rgba(98,81,43,1)\",\"rgba(177,162,6,1)\",\"rgba(84,93,44,1)\",\"rgba(55,202,122,1)\",\"rgba(34,88,126,1)\",\"rgba(58,150,16,1)\",\"rgba(85,188,38,1)\",\"rgba(102,36,44,1)\",\"rgba(71,48,55,1)\",\"rgba(195,70,34,1)\",\"rgba(3,142,81,1)\",\"rgba(30,164,58,1)\",\"rgba(193,124,8,1)\",\"rgba(75,132,7,1)\",\"rgba(16,117,59,1)\",\"rgba(117,143,7,1)\",\"rgba(21,170,124,1)\",\"rgba(38,95,55,1)\",\"rgba(126,28,50,1)\",\"rgba(17,152,70,1)\",\"rgba(156,33,43,1)\",\"rgba(137,134,9,1)\",\"rgba(88,37,49,1)\",\"rgba(94,151,6,1)\",\"rgba(63,118,36,1)\"]}},\"textfont\":{\"color\":[\"rgba(100,121,51,1)\",\"rgba(115,36,41,1)\",\"rgba(152,101,22,1)\",\"rgba(131,33,40,1)\",\"rgba(35,32,35,1)\",\"rgba(19,130,51,1)\",\"rgba(148,62,31,1)\",\"rgba(23,174,171,1)\",\"rgba(12,136,100,1)\",\"rgba(73,149,53,1)\",\"rgba(56,77,57,1)\",\"rgba(87,63,59,1)\",\"rgba(159,128,8,1)\",\"rgba(4,117,121,1)\",\"rgba(7,124,109,1)\",\"rgba(16,141,176,1)\",\"rgba(186,46,44,1)\",\"rgba(6,102,124,1)\",\"rgba(13,215,180,1)\",\"rgba(134,178,13,1)\",\"rgba(139,135,132,1)\",\"rgba(95,120,11,1)\",\"rgba(118,109,42,1)\",\"rgba(192,96,18,1)\",\"rgba(24,96,169,1)\",\"rgba(98,81,43,1)\",\"rgba(177,162,6,1)\",\"rgba(84,93,44,1)\",\"rgba(55,202,122,1)\",\"rgba(34,88,126,1)\",\"rgba(58,150,16,1)\",\"rgba(85,188,38,1)\",\"rgba(102,36,44,1)\",\"rgba(71,48,55,1)\",\"rgba(195,70,34,1)\",\"rgba(3,142,81,1)\",\"rgba(30,164,58,1)\",\"rgba(193,124,8,1)\",\"rgba(75,132,7,1)\",\"rgba(16,117,59,1)\",\"rgba(117,143,7,1)\",\"rgba(21,170,124,1)\",\"rgba(38,95,55,1)\",\"rgba(126,28,50,1)\",\"rgba(17,152,70,1)\",\"rgba(156,33,43,1)\",\"rgba(137,134,9,1)\",\"rgba(88,37,49,1)\",\"rgba(94,151,6,1)\",\"rgba(63,118,36,1)\"],\"size\":[55.8780487804878,100,19.8780487804878,68.609756097561,46.8780487804878,56.0975609756098,24.2682926829268,18.5609756097561,57.1951219512195,52.1463414634146,31.5121951219512,50.390243902439,39.6341463414634,60.2682926829268,56.7560975609756,10.6585365853659,48.4146341463415,61.3658536585366,13.5121951219512,21.4146341463415,17.2439024390244,54.5609756097561,50.1707317073171,34.8048780487805,10,33.2682926829268,18.1219512195122,53.2439024390244,11.7560975609756,28.4390243902439,74.3170731707317,24.4878048780488,83.3170731707317,67.9512195121951,42.4878048780488,70.3658536585366,56.5365853658537,26.9024390243902,74.9756097560976,40.9512195121951,59.609756097561,19.4390243902439,29.0975609756098,32.390243902439,75.4146341463415,60.7073170731707,51.0487804878049,49.7317073170732,55.219512195122,52.5853658536585]},\"error_y\":{\"width\":[]},\"error_x\":{\"width\":[]},\"line\":{\"color\":[\"rgba(100,121,51,1)\",\"rgba(115,36,41,1)\",\"rgba(152,101,22,1)\",\"rgba(131,33,40,1)\",\"rgba(35,32,35,1)\",\"rgba(19,130,51,1)\",\"rgba(148,62,31,1)\",\"rgba(23,174,171,1)\",\"rgba(12,136,100,1)\",\"rgba(73,149,53,1)\",\"rgba(56,77,57,1)\",\"rgba(87,63,59,1)\",\"rgba(159,128,8,1)\",\"rgba(4,117,121,1)\",\"rgba(7,124,109,1)\",\"rgba(16,141,176,1)\",\"rgba(186,46,44,1)\",\"rgba(6,102,124,1)\",\"rgba(13,215,180,1)\",\"rgba(134,178,13,1)\",\"rgba(139,135,132,1)\",\"rgba(95,120,11,1)\",\"rgba(118,109,42,1)\",\"rgba(192,96,18,1)\",\"rgba(24,96,169,1)\",\"rgba(98,81,43,1)\",\"rgba(177,162,6,1)\",\"rgba(84,93,44,1)\",\"rgba(55,202,122,1)\",\"rgba(34,88,126,1)\",\"rgba(58,150,16,1)\",\"rgba(85,188,38,1)\",\"rgba(102,36,44,1)\",\"rgba(71,48,55,1)\",\"rgba(195,70,34,1)\",\"rgba(3,142,81,1)\",\"rgba(30,164,58,1)\",\"rgba(193,124,8,1)\",\"rgba(75,132,7,1)\",\"rgba(16,117,59,1)\",\"rgba(117,143,7,1)\",\"rgba(21,170,124,1)\",\"rgba(38,95,55,1)\",\"rgba(126,28,50,1)\",\"rgba(17,152,70,1)\",\"rgba(156,33,43,1)\",\"rgba(137,134,9,1)\",\"rgba(88,37,49,1)\",\"rgba(94,151,6,1)\",\"rgba(63,118,36,1)\"]},\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]} ","date":1618272000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618329969,"objectID":"5354f59d6f9387f598b2da8cfa7e773f","permalink":"/post/modifying-pixel-plots/","publishdate":"2021-04-13T00:00:00Z","relpermalink":"/post/modifying-pixel-plots/","section":"post","summary":"How to make prettier, more flexible plots of pixels in color space.","tags":["colordistance","color","r packages","plotting"],"title":"Modifying pixel plots","type":"post"},{"authors":null,"categories":null,"content":"What I\u0026rsquo;m working on these days The evolution of mouthbrooding in fishes Right now I\u0026rsquo;m studying the evolution of mouthbrooding (a kind of parental care where parents incubate offspring in their mouths), and how much feeding phenotypes influence that evolution. I think that mouthbrooding is a beautiful example of an extraordinary behavior (using a mouth as a nursery!) that arises from co-opting existing traits. Specifically, it seems like mouthbrooding is more likely to evolve in species whose feeding adaptations already make them good at mouthbrooding. And the further I dive into the whys and hows, the more I appreciate how much this behavior seems to be the result of the interplay of morphology, behavior, and environment. I have a somewhat out-there idea for why only some fishes in a given environemtn will evolve mouthbrooding, and it\u0026rsquo;s what I\u0026rsquo;m testing now.\nMore here.\nColor analysis software I also work a lot on color pattern evolution, and have written a few R packages to make that easier for myself and others. I think that accessible, objective tools for color pattern research are an important part of making sure we\u0026rsquo;re being careful with the conclusions we draw about how much color matters to other living things. Current projects include:\n  recolorize, an R package for color segmentation, which integrates with the pavo and patternize packages as well as providing a variety of other output formats (vectorized images, individual layers, masks). More here.\n  colordistance, an R package for comparing images by quantitative color similarity:\n  More here.\nCollaborations I\u0026rsquo;m lucky to have really delightful spread of collaborations with researchers at other universities, including:\n UV in snakes (University of Michigan, Davis-Rabosky lab) The origin and diversity of color jewel beetles (Louisiana State University, Lord lab) Population structure and color variation in brook trout (Pennsylvania State University) The effect of mouthbrooding on the rate of craniofacial evolution (Clemson, Price lab)  ","date":1616889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616889600,"objectID":"9ecfcf41a6071b7ae32bf44d8216e251","permalink":"/currently/","publishdate":"2021-03-28T00:00:00Z","relpermalink":"/currently/","section":"","summary":"What I'm working on now.","tags":null,"title":"","type":"page"},{"authors":["Hannah Weller","Shawn Schwartz","Elizabeth Karan","Nathan Lord"],"categories":["recolorize"],"content":"","date":1609549043,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609549043,"objectID":"c13b3f41024280092a23fac589b9a9a2","permalink":"/publication/sicb-2021/","publishdate":"2021-04-18T20:57:23-04:00","relpermalink":"/publication/sicb-2021/","section":"publication","summary":"Demo of recolorize, a package for color segmentation.","tags":["recolorize","color","r packages","beetles"],"title":"Recolorize: Color-based image segmentation (for people with other things to do)","type":"publication"},{"authors":["Hannah Weller","Aaron Olsen","Ariel Camp","Armita Manafzadeh","L. Patricia Hernandez","Elizabeth Brainerd"],"categories":["fish"],"content":"","date":1591053517,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591053517,"objectID":"dd96ea6ddf5cfd0e511328ac62f3a1df","permalink":"/publication/catfish/","publishdate":"2021-04-18T19:18:37-04:00","relpermalink":"/publication/catfish/","section":"publication","summary":"We don't know how fish swallow food, but we do know they regularly swallow things half their own size (or more). We used biplanar X-ray video to track swallowing in 3D in catfishes.","tags":["biomechanics","kinematics","fish"],"title":"An XROMM Study of Food Transport and Swallowing in Channel Catfish","type":"publication"},{"authors":null,"categories":null,"content":"A package for implementing distance metrics to quantify color diversity across images. This is done by binning pixels by color using either data-dependent or automatically generated color bins, quantitatively measuring color similarity among images using one of several distance metrics for comparing pixel color clusters, and clustering images by object color similarity. Uses CIE Lab, RGB, or HSV color spaces. Originally written for use with organism coloration (reef fish color diversity, butterfly mimicry, etc), but easily applicable for any image set.\n","date":1587945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587945600,"objectID":"e915fe00a55f8980c91cd319f0a77a5e","permalink":"/project/colordistance/","publishdate":"2020-04-27T00:00:00Z","relpermalink":"/project/colordistance/","section":"project","summary":"An R package for quantitative color comparisons.","tags":["color","r packages","colordistance"],"title":"colordistance","type":"project"},{"authors":null,"categories":null,"content":"This is a package for making color maps, which are needed (or at least useful) for a wide range of color analysis techniques. It was born out of conversations with many biologists who found, to their surprise and mine, that generating color maps was the bottleneck step in their analyses. Fully automated methods rarely work all of the time, and are difficult to modify, while fully manual methods are subjective and time-consuming. This package tries to split the difference by giving you a mix of tools that will do a pretty good job with no user input, and then allow minor manual changes like merging and filtering layers or splitting components, before exporting them to the next step of your analysis. It\u0026rsquo;s also, for the most part, totally deterministic – no arbitrary seed-setting for repeatability.\n","date":1587945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587945600,"objectID":"9cbda19e8c9aaff8e9b1f81e512f9ab0","permalink":"/project/recolorize/","publishdate":"2020-04-27T00:00:00Z","relpermalink":"/project/recolorize/","section":"project","summary":"An R package for automatic, semi-automatic, and manual color segmentation.","tags":["color","r packages","recolorize"],"title":"recolorize","type":"project"},{"authors":["Sarah Hooper","Hannah Weller","Sybill Amelon"],"categories":["colordistance"],"content":"","date":1580600174,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580600174,"objectID":"3a79822c819304e389a46807df113406","permalink":"/publication/countcolors/","publishdate":"2021-04-18T19:36:14-04:00","relpermalink":"/publication/countcolors/","section":"publication","summary":"An R package for calculating the area and location of pixels in color ranges in images, used to count the area of white-nose syndrome infection in bats.","tags":["color","r packages"],"title":"Countcolors, an R package for quantification of the fluorescence emitted by Pseudogymnoascus destructans lesions on the wing membranes of hibernating bats","type":"publication"},{"authors":["Hannah Weller","Hernán López-Fernández","Caleb McMahan","Elizabeth Brainerd"],"categories":["mouthbrooding","fish"],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"1707a92c7864b65e806cb5a9cdaa7890","permalink":"/publication/sicb-2020/","publishdate":"2021-04-18T00:00:00Z","relpermalink":"/publication/sicb-2020/","section":"publication","summary":"Does the way fish feed influence the likelihood that they will evolve to use their mouths for parental care?","tags":["mouthbrooding","evolution","fish","cichlids"],"title":"The spandrels of Satan's perches: evidence for the co-optation of feeding traits in the convergent evolution of mouthbrooding in Neotropical cichlids","type":"publication"},{"authors":["Hannah Weller","Mark Westneat"],"categories":["colordistance"],"content":"","date":1549411200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549411200,"objectID":"a3c5a2437dfc61b5d3a25ffacff0d7eb","permalink":"/publication/colordistance/","publishdate":"2021-04-16T15:11:40-04:00","relpermalink":"/publication/colordistance/","section":"publication","summary":"An R package for quantifying color differences.","tags":["color","r packages","colordistance"],"title":"Quantitative color profiling of digital images with earth mover’s distance using the R package colordistance","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"  Click here to download.\nHannah Weller  Research interests: the role of biomechanical constraints in life history evolution; paths of least resistance in the evolution of new traits; methods development for analyzing organism color and pattern.\n  Education  2019 – Present PhD candidate, Ecology and Evolutionary Biology\nBrown University (Providence, RI) Thesis: How much does functional morphology matter to the evolution of mouthbrooding? 2017 – 2019 Transitional M.Sc., Ecology and Evolutionary Biology\nBrown University (Providence, RI) Thesis: How do feeding adaptations influence the convergent evolution of mouthbrooding? 2012 – 2016 Honors B.Sc., Biology\nUniversity of Chicago (Chicago, IL) Thesis: Winnowing in the eartheater cichlids  Awards and Fellowships  April 2019 Graduate Research Fellowship\n$138,000, National Science Foundation December 2018 Field Museum Visiting Scientist Scholarship\n$1,500, Field Museum of Natural History May 2017 Presidential Fellowship\n$108,000, Brown University June 2015 Jeff Metcalf Undergraduate Research Fellowship\n$5,000, Marine Biological Laboratory March 2015 Elected to Phi Beta Kappa Society September 2014 Best Presentation, Undergraduate Research Symposium\n$150, University of Chicago June 2014 Elliott and Eileen Hinkes Research Fellowship\n$4,000, University of Chicago  Peer-reviewed publications Weller, H.I., López-Fernández, H., McMahan, C.D., and Brainerd, E.L. (2021). Relaxed feeding constraints facilitate the evolution of mouthbrooding in Neotropical cichlids. The American Naturalist. In press.\nWeller, H.I., Olsen, A., Camp, A.L., Hernandez, L.P., Manafzadeh, A.R., and Brainerd, E.L. (2020). An XROMM study of intra-oral transport and swallowing in catfish. Integrative Organismal Biology. DOI: https://doi.org/10.1093/iob/obaa018.\nCohen, K.E., Weller, H.I., Westneat, M.W., and Summers, A.P (2020). The Evolutionary Continuum of Functional Homodonty to Heterodonty in the Dentition of Halichoeres Wrasses. Integrative and Comparative Biology. https://doi.org/10.1093/icb/icaa137.\nWeller, H.I.*, Hooper, S.E.*, and Amelon, S.K* (2020). Countcolors, an R package for quantification of the fluorescence emitted by Pseudogymnoascus destructans lesions on the wing membranes of hibernating bats. Journal of Wildlife Diseases. https://doi.org/10.7589/2019-09-231\n*These authors contributed equally to this work.\nCohen, K.E., Weller, H.I., and Summers, A.P. (2020). Not your father’s homodonty—stress, tooth shape, and the functional homodont. Journal of Anatomy. DOI: https://doi.org/10.1111/joa.13248\nvan Meer, N.M., Weller, H.I., Manafzadeh, A.R., Kaczmarek, E.B., Scott, B., Gussekloo, S.W.S, Wilga, C.D., Brainerd, E.B., and Camp, A.L. (2019). Intra-oropharyngeal food transport and swallowing in white-spotted bamboo sharks. Journal of Experimental Biology. DOI: 10.1242/jeb.201426\nWeller, H.I., and Westneat, M.W. (2019). Quantitative color profiling of digital images with earth mover’s distance using the R package colordistance. PeerJ. DOI: 10.7717/peerj.6398\nWeller, H.I., McMahan, C.D., and Westneat, M.W. (2016). Dirt-sifting Devilfish: Winnowing in the geophagine cichlid Satanoperca daemon and evolutionary implications. Zoomorphology. DOI: 10.1007/s00435-016-0335-6\nSoftware Weller, H.I. (2020). recolorize: Simplify and Remap Image Colors for Biological Analysis (ver. 0.9.000). Compiled and installable; CRAN release planned. https://github.com/hiweller/recolorize\nO\u0026rsquo;Sullivan, D., Weller, H.I., and Lord, N.P. Insect Color Database (ICDB). In development. https://insectcolor.com/\nWeller, H.I. (2019). colordistance: Distance Metrics for Image Color Similarity (ver. 1.1.0). CRAN repository. https://CRAN.R-project.org/package=colordistance\nWeller, H.I. (2018). countcolors: Locates and Counts Pixels Within Color Range(s) in Images (ver. 0.9.1). CRAN Repository. https://CRAN.R-project.org/package=countcolors\nPresentations Weller, H.I., Wham, D., Ezray-Wham, B., and Lord, N.P. (August 2021). Talk: Greater than the sum of their parts? Unpacking the “black box” of perceptual similarity using classical color pattern metrics. Living Light Early Career Reserachers, virtual conference.\nWeller, H.I., Schwartz, S.T., Karan, E., and Lord, N.P. (Jan. 2021). Talk: Recolorize: a flexible R package for color classification. Society for Integrative and Comparative Biology, virtual conference.\nWeller, H.I., Karan, E., Schwartz, S. and Lord, N.P. (Jan. 2021). Talk: recolorize: color-based image segmentation (for people with other things to do). Society for Integrative and Comparative Biology (Virtual).\nWeller, H.I., López-Fernández, H., McMahan, C.D., and Brainerd, E.L. (Jan. 2020). Talk: The spandrels of Satan\u0026rsquo;s perches: evidence for the co-optation of feeding traits in the convergent evolution of mouthbrooding in Neotropical cichlids. Society for Integrative and Comparative Biology, Austin, TX.\nWeller, H.I., López-Fernández, H., McMahan, C.D., and Brainerd, E.L. (Oct. 2019). Talk: Does mouthbrooding constrain or complement feeding morphology? Regional Division of Vertebrate Morphology (Northeast), Newton, MA.\nWeller, H.I., Olsen, A., Camp, A.L., Hernandez, L.P., Manafzadeh, A.R., and Brainerd, E.L. (Jan. 2019). Talk: 3D-Intra-oral Prey Trajectories Indicate Distinct Phases in how Channel Catfish (Ictalurus punctatus, Siluriformes: Ictaluridae) Swallow Food. International Congress of Vertebrate Morphology, Prague, CZ.\nWeller, H.I., Cohen, K.E., Gibb, A., and Brainerd, E.L. (Jan. 2019). Poster: Using tethers to measure food transport in a flatfish. Society for Integrative and Comparative Biology, Tampa, FL.\nWeller, H.I., Olsen, A., Camp, A.L., Hernandez, L.P., Manafzadeh, A.R., and Brainerd, E.L.(Jan. 2019). Talk: An XROMM study of intra-oral transport and swallowing in catfish. Society for Integrative and Comparative Biology, Tampa, FL.\nWeller, H.I. and Brainerd, E.L. (Oct. 2017). Talk: How do fish swallow food? Regional Division of Vertebrate Morphology (Northeast), Lowell, MA.\nWeller, H.I., McMahan, C.D., and Westneat, M.W. (July 2016). Poster: Dirt-sifting devilfish: winnowing in eartheater cichlids. American Society of Ichthyologists and Herpetologists, New Orleans, LA.\nInvited talks, lectures, \u0026amp; workshops  July 2020 Workshop: Phylogenetic Comparative Methods in R\nUniversity of Washington, Friday Harbor Laboratories (Friday Harbor, WA) R workshop focusing on phylogenetic and comparative methods. Instructors: Matthew Kolmann and Cassandra Donatelli. July 2020 A field guide to statistics in organismal biology\nUniversity of Washington, Friday Harbor Laboratories (Friday Harbor, WA)\nGuest lecture. Instructors: Matthew Kolmann and Cassandra Donatelli. July 2020 Mouthbrooding morphologies in Neotropical cichlids\nUniversity of California Davis, Dept. of Ecology and Evolutionary Biology (Davis, CA)\nVirtual seminar. Host: Peter Wainwright. April 2020 Special Topics: Light, Color, and Vision in Biology (BIOL 7901/ENTM 7008)\nLouisiana State University, Dept. of Entomology and Dept. of Biology (Baton Rouge, LA)\nGuest lecturer (3 classes). Instructors: Nathan Lord (ENTM) \u0026amp; Brant Faircloth (BIOL). December 2019 Workshop: R for Biologists\nLouisiana State University, Dept. of Entomology (Baton Rouge, LA)\nOrganizer. Day-long workshop on data analysis and visualization in R.  Research experience  2017 – Present PhD candidate, Brainerd Lab; advisor: Elizabeth Brainerd\nBrown University, Dept. of Ecology \u0026amp; Evolutionary Biology\nComparative morphology, kinematics, and biomechanics of mouthbrooding fishes; XROMM fish feeding and transport. September 2013 – July 2017 Research assistant; advisor: Mark Westneat\nUniversity of Chicago, Dept. of Organismal Biology \u0026amp; Anatomy\nQuantitative color analysis; geometric morphometrics; high-speed video kinematics. June 2015 – September 2015 Jeff Metcalf Summer Research Fellow; advisor: Roger Hanlon\nBrown University, Dept. of Ecology \u0026amp; Evolutionary Biology\nHyperspectral imaging; image analysis pipelines; camouflage analyses. June 2014 – September 2014 Summer Research Fellow, Westneat Lab; advisor: Mark Westneat\nUniversity of Chicago, Dept. of Organismal Biology \u0026amp; Anatomy\nOntogenetic scaling; biomechanical modeling; geometric morphometrics.  Teaching and outreach  June 2021 – July 2021 Instructor, Brown University, Summer@Brown Program (Providence, RI)\nAnatomy, Behavior, and Evolution: Fishy Solutions to Life Underwater\nIntensive high school course including labs, assignments, and mentoring of final project (preparation of research proposals and presentations). August 2020 – April 2020 Teaching assistant, Brown University, Alpert Medical School (Providence, RI)\nCOVID-modified Human Anatomy (lecture and lab)\nRestructuring the traditional gross anatomy curriculum, including remote/small group work and prosection-based staggered labs. September 2019 – Present R User Group, Brown University, Dept. of Ecology and Evolutionary Biology (Providence, RI)\nOrganizing and running monthly R workshops for graduate and undergraduate students, focusing on techniques for biological analysis (e.g., data organization, statistics, and visualization). August 2019 – April 2020 Teaching assistant, Brown University, Alpert Medical School (Providence, RI)\nHuman Anatomy (lecture and lab)\nGuiding medical students through cadaver-based human anatomy labs. September 2018 – Present Marine Science Club, Paul Cuffee High School (Providence, RI)\nCollaborating with high school teachers for weekly science activities with high school students. September 2017 – Dec. 2017 Teaching assistant, Brown University, Dept. of Ecology \u0026amp; Evolutionary Biology (Providence, RI)\nDiversity of Life (lecture) January 2015 – April 2017 Teaching assistant, University of Chicago, Dept. of Biological Sciences (Chicago, IL)\nPresenting and supervising lab experiments; writing and grading assignments; lecturing; leading paper discussions and review sessions; guiding dissection-based anatomy labs. Genetic and Developmental Biology (lab \u0026amp; lecture)\nMultiscale Modeling of Biological Systems (lecture)\nMolecular Biology of the Cell (lab)\nComparative Vertebrate Anatomy (lab \u0026amp; lecture)\n June 2013 – September 2013 Animal care intern, New England Aquarium (Boston, MA)\nDaily animal care and maintenance; visitor outreach; collection trips.  Skills  Coding R, Python (OpenCV, Scrapy, \u0026amp; BioPython libraries), MATLAB, UNIX, MEL Software Latex, Maya, FIJI/ImageJ, Horos, 3DSlicer, XMALab, Mesquite, Pandoc, Microsoft Office Languages English (native), French (intermediate)    Lab: Biomedical Center 426, 171 Meeting St., Providence, RI 02906\nEmail: hannahiweller@gmail.com\nWebsite: hiweller.github.io\n ","date":1530144000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530144000,"objectID":"fd36605688ef45e10dc233c860158012","permalink":"/cv/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/cv/","section":"","summary":"My current CV.","tags":null,"title":"","type":"page"},{"authors":["Hannah Weller","Caleb McMahan","Mark Westneat"],"categories":["fish"],"content":"","date":1504307149,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504307149,"objectID":"fe6c1ee086457923e985e8bfa1e52bb9","permalink":"/publication/winnowing/","publishdate":"2021-04-18T19:05:49-04:00","relpermalink":"/publication/winnowing/","section":"publication","summary":"Eartheaters (geophagines) are Neotropical fishes that can sift edible particles out of sand, without swallowing too much sand. How?","tags":["evolution","winnowing","cichlids","kinematics"],"title":"Winnowing in the geophagine cichlid Satanoperca daemon","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"10208a5f41e42dc21587b71536d3b832","permalink":"/project/icdb/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/icdb/","section":"project","summary":"Check out the `Insect Color Database`, a resource for storing image, spectral, and EM data relating to insect color.","tags":["color"],"title":"Insect Color Database","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]