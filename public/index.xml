<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hannah Weller</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Hannah Weller</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hu894dd0f75b84cd2ded4b9885934a1072_25364_512x512_fill_lanczos_center_2.png</url>
      <title>Hannah Weller</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Python basics</title>
      <link>/courses/example/python/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/courses/example/python/</guid>
      <description>&lt;p&gt;Build a foundation in Python.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/rfscVS0vtbw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the difference between lists and tuples?&lt;/summary&gt;
  &lt;p&gt;&lt;p&gt;Lists&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lists are mutable - they can be changed&lt;/li&gt;
&lt;li&gt;Slower than tuples&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_list = [1, 2.0, &#39;Hello world&#39;]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tuples&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tuples are immutable - they can&amp;rsquo;t be changed&lt;/li&gt;
&lt;li&gt;Tuples are faster than lists&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_tuple = (1, 2.0, &#39;Hello world&#39;)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Is Python case-sensitive?&lt;/summary&gt;
  &lt;p&gt;Yes&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Visualization</title>
      <link>/courses/example/visualization/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/courses/example/visualization/</guid>
      <description>&lt;p&gt;Learn how to visualize data with Plotly.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/hSPmj7mK6ng&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;When is a heatmap useful?&lt;/summary&gt;
  &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Write Plotly code to render a bar chart&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import plotly.express as px
data_canada = px.data.gapminder().query(&amp;quot;country == &#39;Canada&#39;&amp;quot;)
fig = px.bar(data_canada, x=&#39;year&#39;, y=&#39;pop&#39;)
fig.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Statistics</title>
      <link>/courses/example/stats/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/courses/example/stats/</guid>
      <description>&lt;p&gt;Introduction to statistics for data science.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;
&lt;p&gt;The general form of the &lt;strong&gt;normal&lt;/strong&gt; probability density function is:&lt;/p&gt;
&lt;p&gt;$$
f(x) = \frac{1}{\sigma \sqrt{2\pi} } e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
$$&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the parameter $\mu$?&lt;/summary&gt;
  &lt;p&gt;The parameter $\mu$ is the mean or expectation of the distribution.&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scaling images to a uniform resolution</title>
      <link>/post/scaling-images-to-a-uniform-resolution/</link>
      <pubDate>Mon, 14 Mar 2022 00:00:00 +0000</pubDate>
      <guid>/post/scaling-images-to-a-uniform-resolution/</guid>
      <description>&lt;p&gt;Kei-Lin Ooi at the University of Melbourne has a very good question about batch resizing (excerpted from an email):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I am using images from online databases and thus the images are not standardized. I am using the anisotropic blur to smooth out the image and eliminate image &amp;ldquo;noise&amp;rdquo;, but the anisotropic blur function is dependent on the image resolution. I was wondering if there was a way of batch processing images to scale and resize them to be, for example, 10 pixels / millimeter, so that the blur function smooths each image proportionally?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is an important step of image processing, so I wanted to use Kei-Lin&amp;rsquo;s email as motivation for writing out slightly more general instructions for this problem.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re reading this post, you&amp;rsquo;re most likely already familiar with image resolution, usually defined as pixels per some real-world unit, like millimeters or inches (&lt;em&gt;not&lt;/em&gt; the number of pixels in the image). When we&amp;rsquo;re taking photographs for analysis, we often try to take the highest resolution pictures we can of each subject, which might mean zooming in on smaller specimens and zooming out for large ones. The result is that we&amp;rsquo;re sampling those smaller specimens at a much higher resolution than the larger ones, which if nothing else introduces a confounding variable to our measurements.&lt;/p&gt;
&lt;p&gt;Luckily, this is pretty easy to fix a long as you know the resolution of each of your images: you just have to calculate the rescaling factor for the image from its current resolution and its target resolution, and provide that factor as an argument to an image resizing tool. We&amp;rsquo;ll do it in R (for pretty obvious inertia reasons), but I&amp;rsquo;ll list some alternatives at the end of the post.&lt;/p&gt;
&lt;h2 id=&#34;generating-example-images&#34;&gt;Generating example images&lt;/h2&gt;
&lt;p&gt;First, I&amp;rsquo;ll generate some simple exmple images by resizing an original image. We&amp;rsquo;ll do this with one of the images that comes with &lt;code&gt;recolorize&lt;/code&gt;, reading it in at 1x, 2x, and 3x the original size:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# get image path
image_path &amp;lt;- system.file(&amp;quot;extdata/chongi.png&amp;quot;, package = &amp;quot;recolorize&amp;quot;)

# load recolorize
library(recolorize)

# read in image at 1x, 2x, and 3x
sample_images &amp;lt;- lapply(1:3, function(i) readImage(image_path, resize = i))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can verify that the dimensions of the 2x and 3x images are indeed 2x and 3x the dimensions of the original:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lapply(sample_images, dim)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 226  90   4
## 
## [[2]]
## [1] 452 180   4
## 
## [[3]]
## [1] 678 270   4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I&amp;rsquo;m using this as sample data because the final solution is obvious: we want to downsample the 2x and 3x images to have the same dimensions as the 1x image again. For now, let&amp;rsquo;s save them as their own set of images:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# save as images
for (i in 1:3) {
  png::writePNG(sample_images[[i]], paste0(&amp;quot;beetle_&amp;quot;, i, &amp;quot;.png&amp;quot;))
}

# and make a list of image paths
image_paths &amp;lt;- dir(&amp;quot;.&amp;quot;, &amp;quot;beetle_&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Skip this step if you have your own images that you want to resize!&lt;/p&gt;
&lt;h2 id=&#34;calculating-current-resolution-and-rescaling-factors&#34;&gt;Calculating current resolution and rescaling factors&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s say the beetle in this image is 35mm long, and I measure it in ImageJ on each image to find that the beetle is 200px long in image 1, 400px long in image 2, and 600px long in image 3. That means my image resolutions are 200/35 = 5.71 px/mm for image 1, 400/35 = 11.43 px/mm for image 2, and 600/35 = 17.14 px/mm in image 3. For a real dataset, I would probably make a metadata spreadsheet of image name in one column and resolution in another so that you can keep track of everything.&lt;/p&gt;
&lt;p&gt;In our example, we&amp;rsquo;ll try to resize everything so that it&amp;rsquo;s the same as the original resolution of 5.71 px/mm. For an actual dataset, you could pick any target resolution so long as it is equal to or lower than the lowest resolution of any image in your dataset.&lt;/p&gt;
&lt;p&gt;In our case, we know our rescaling factors because we picked them, but let&amp;rsquo;s pretend we need to find them. The simplest calculation is to just divide the target resolution by the current resolution:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;current_resolutions &amp;lt;- c(200/35, 400/35, 600/35)
target_resolution &amp;lt;- 200/35

rescaling_factors &amp;lt;- target_resolution / current_resolutions
print(rescaling_factors)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.0000000 0.5000000 0.3333333
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected, we end up with rescaling factors of 1 for the original image (no resizing), 0.5 for the 2x image (1/2), and 0.3333 for the 3x image (1/3).&lt;/p&gt;
&lt;h2 id=&#34;rescaling-images&#34;&gt;Rescaling images&lt;/h2&gt;
&lt;p&gt;The easiest thing to do is to rescale the images using the &lt;code&gt;resize&lt;/code&gt; argument in &lt;code&gt;recolorize&lt;/code&gt;, since you have the option any time you read in an image for the package:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# make an empty list for images
image_list &amp;lt;- vector(&amp;quot;list&amp;quot;, length = length(image_paths))
image_list &amp;lt;- setNames(image_list, basename(image_paths))

# read in images and rescale appropriately
for (i in 1:length(image_paths)) {
  image_list[[i]] &amp;lt;- recolorize::readImage(image_paths[i],
                                           resize = rescaling_factors[i])
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, you&amp;rsquo;ll notice something if you look at the actual image dimensions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lapply(image_list, dim)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $beetle_1.png
## [1] 226  90   4
## 
## $beetle_2.png
## [1] 226  90   4
## 
## $beetle_3.png
## [1] 223  89   4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first two images now have identical dimensions, but the last one—which we scaled up 3x—isn&amp;rsquo;t quite right: it&amp;rsquo;s 223x89 pixels, instead of 226x90 pixels, so we have a resolution of about 5.63 px/mm instead of 5.71 px/mm. As far as I can tell, this is an artifact of our particular rescaling factor (1/3) being a repeating decimal (0.333&amp;hellip;) that gets rounded by the computer. One way around that would be to explicitly calculate the image dimensions you want, and use the &lt;code&gt;imager&lt;/code&gt; library directly to specify those dimensions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(imager)

# load the image as a cimg object
img &amp;lt;- load.image(image_paths[3])

# this doesn&#39;t work (this is the function recolorize calls):
img_imresize &amp;lt;- imresize(img, scale = 1/3)
dim(img_imresize) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  89 223   1   4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# cimg objects have x and y flipped, but this is still 223 pixels long x 89
# pixels wide

# we can explicitly calculate image dimensions:
new_dimensions &amp;lt;- dim(img)[1:2] * 1/3

# and specify those dimensions directly:
img_resize &amp;lt;- resize(img, 
                     size_x = new_dimensions[1], 
                     size_y = new_dimensions[2])
dim(img_resize)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  90 226   1   4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In practice, you&amp;rsquo;ll most likely encounter these fractional rescaling artifacts a lot, and even doing it the more precise way in &lt;code&gt;imager&lt;/code&gt; doesn&amp;rsquo;t totally eliminate it, since images have to be represented as an integer number of pixels. In this case, our artifact translated to a 0.08 px/mm discrepancy, partly because the images were so small to begin with.&lt;/p&gt;
&lt;h2 id=&#34;saving-images&#34;&gt;Saving images&lt;/h2&gt;
&lt;p&gt;Once you rescale an image, you&amp;rsquo;ll want to save it. I would use &lt;code&gt;writePNG()&lt;/code&gt; if your images are arrays, but the other option is &lt;code&gt;imager&lt;/code&gt;&amp;rsquo;s &lt;code&gt;save.image()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# we can save it with save.image:
save.image(img_resize, file = &amp;quot;beetle_3_resized.png&amp;quot;, quality = 1)

# or we can use a non-exported recolorize function to turn it back into an array:
img_array &amp;lt;- recolorize:::cimg_to_array(img_resize)

# and then export it:
png::writePNG(img_array, &amp;quot;beetle_3_resized.png&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That&amp;rsquo;s basically it! Calculate the rescaling factor for each image, apply it to that image, and save the downsampled result.&lt;/p&gt;
&lt;h2 id=&#34;a-slightly-more-realistic-example&#34;&gt;A slightly more realistic example&lt;/h2&gt;
&lt;p&gt;Here&amp;rsquo;s some code for running through a folder of images (the beetles that come with the package). The easier way:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# get vector of images:
images &amp;lt;- dir(system.file(&amp;quot;extdata&amp;quot;, package = &amp;quot;recolorize&amp;quot;), 
              &amp;quot;png&amp;quot;, full.names = TRUE)

# best practice would be to have these stored in a CSV in one column with image
# name in the other column, but for this example we&#39;ll just define image
# resolution as a vector:
image_resolutions &amp;lt;- c(5.71, 6.63, 5.32, 5.91, 6.63) # px/mm

# target resolution is 5 px/mm, since our lowest resolution is 5.3 px/mm
target_resolution &amp;lt;- 5

# for every image...
for (i in 1:length(images)) {
  
  # read in new image, rescaling it appropriately
  new_image &amp;lt;- readImage(images[i], 
                         resize = target_resolution / image_resolutions[i])
  
  # get filename for renaming
  filename &amp;lt;- basename(tools::file_path_sans_ext(images[i]))
  
  # and store output in current working directory
  png::writePNG(new_image, target = paste0(filename, &amp;quot;_resized.png&amp;quot;))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the slightly more complicated way:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# or, you could use the more precise option:
for (i in 1:length(images)) {
  # load image
  img &amp;lt;- load.image(images[i])
  
  # define new dimensions
  new_dimensions &amp;lt;- dim(new_image)[1:2] * (target_resolution / image_resolutions[i])
  
  # resize
  new_image &amp;lt;- resize(img,
                      size_x = new_dimensions[1], 
                      size_y = new_dimensions[2])
  
  # and save
  filename &amp;lt;- basename(tools::file_path_sans_ext(images[i]))
  save.image(new_image, file = paste0(filename, &amp;quot;_resized.png&amp;quot;))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;alternatives-to-rescaling-in-r&#34;&gt;Alternatives to rescaling in R&lt;/h2&gt;
&lt;p&gt;Almost any image processing tool will let you resize/rescale an image. The most tedious (and familiar) way is probably to use &lt;a href=&#34;https://bobbingwidewebdesign.com/photoshop-tutorial/how-do-i-batch-resize-in-gimp.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Photoshop or Gimp&lt;/a&gt;, manually opening each image and resizing it to desired dimensions.&lt;/p&gt;
&lt;p&gt;Personally, I&amp;rsquo;m a big fan of &lt;a href=&#34;https://ffmpeg.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ffmpeg&lt;/a&gt;, a popular command line tool for video, audio, and image processing. For example, to resize the 3x beetle, we would just call the following line in the terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; ffmpeg -i beetle_3.png -vf &amp;quot;scale=iw/3:ih/3&amp;quot; beetle_3_resized.png
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&amp;rsquo;s pretty easy to automate the renaming and rescaling. The only thing that would be difficult here is figuring out how to supply a different rescaling argument for each image (notice here I just divided the image width and height by 3). I&amp;rsquo;m sure you could do this by writing a short bash script, but I didn&amp;rsquo;t bother to do that for this post.&lt;/p&gt;
&lt;p&gt;Hopefully this is helpful—I guess the takeaway is that you have to calculate a simple ratio and then use any of half a dozen tools to resize your image. Pretty straightforward!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Recolorize &amp; patternize workflow</title>
      <link>/post/recolorize-patternize-workflow/</link>
      <pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate>
      <guid>/post/recolorize-patternize-workflow/</guid>
      <description>&lt;p&gt;This tutorial will go through the process of combining &lt;code&gt;patternize&lt;/code&gt; and &lt;code&gt;recolorize&lt;/code&gt; tools to produce a PCA quantifying color pattern variation in wasp faces (&lt;em&gt;Polistes fuscatus&lt;/em&gt;). This subset of 20 images (and workflow) is excerpted from &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2021.09.07.459327v1.abstract&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;lsquo;Evidence for a selective link between cooperation and individual recognition&amp;rsquo;&lt;/a&gt; (Tumulty et al. 2021),  with permission from the lead author. (Thanks James!)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/wasps.png&#34; alt=&#34;figures illustrating steps in the quantification of wasp facial patterns using recolorize and patternize&#34;&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12853&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;patternize&lt;/code&gt; package&lt;/a&gt; is an excellent tool for quantifying variation in color patterns. I use it frequently, because it&amp;rsquo;s a consistent, scaleable method for quantification that works for almost any organism, and it allows you to control for variation in shape, orientation, and size by first aligning all of your color patterns to a RasterStack—analogous to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Procrustes_analysis&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Procrustes fit step of geometric morphometrics&lt;/a&gt;. It also helps that the package author, Steven Van Belleghem, is extremely friendly!&lt;/p&gt;
&lt;p&gt;In practice, the most difficult step of using &lt;code&gt;patternize&lt;/code&gt; is often the color segmentation: like several other color analysis packages and tools, &lt;code&gt;patternize&lt;/code&gt; frequently relies on k-means clustering to extract color patches from images (especially for batch processing). That&amp;rsquo;s where &lt;code&gt;recolorize&lt;/code&gt; comes in. In order to use &lt;code&gt;recolorize&lt;/code&gt; to do the segmentation step for &lt;code&gt;patternize&lt;/code&gt;, we have to follow three steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Align original images as RasterStacks using &lt;code&gt;alignLan()&lt;/code&gt; in &lt;code&gt;patternize&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Segment the list of aligned images using &lt;code&gt;recolorize&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Convert list of segmented images back into the &lt;code&gt;patternize&lt;/code&gt; format&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let&amp;rsquo;s do it!&lt;/p&gt;
&lt;h2 id=&#34;example-files&#34;&gt;Example files&lt;/h2&gt;
&lt;p&gt;All the data and code used in this tutorial can be found here: &lt;a href=&#34;https://github.com/hiweller/recolorize_examples/02_wasps&#34;&gt;https://github.com/hiweller/recolorize_examples/02_wasps&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-1-image-alignment-in-patternize&#34;&gt;Step 1: Image alignment in &lt;code&gt;patternize&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Make sure you have installed the development version of &lt;code&gt;patternize&lt;/code&gt; (e.g. by running &lt;code&gt;devtools::install_github(&amp;quot;StevenVB12/patternize&amp;quot;)&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re starting with a folder of unaltered images of wasp faces. These images have been color-corrected and cropped to the wasp&amp;rsquo;s face, but the background hasn&amp;rsquo;t been masked out, since &lt;code&gt;patternize&lt;/code&gt; will do that when we do the alignment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/recolorize-patternize-workflow/index.en_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note that even on this dataset—which is highly standardized—the images have slight variations in the size, shape, and angle of the head, making it difficult to differentiate variation due to color pattern differences from that due to other factors.&lt;/p&gt;
&lt;p&gt;To use the &lt;code&gt;alignLan()&lt;/code&gt; function, we need to provide XY coordinates of landmarks (one set per image). I did these in ImageJ using the &lt;a href=&#34;https://imagej.nih.gov/ij/docs/guide/146-19.html#toc-Subsection-19.5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;multi-point tool&lt;/a&gt;, but really you just need a two-column, tab-delimited text file with X coordinates on the left and Y coordinates on the right, and &lt;strong&gt;no header&lt;/strong&gt;. Our landmarking scheme for the wasp faces only had 8 points:
&lt;img src=&#34;images/F03_wasps_landmarking.png&#34; alt=&#34;&#34; width=&#34;40%&#34;/&gt;
So, I opened up each image in ImageJ, selected those landmarks using the multi-point tool, then saved those pixel coordinates as a plain text file with the same suffix. For example, the pixel coordinates for &lt;code&gt;polistes_01.jpg&lt;/code&gt; is called &lt;code&gt;polites_01_landmarks.txt&lt;/code&gt; (&lt;a href=&#34;https://github.com/hiweller/recolorize_examples/blob/main/02_wasps/landmarks/polistes_01_landmarks.txt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;you can see it here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;I also made a mask for the images using the polygon selection tool in ImageJ, which will allow us to do the batch background masking. In this case, we only want to retain the frons and clypeus of the head (masking out the eyes and antennae openings), so I outlined them in a representative image (polistes_05) and saved those as XY coordinates as well (&lt;a href=&#34;https://github.com/hiweller/recolorize_examples/tree/main/02_wasps/masks&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;). Because we&amp;rsquo;re aligning using landmarks, we only need to make one outline which will be applied to all images in the dataset—much faster than masking each image manually!&lt;/p&gt;
&lt;p&gt;Once you have all those files (original images, XY landmark coordinates, and masking outline coordinates), we can combine them using &lt;code&gt;patternize&lt;/code&gt;. I organized my files into separate folders (images in the &lt;code&gt;original_images/&lt;/code&gt; folder, landmark text files in the &lt;code&gt;landmarks&lt;/code&gt; folder, etc), but you don&amp;rsquo;t have to do that so long as your files are organized and named in a way that works with the &lt;code&gt;makeList()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# load library
library(patternize)

### Align set of 20 images ###

# set of specimen IDs
IDlist &amp;lt;- tools::file_path_sans_ext(dir(&amp;quot;original_images/&amp;quot;, &amp;quot;.jpg&amp;quot;))

# make list with images
imageList &amp;lt;- makeList(IDlist, type = &amp;quot;image&amp;quot;,
                      prepath = &amp;quot;original_images/&amp;quot;,
                      extension = &amp;quot;.jpg&amp;quot;)

# make list with landmarks
landmarkList &amp;lt;- makeList(IDlist,
                         type = &amp;quot;landmark&amp;quot;,
                         prepath = &amp;quot;landmarks/&amp;quot;,
                         extension = &amp;quot;_landmarks.txt&amp;quot;)

# Set target as polistes 05
target &amp;lt;- landmarkList[[&#39;polistes_05&#39;]]

# Set up mask, which excludes eyes/mandibles and antenna holes
mask1 &amp;lt;- read.table(&amp;quot;masks/polistes_05_mask.txt&amp;quot;, header = FALSE)
mask2 &amp;lt;- read.table(&amp;quot;masks/polistes_05_Lantenna.txt&amp;quot;, header = FALSE)
mask3 &amp;lt;- read.table(&amp;quot;masks/polistes_05_Rantenna.txt&amp;quot;, header = FALSE)

### Alignment ###
# this takes ~1 minute on a 16Gb RAM laptop running Ubuntu
imageList_aligned &amp;lt;- alignLan(imageList, landmarkList, transformRef = target, 
                              adjustCoords = TRUE,
                              plotTransformed = T, 
                              resampleFactor = 5, 
                              cartoonID = &#39;polistes_05&#39;,
                              maskOutline = list(mask1, mask2, mask3), 
                              inverse = list(FALSE, TRUE, TRUE))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting &lt;code&gt;imageList_aligned&lt;/code&gt; object is a list of aligned &lt;a href=&#34;https://rdrr.io/cran/raster/man/brick.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RasterBrick&lt;/a&gt; objects, one per image, with everything but the region of interest (frons and clypeus) removed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: I usually save this list as an .RDS file so I can load it back in at my convenience without having to do the alignment step again:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# save RDS file
saveRDS(imageList_aligned, &amp;quot;rds_files/imageList_aligned.rds&amp;quot;)

# read it in:
imageList_aligned &amp;lt;- readRDS(&amp;quot;rds_files/imageList_aligned.rds&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;step-2-segment-images-in-recolorize&#34;&gt;Step 2: Segment images in &lt;code&gt;recolorize&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The wonky step in this workflow is that &lt;code&gt;patternize&lt;/code&gt; works with raster images, and &lt;code&gt;recolorize&lt;/code&gt; works with arrays, so we have to convert from raster objects to arrays before using &lt;code&gt;recolorize&lt;/code&gt;. The &lt;code&gt;brick_to_array()&lt;/code&gt; function makes that fairly straightforward:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# load library
library(recolorize)

# convert from RasterBricks to image arrays using the brick_to_array function:
imgs &amp;lt;- lapply(imageList_aligned, brick_to_array)
names(imgs) &amp;lt;- names(imageList_aligned)

# save raster extents for later conversion:
extent_list &amp;lt;- lapply(imageList_aligned, extent)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have a list of image arrays. Plotting them using &lt;code&gt;plotImageArray()&lt;/code&gt; helps us to see what the &lt;code&gt;alignLan()&lt;/code&gt; step did for our original images:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/recolorize-patternize-workflow/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;480&#34; /&gt;
(Note that it also flipped the images upside because the y coordinate systems are reversed–this is annoying, but doesn&amp;rsquo;t affect our results, so we&amp;rsquo;ll leave it for now.)&lt;/p&gt;
&lt;p&gt;We want to map each of these wasp faces to the same set of three colors: dark brown, reddish brown, and yellow. K-means clustering could work in theory for this problem (we would fit &lt;em&gt;n = 3&lt;/em&gt; colors for each image), but in practice, we get the colors back in a random order—and they&amp;rsquo;re not actually the same color. Here&amp;rsquo;s what it looks like if we try to do that:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;for (i in 1:length(imgs)) {
  rc &amp;lt;- recolorize(imgs[i], method = &amp;quot;k&amp;quot;, n = 3, plotting = FALSE)
  plotColorPalette(rc$centers)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/recolorize-patternize-workflow/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These colors are definitely similar across images, but they&amp;rsquo;re not consistent, especially since not all wasps have all three colors present. Maybe most intractably, they&amp;rsquo;re not in the same order: yellow is color 1, 2, or 3 depending on the image, and sometimes it&amp;rsquo;s not there at all.&lt;/p&gt;
&lt;p&gt;Instead, we&amp;rsquo;ll come up with our list of 3 colors by combining color palettes across images, and then use the &lt;code&gt;imposeColors()&lt;/code&gt; function in &lt;code&gt;recolorize&lt;/code&gt; to map each of our images to the same color palette. First, generate a color palette for each image:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# make an empty list for storing the recolorize objects
rc_list &amp;lt;- vector(&amp;quot;list&amp;quot;, length(imgs))
names(rc_list) &amp;lt;- names(imgs)

# for every image, run the same recolorize2 function to fit a recolorize object:
for (i in 1:length(imgs)) {
  rc_list[[i]] &amp;lt;- recolorize2(imgs[[i]], bins = 3,
                              cutoff = 35, plotting = FALSE)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I kept it pretty simple for this example (we&amp;rsquo;re just calling &lt;code&gt;recolorize2()&lt;/code&gt; with the same parameters for each image), but you could get more complicated with what you put in the for loop. (You could even choose to use k-means clustering as the method here by setting &lt;code&gt;method = &amp;quot;k&amp;quot;&lt;/code&gt; and specifying the number of colors, since we&amp;rsquo;re just using it as a starting point, but since k-means is not deterministic that poses problems for repeatability.)&lt;/p&gt;
&lt;p&gt;Next you can combine the color palettes from all of the &lt;code&gt;recolorize&lt;/code&gt; objects in &lt;code&gt;rc_list&lt;/code&gt; and use &lt;code&gt;hclust_color&lt;/code&gt; to plot them and return a list of which colors to group together:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# get a dataframe of all colors:
all_palettes &amp;lt;- do.call(rbind, lapply(rc_list, function(i) i$centers))

# and for cluster sizes (as a proportion of their original image):
all_sizes &amp;lt;- do.call(c, lapply(rc_list, function(i) i$sizes))

# plot colors using hclust and return grouping list:
par(mar = rep(2, 4))
cluster_list &amp;lt;- hclust_color(all_palettes, n_final = 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/recolorize-patternize-workflow/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;cluster_list&lt;/code&gt; object is a list, each element of which is a vector of which of the original colors should be clustered together. See the rest of the &lt;code&gt;hclust_color()&lt;/code&gt; options to various ways to combine colors by similarity—by default, it calculates the Euclidean distance matrix between all provided color centers in &lt;a href=&#34;https://cran.r-project.org/web/packages/colordistance/vignettes/lab-analyses.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CIE Lab&lt;/a&gt; color space. We can use that list to combine all the colors and come up with our universal palette:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# make an empty matrix for storing the new palette
wasp_palette &amp;lt;- matrix(NA, ncol = 3, nrow = length(cluster_list))

# for every color in cluster_list...
for (i in 1:length(cluster_list)) {
  
  # get the center indices
  idx &amp;lt;- cluster_list[[i]]
  
  # get the average value for each channel, using cluster size to get a weighted average
  ctr &amp;lt;- apply(all_palettes, 2, 
                 function(j) weighted.mean(j[idx], 
                                           w = all_sizes[idx]))
  
  # store in the palette matrix
  wasp_palette[i, ] &amp;lt;- ctr
}

# check that our colors seem reasonable
par(mar = rep(0, 4))
plotColorPalette(wasp_palette)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/recolorize-patternize-workflow/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;288&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now, we can use &lt;code&gt;imposeColors()&lt;/code&gt; to map every image to the same set of three colors:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;impose_list &amp;lt;- lapply(imgs, function(i) imposeColors(i, wasp_palette, 
                                                     adjust_centers = FALSE, 
                                                     plotting = FALSE))

# let&#39;s look at our palettes!
layout(matrix(1:20, nrow = 4))
par(mar = rep(0, 4))
for (i in impose_list) {
  plotColorPalette(i$centers, i$sizes)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/recolorize-patternize-workflow/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Although the proportions of each color vary by image, the order/value of the colors does not (unlike with k-means). This is the key step. As long as you can provide a color palette to which all of your images should be mapped, you can use &lt;code&gt;imposeColors()&lt;/code&gt; to map every image to those colors. The earlier portion where we did an initial fit and used &lt;code&gt;hclust_color&lt;/code&gt; is a good option when you want to come up with a color palette intrinsic to your original images, but it may still take some toying around before you find a palette that works.&lt;/p&gt;
&lt;p&gt;The last step is to convert each &lt;code&gt;recolorize&lt;/code&gt; fit in back to a &lt;code&gt;patternize&lt;/code&gt; format, which we can do with the &lt;code&gt;recolorize_to_patternize()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# convert to patternize:
patternize_list &amp;lt;- lapply(impose_list, recolorize_to_patternize)

# and set extents again:
for (i in 1:length(patternize_list)) {
  for (j in 1:length(patternize_list[[1]])) {
    raster::extent(patternize_list[[i]][[j]]) &amp;lt;- extent_list[[i]]
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a list of lists: there is one element per sample ID in &lt;code&gt;patternize_list&lt;/code&gt; (20 total), and each of those elements is a list of &lt;code&gt;RasterLayer&lt;/code&gt; objects, one per color class (3 per sample ID). You may need to reshuffle these depending on what you want to do.&lt;/p&gt;
&lt;p&gt;Now, back to &lt;code&gt;patternize&lt;/code&gt;!&lt;/p&gt;
&lt;h2 id=&#34;step-3-color-pattern-analyses-in-patternize&#34;&gt;Step 3: Color pattern analyses in &lt;code&gt;patternize&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Since we now have the images segmented in the way that &lt;code&gt;patternize&lt;/code&gt; needs, we can run any of the regular &lt;code&gt;patternize&lt;/code&gt; functions on it (see the methods paper and &lt;a href=&#34;https://github.com/StevenVB12/patternize-examples&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;examples repository&lt;/a&gt;). Here, we&amp;rsquo;ll use a custom function based on code that Steven sent me for running a PCA on the entire color pattern (all three colors simultaneously, rather than one color class at a time). You can see the full function &lt;a href=&#34;https://github.com/hiweller/recolorize_examples/blob/main/wasps/patPCA_total.R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. If you&amp;rsquo;ve downloaded the wasp example dataset, the easiest thing to do is to just source it and run the function on the list we made earlier:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;source(&amp;quot;patPCA_total.R&amp;quot;)
wasp_pca &amp;lt;- patPCA_total(patternize_list, quietly = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Summing raster lists...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Making dataframe from rasters...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Running PCA on 3 colors and 20 images...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/recolorize-patternize-workflow/index.en_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;
That&amp;rsquo;s it! The &lt;code&gt;wasp_pca&lt;/code&gt; object is a &lt;code&gt;prcomp&lt;/code&gt; object (the standard class for principal components analysis in R).&lt;/p&gt;
&lt;h2 id=&#34;bonus-visualization&#34;&gt;Bonus: visualization&lt;/h2&gt;
&lt;p&gt;It can be hard to tell whether the PCA is capturing relevant axes of color pattern variation from a scatterplot; I find it more intuitive to plot some version the actual images. The &lt;code&gt;add_image()&lt;/code&gt; function is an easy way to do that:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# first, make a blank plot
PCx &amp;lt;- 1; PCy &amp;lt;- 2
pca_summary &amp;lt;- summary(wasp_pca)
limits &amp;lt;- apply(wasp_pca$x[ , c(PCx, PCy)], 2, range)
par(mar = c(4, 4, 2, 1))
plot(wasp_pca$x[ , c(PCx, PCy)], type = &amp;quot;n&amp;quot;,
     asp = 1,
     xlim = limits[ , 1] + c(-5, 5), 
     ylim = limits[ , 2] + c(-10, 10),
     xlab=paste0(&#39;PC1 (&#39;, round(pca_summary$importance[2, PCx]*100, 1), &#39; %)&#39;),
     ylab=paste0(&#39;PC2 (&#39;, round(pca_summary$importance[2, PCy]*100, 1), &#39; %)&#39;))

# then add images:
for (i in 1:length(impose_list)) {
  add_image(impose_list[[i]]$original_img, 
            x = wasp_pca$x[i, PCx],
            y = wasp_pca$x[i, PCy],
            width = 20)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/recolorize-patternize-workflow/index.en_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;
You could also plot images from a folder on your computer:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(wasp_pca$x[ , c(PCx, PCy)], type = &amp;quot;n&amp;quot;,
     asp = 1,
     xlim = limits[ , 1] + c(-5, 5), 
     ylim = limits[ , 2] + c(-10, 10),
     xlab=paste0(&#39;PC1 (&#39;, round(pca_summary$importance[2, PCx]*100, 1), &#39; %)&#39;),
     ylab=paste0(&#39;PC2 (&#39;, round(pca_summary$importance[2, PCy]*100, 1), &#39; %)&#39;))

# read in images from the original folder:
images &amp;lt;- lapply(dir(&amp;quot;original_images/&amp;quot;, full.names = TRUE),
                 readImage)

# and plot:
for (i in 1:length(images)) {
  add_image(images[[i]], 
            x = wasp_pca$x[i, PCx],
            y = wasp_pca$x[i, PCy],
            width = 20)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/recolorize-patternize-workflow/index.en_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;
(If I were to use these images for a paper figure, though, I would go through and mask out the background using transparencies—these are a little hard to see on a white background.)&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s it for the tutorial. I would recommend downloading the example code and files from the linked GitHub repository if you want to try it out: there are a few steps involved, but ultimately it&amp;rsquo;s a reasonably simple procedure. I&amp;rsquo;d love to be able to write a one-and-done version of this process, but if you&amp;rsquo;ve been reading &lt;a href=&#34;https://hiweller.github.io/recolorize/articles/Introduction.html#general-guidelines&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the other recolorize documentation&lt;/a&gt;, you&amp;rsquo;ll be familiar with my perspective on this. Basically, if I try to impose a general structure for how to do this every time, that&amp;rsquo;s not going to be flexible enough to encompass many use cases, and I prefer to keep things modular. Still, if you have any ideas for how to make this a more friendly process, I&amp;rsquo;m all ears!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Image trees</title>
      <link>/post/image-trees/</link>
      <pubDate>Fri, 07 May 2021 00:00:00 +0000</pubDate>
      <guid>/post/image-trees/</guid>
      <description>&lt;p&gt;One of the most direct ways to tell whether or not your image analysis is working is to plot your images themselves as points in your result plots, which is usually easier said than done. Lots of packages in R will allow you to do some form of this, but I usually run into two problems: 1) I have to download a (sometimes pretty hefty) package for a single function, and 2) that function often only works in a specific context, which means it&amp;rsquo;s not very flexible. In practice, I usually end up defining functions for this as-needed, in a sort of ad-hoc dirtbag fashion. This post will outline the basics of doing just that.&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s take a look at our images:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/image-trees/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;
This is a lovely set of 40 images of jewel beetles, taken by my collaborator &lt;a href=&#34;https://www.thelordlab.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nathan P. Lord&lt;/a&gt;. Not only are they all nicely uniform and centered, but the backgrounds are &lt;strong&gt;transparent&lt;/strong&gt; &amp;ndash; this almost always makes for nicer plotting, because you don&amp;rsquo;t get big white corners when the images overlap. Although if you&amp;rsquo;re just using these plots as diagnostics instead of figures, it doesn&amp;rsquo;t really matter as long as it helps you understand your data better.&lt;/p&gt;
&lt;p&gt;As an example of the kind of thing we might want to plot, we&amp;rsquo;ll use &lt;a href=&#34;https://github.com/hiweller/colordistance&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;colordistance&lt;/a&gt; to generate a distance matrix of color similarity for the forty images above:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(colordistance)

# in my case, I have a folder called &#39;images&#39; which contains the 40 images,
# so &#39;images&#39; is a vector of 40 paths
images &amp;lt;- dir(&amp;quot;images/&amp;quot;, full.names = TRUE)

# generate a distance matrix using all the package defaults
cdm &amp;lt;- imageClusterPipeline(images, sample.size = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/image-trees/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;
The idea of this analysis is to cluster the images with the most similar color palettes together. So, we want to know if the clusters produced by this distance matrix represent images that actually are the most similar-looking.&lt;/p&gt;
&lt;p&gt;By default, colordistance generates a heatmap representing the pairwise color distances between each image, where darker blue indicates that two images are more similar, and brighter pink indicates that they are less similar. You might notice that this graphic is kind of useless for diagnostics. The image names are just printed as labels, and their names are not indicative of their contents&amp;ndash;so I have no idea if this analysis has lumped together the green-and-shiny beetles separate from the black-and-yellow beetles, or if I need to try different settings, and sitting here looking up image names is not a quick way to check.&lt;/p&gt;
&lt;p&gt;A better solution is to plot the images at the tips of the hierarchical clustering tree shown on the top and left of the heatmap:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/image-trees/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To make this plot, I used the &lt;code&gt;ape&lt;/code&gt; package to plot a neighbor-joining tree of the distance matrix, then defined a function for plotting images at the tips. First, let&amp;rsquo;s make the neighbor-joining tree:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ape)
tree &amp;lt;- nj(as.dist(cdm))
plot(tree, direction = &amp;quot;upwards&amp;quot;, cex = 0.5)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/image-trees/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Next, we can define a function, &lt;code&gt;add_image&lt;/code&gt;, which adds an image to a plot at a given set of XY coordinates. It&amp;rsquo;s sort of analogous to the &lt;code&gt;points&lt;/code&gt; function, which lets you add points to an existing base R plot.&lt;/p&gt;
&lt;p&gt;This is more complicated than just plotting an image as an image, because we have to play nice with existing plotting parameters (aspect ratio, range of the X- and Y-axes, etc).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# define add_image function:
add_image &amp;lt;- function(obj, # an object interpretable by rasterImage
                      x = NULL, # x &amp;amp; y coordinates for the center of the image
                      y = NULL,
                      width = NULL, # width of the image
                      interpolate = TRUE, # method for resizing
                      angle = 0) {
  
  # get current plotting window parameters:
  usr &amp;lt;- graphics::par()$usr # extremes of user coordinates in the plotting region
  pin &amp;lt;- graphics::par()$pin # plot dimensions (in inches)
  
  # image dimensions and scaling factor:
  imdim &amp;lt;- dim(obj)
  sf &amp;lt;- imdim[1] / imdim[2]
  
  # set the width of the image (relative to x-axis)
  w &amp;lt;- width / (usr[2] - usr[1]) * pin[1]
  h &amp;lt;- w * sf # height is proportional to width
  hu &amp;lt;- h / pin[2] * (usr[4] - usr[3]) # scale height to y-axis range
  
  # plot the image
  graphics::rasterImage(image = obj,
                        xleft = x - (width / 2), xright = x + (width / 2),
                        ybottom = y - (hu / 2), ytop = y + (hu/2),
                        interpolate = interpolate,
                        angle = angle)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that if you just want to plot an image as an image, you can use &lt;code&gt;rasterImage&lt;/code&gt; from the &lt;code&gt;graphics&lt;/code&gt; package, and almost any other image analysis package will come with a plotting method (for example, in &lt;code&gt;recolorize&lt;/code&gt; you can use &lt;code&gt;plotImageArray&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;We can use this function to plot the images on a regular XY plot:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;X &amp;lt;- runif(40)
Y &amp;lt;- runif(40)
plot(X, Y)

for (i in 1:length(images)) {
  
  # read the image into R:
  img &amp;lt;- png::readPNG(images[i]) 
  
  # add the image:
  add_image(img, x = X[i], y = Y[i],
            width = 0.05)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/image-trees/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we wanted to actually plot the distance matrix as a bivariate plot, we could use non-metric multidimensional scaling (NMDS), as described in &lt;a href=&#34;https://cougrstats.wordpress.com/2019/12/11/non-metric-multidimensional-scaling-nmds-in-r/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this post&lt;/a&gt;, to represent the distance matrix with a set of 2D coordinates:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# explaining NMDS is beyond the scope of this post (and is probably best left to the ecologists)
# see this link for more: 
# https://cougrstats.wordpress.com/2019/12/11/non-metric-multidimensional-scaling-nmds-in-r/

# for now, we&#39;ll just do it in two lines!
library(vegan)
nmds_scores &amp;lt;- scores(metaMDS(comm = as.dist(cdm)))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Run 0 stress 0.1158626 
## Run 1 stress 0.1139447 
## ... New best solution
## ... Procrustes: rmse 0.01705616  max resid 0.09840254 
## Run 2 stress 0.1140722 
## ... Procrustes: rmse 0.007575743  max resid 0.03447679 
## Run 3 stress 0.1159785 
## Run 4 stress 0.1158626 
## Run 5 stress 0.1139448 
## ... Procrustes: rmse 0.0001779728  max resid 0.0006533518 
## ... Similar to previous best
## Run 6 stress 0.1158627 
## Run 7 stress 0.115814 
## Run 8 stress 0.1158626 
## Run 9 stress 0.1139447 
## ... New best solution
## ... Procrustes: rmse 6.912601e-05  max resid 0.0002514859 
## ... Similar to previous best
## Run 10 stress 0.1139447 
## ... Procrustes: rmse 5.642976e-05  max resid 0.0001733153 
## ... Similar to previous best
## Run 11 stress 0.1140719 
## ... Procrustes: rmse 0.007496018  max resid 0.03406593 
## Run 12 stress 0.1139448 
## ... Procrustes: rmse 9.99557e-05  max resid 0.000494275 
## ... Similar to previous best
## Run 13 stress 0.1139447 
## ... Procrustes: rmse 9.345179e-05  max resid 0.0004509194 
## ... Similar to previous best
## Run 14 stress 0.1139447 
## ... Procrustes: rmse 6.492366e-05  max resid 0.0003038437 
## ... Similar to previous best
## Run 15 stress 0.1140722 
## ... Procrustes: rmse 0.007604775  max resid 0.03440036 
## Run 16 stress 0.1158141 
## Run 17 stress 0.1158141 
## Run 18 stress 0.1158142 
## Run 19 stress 0.1139447 
## ... Procrustes: rmse 5.046786e-05  max resid 0.0002452231 
## ... Similar to previous best
## Run 20 stress 0.1158141 
## *** Solution reached
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(nmds_scores)
for (i in 1:length(images)) {
  
  # read the image into R:
  img &amp;lt;- png::readPNG(images[i]) 
  
  # add the image:
  add_image(img, x = nmds_scores[i, 1], y = nmds_scores[i, 2],
            width = 0.05)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/image-trees/index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If this were a presentation-quality figure, I would probably bump out the X- and Y-axis ranges a bit so none of the images got cut off, but this looks pretty good!&lt;/p&gt;
&lt;p&gt;However, I did promise plotting images at the tips of trees, and that turns out to be pretty easy once you&amp;rsquo;ve got a plotted tree and a set of tips. This mostly comes from &lt;a href=&#34;http://blog.phytools.org/2017/04/new-function-to-add-tip-labels-to-tree.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this post&lt;/a&gt; on Liam Revell&amp;rsquo;s Phytools blog, which shows how to extract the XY coordinates of the tree tips from a plotted phylogeny; once we have those XY coordinates, we can plot images at those coordinates just as we would for a regular bivariate plot:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# plot the tree
plot(tree, show.tip.label = FALSE, direction = &amp;quot;upward&amp;quot;)

# get the parameters from the plotting environment
lastPP &amp;lt;- get(&amp;quot;last_plot.phylo&amp;quot;, envir = .PlotPhyloEnv)

# get the xy coordinates of the tips
ntip &amp;lt;- lastPP$Ntip

# first n values are the tips, remaining values are the coordinates of the
# nodes:
xy &amp;lt;- data.frame(x = lastPP$xx[1:ntip],
                 y = lastPP$yy[1:ntip]) 

# we can add points to the tree pretty easily using generic functions:
points(xy[ , 1], xy[ , 2], 
       col = viridisLite::viridis(40), 
       pch = 19, cex = 2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/image-trees/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Putting it all together, all we have to do is plot the tree, then plot the images. One crucial thing here&amp;ndash;and familiar to anyone working with trees&amp;ndash;&lt;strong&gt;make sure your images are in the same order as your tips&lt;/strong&gt;. This will save you a lot of head-scratching later.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# get image names
imnames &amp;lt;- tools::file_path_sans_ext(basename(images))

# get tip labels
tipnames &amp;lt;- tree$tip.label

# in my case, the tip labels are identical to the image names, so I can
# use these to check that my images are in the right order:
image_order &amp;lt;- match(tipnames, imnames)
images &amp;lt;- images[image_order]

# and plot!
par(mar = rep(0, 4))
plot(tree, show.tip.label = FALSE, direction = &amp;quot;upward&amp;quot;)

# get the parameters from the plotting environment
lastPP &amp;lt;- get(&amp;quot;last_plot.phylo&amp;quot;, envir = .PlotPhyloEnv)

# get the xy coordinates of the tips
ntip &amp;lt;- lastPP$Ntip
xy &amp;lt;- data.frame(x = lastPP$xx[1:ntip],
                 y = lastPP$yy[1:ntip]) 

for (i in 1:length(images)) {
  add_image(png::readPNG(images[i]),
            x = xy[i, 1],
            y = xy[i, 2], 
            width = 3)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/image-trees/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At this point,  I usually write a wrapper function to do all of this for me, so I can plot an image tree from a tree and a list of image paths. I also add a bit of trickery to fix the x-axis scaling; phylogenies typically have weird axis scaling.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;image_tree &amp;lt;- function(tree, # a phylo object
                       image_paths, # a vector of image paths (in order)
                       image_width = 0.1, # image width (as a proportion of the x-axis)
                       tip_label = FALSE, # whether to draw the tip labels
                       ...) {
  
  require(ape)
  # plot the tree
  plot.phylo(tree, show.tip.label = tip_label, ...)
  
  # this is the weird part: we get the phylo plot parameters from the active
  # graphics device
  lastPP &amp;lt;- get(&amp;quot;last_plot.phylo&amp;quot;, envir = .PlotPhyloEnv)
  
  # get the xy coordinates of the tips
  ntip &amp;lt;- lastPP$Ntip
  xy &amp;lt;- data.frame(x = lastPP$xx[1:ntip],
                   y = lastPP$yy[1:ntip])
  
  # scale image width according to plot width
  image_width &amp;lt;- diff(range(lastPP$x.lim)) * image_width
  
  # add the images using the add_image function
  for (i in 1:length(image_paths)) {
    img &amp;lt;- recolorize::readImage(image_paths[i])
    add_image(img,
              xy[i, 1], xy[i, 2],
              width = image_width)
  }
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I&amp;rsquo;ll save that function and the &lt;code&gt;add_image&lt;/code&gt; function in a script file (typically called &lt;code&gt;image_tree.R&lt;/code&gt; or similar) and source that for the relevant project, so in practice my actual workflow looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ape)
library(colordistance)

# get images
images &amp;lt;- dir(&amp;quot;images/&amp;quot;, full.names = TRUE)

# get distance matrix
cdm &amp;lt;- imageClusterPipeline(images, 
                            plot.heatmap = FALSE, 
                            sample.size = NULL)

# make neighbor-joining tree
tree &amp;lt;- nj(as.dist(cdm))

# plot image tree
par(mar = rep(0, 4))
image_tree(tree, images, 
           direction = &amp;quot;upward&amp;quot;,
           y.lim = c(0, 0.7))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/image-trees/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So it&amp;rsquo;s actually pretty straightforward!&lt;/p&gt;
&lt;p&gt;One question I would have after reading this post is: &amp;ldquo;Why don&amp;rsquo;t you just add this function to your R packages, instead of the crummy-looking default?&amp;rdquo; This is a good question, and there are two answers.&lt;/p&gt;
&lt;p&gt;First, I didn&amp;rsquo;t know how to do this when I first wrote the colordistance package, but I did know how to make heatmaps. I assumed that anyone using the package would take a quick look at the heatmap and then export the distance matrix for further analysis and plotting to emphasize whatever was most important about their results, and it didn&amp;rsquo;t occur to me that people are pretty likely to use the default visualization because they assume that&amp;rsquo;s what the package author intended. If I ever get the time and incentive to update the package, I hope to do so.&lt;/p&gt;
&lt;p&gt;Second, I find myself redefining or tweaking this function so much for specific use cases (for instance, in this case we just use the &lt;code&gt;readPNG&lt;/code&gt; function because all the images are PNGs, but you would need to change this if that&amp;rsquo;s not true of your images) that I didn&amp;rsquo;t see the point of including a static version in any one package. There&amp;rsquo;s so much variability in how plots are displayed and in how images are stored and displayed that a post explaining the details of the function was more helpful than creating a static version that would be out of date or too specific in scope. For instance, the &lt;code&gt;image_tree&lt;/code&gt; function above doesn&amp;rsquo;t try to match your image list to your tree tips, because that would require assuming your images are named the same way as your tree tips, which probably won&amp;rsquo;t usually be the case.&lt;/p&gt;
&lt;p&gt;Anyways, there is probably a happier middle ground than what I&amp;rsquo;ve included here. Hopefully this post provides enough detail for other people to modify it for their needs!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Function gallery for recolorize</title>
      <link>/post/function-gallery-for-recolorize/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>/post/function-gallery-for-recolorize/</guid>
      <description>&lt;p&gt;A quick reference gallery for what the most broadly useful functions do.&lt;/p&gt;
&lt;h3 id=&#34;loading-and-pre-processing-images&#34;&gt;Loading and pre-processing images&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;readImage&lt;/code&gt;: Reads in a PNG or JPEG image, optionally resizing and/or rotating it.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;img &amp;lt;- system.file(&amp;quot;extdata/corbetti.png&amp;quot;, package = &amp;quot;recolorize&amp;quot;)
loaded_image &amp;lt;- readImage(img_path = img, resize = NULL, rotate = NULL)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;blurImage&lt;/code&gt;: Applies one of several blurring filters from the &lt;code&gt;imager&lt;/code&gt; package to a loaded image. Helpful for dealing with variation from textures (e.g. scales, reflections, hairs, etc).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;blurred_image &amp;lt;- blurImage(loaded_image, blur_function = &amp;quot;medianblur&amp;quot;, n = 3, threshold = 5)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;initial-segmentation&#34;&gt;Initial segmentation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;recolorize&lt;/code&gt;: The major function of the package. Segments colors using color binning (&lt;code&gt;method = &amp;quot;hist&amp;quot;&lt;/code&gt;) or k-means clustering (&lt;code&gt;method = &amp;quot;k&amp;quot;&lt;/code&gt;), in several color spaces.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rc_hist &amp;lt;- recolorize(img, method = &amp;quot;hist&amp;quot;, bins = 2, color_space = &amp;quot;sRGB&amp;quot;)
#&amp;gt; 
#&amp;gt; Using 2^3 = 8 total bins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
rc_k &amp;lt;- recolorize(img, method = &amp;quot;k&amp;quot;, n = 8, color_space = &amp;quot;sRGB&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-4-2.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;recolorize2&lt;/code&gt;: Runs &lt;code&gt;recolorize&lt;/code&gt; and &lt;code&gt;recluster&lt;/code&gt; (see next section) in sequence. I have found this to be an effective, fast combination for very many kinds of images, so if you&amp;rsquo;re going to pick one function to start with, pick this one!&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rc &amp;lt;- recolorize2(img, cutoff = 45)
#&amp;gt; 
#&amp;gt; Using 2^3 = 8 total bins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;imposeColors&lt;/code&gt;: Imposes colors from one image onto another image (useful for batch processing).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;colors &amp;lt;- c(&amp;quot;tomato&amp;quot;,
            &amp;quot;limegreen&amp;quot;,
            &amp;quot;dodgerblue&amp;quot;,
            &amp;quot;cornsilk&amp;quot;,
            &amp;quot;black&amp;quot;)
colors &amp;lt;- t(col2rgb(colors)) / 255
imposed &amp;lt;- imposeColors(img, centers = colors)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;refining-initial-results&#34;&gt;Refining initial results&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;recluster&lt;/code&gt;: Combines existing clusters based on either a cutoff for color similarity or a target number of colors.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;recluster_fit &amp;lt;- recluster(rc_hist, similarity_cutoff = 45)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-7-2.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;thresholdRecolor&lt;/code&gt;: Drops the smallest clusters from a &lt;code&gt;recolorize&lt;/code&gt; fit and refits the original image.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rc_thresh &amp;lt;- thresholdRecolor(rc_hist, pct = 0.01)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;wernerColor&lt;/code&gt;: Remaps a recolorize object to the colors in Werner&amp;rsquo;s Nomenclature of Colors by Patrick Syme (1821), one of the first attempts at an objective color reference in western science, notably used by Charles Darwin. This one is mostly just for fun.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rc_werner &amp;lt;- wernerColor(recluster_fit)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;minor-edits&#34;&gt;Minor edits&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;absorbLayer&lt;/code&gt;: &amp;ldquo;Absorbs&amp;rdquo; all or part of a layer into the surrounding colors, optionally according to a size or location condition.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;absorb_red &amp;lt;- absorbLayer(recluster_fit,
                          layer_idx = 3, 
                          size_condition = function(s) s &amp;lt;= 100,
                          highlight_color = &amp;quot;cyan&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;editLayer&lt;/code&gt;/&lt;code&gt;editLayers&lt;/code&gt;: Applies one of several morphological operations from &lt;code&gt;imager&lt;/code&gt; to a layer (or layers) of a &lt;code&gt;recolorize&lt;/code&gt; object. This can be used to despeckle, fill in holes, or uniformly grow or shrink a color patch.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rc_edit &amp;lt;- editLayer(absorb_red, 
                      layer_idx = 3, 
                      operation = &amp;quot;fill&amp;quot;,
                      px_size = 2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mergeLayers&lt;/code&gt;: Merges specified layers together, with options for setting the new color.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;merged_rc &amp;lt;- mergeLayers(rc_hist, merge_list = list(c(4, 7),
                                                    c(3, 5), 
                                                    c(6, 8)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;visualization&#34;&gt;Visualization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;plotImageArray&lt;/code&gt;: Plots a 1D or 3D array as an RGB image.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;layout(matrix(1:4, nrow = 1))
plotImageArray(loaded_image, main = &amp;quot;original&amp;quot;)
plotImageArray(loaded_image[ , , 1], main = &amp;quot;red&amp;quot;)
plotImageArray(loaded_image[ , , 2], main = &amp;quot;green&amp;quot;)
plotImageArray(loaded_image[ , , 3], main = &amp;quot;blue&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;imDist&lt;/code&gt; | &lt;code&gt;imHeatmap&lt;/code&gt;: Compares two versions of the same image by calculating the color distance between the colors of each pair of pixels (&lt;code&gt;imDist&lt;/code&gt;), and gives you a few more options for plotting the results (&lt;code&gt;imHeatmap&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;layout(matrix(1:2, nrow = 1))
par(mar = rep(0, 4))
im_dist &amp;lt;- imDist(im1 = raster_to_array(recluster_fit$original_img),
                  im2 = recoloredImage(recluster_fit), color_space = &amp;quot;Lab&amp;quot;)
imHeatmap(im_dist, palette = viridisLite::viridis(100), 
          legend = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;plotColorClusters&lt;/code&gt;: Plots color clusters in a 3D color space.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mar = rep(1, 4))
plotColorClusters(recluster_fit$centers, 
                  recluster_fit$sizes, 
                  color_space = &amp;quot;sRGB&amp;quot;,
                  xlab = &amp;quot;red&amp;quot;, ylab = &amp;quot;green&amp;quot;, zlab = &amp;quot;blue&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;plotColorPalette&lt;/code&gt;: Alternatively, just plot as a color palette.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;par(mar = rep(0, 4))
plotColorPalette(recluster_fit$centers, recluster_fit$sizes)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;exporting-to-other-packages-or-files&#34;&gt;Exporting to other packages or files&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;splitByColor&lt;/code&gt;: Separates color clusters into individual layers (binary masks).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;layout(matrix(1:6, nrow = 1))
plotImageArray(rc_edit$original_img)
corbetti_layers &amp;lt;- splitByColor(rc_edit, plot_method = &amp;quot;over&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;classify_recolorize&lt;/code&gt;: Converts a &lt;code&gt;recolorize&lt;/code&gt; object to a &lt;a href=&#34;https://rdrr.io/cran/pavo/man/classify.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;classify&lt;/a&gt; object in the &lt;a href=&#34;https://rdrr.io/cran/pavo/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pavo&lt;/a&gt; package for linking with spectral data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;recolorize_adjacency&lt;/code&gt;: Converts to a &lt;code&gt;classify&lt;/code&gt; object using the above function, then runs the &lt;a href=&#34;https://rdrr.io/cran/pavo/man/adjacent.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;adjacency and boundary strength analysis&lt;/a&gt; function using values for human perceptual similarity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;recolorizeVector&lt;/code&gt;: Converts a bitmap (i.e. pixel) image to a vector image.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rc_vector &amp;lt;- recolorizeVector(recluster_fit, size_filter = 0.15, smoothness = 5)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/function-gallery-for-recolorize/index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;144&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to recolorize</title>
      <link>/post/introduction-to-recolorize/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>/post/introduction-to-recolorize/</guid>
      <description>&lt;h2 id=&#34;color-based-image-segmentation-for-people-with-other-things-to-do&#34;&gt;color-based image segmentation (for people with other things to do)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You can also tour the functions in the &lt;a href=&#34;gallery.html&#34;&gt;function gallery&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;code&gt;recolorize&lt;/code&gt; package is a toolbox for making color maps, essentially color-based image segmentation, using a combination of automatic, semi-automatic, and manual procedures. It has four major goals:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Provide a middle ground between automatic segmentation methods (which are hard to modify when they don&amp;rsquo;t work well) and manual methods (which can be slow and subjective).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Be deterministic whenever possible, so that you always get the same results from the same code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Be modular and modifiable, so that you can tailor it for your purposes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Play nice with other color analysis tools.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The color map above, for example, was generated using a single function which runs in a few seconds (and is deterministic):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(recolorize)

# get the path to the image (comes with the package, so we use system.file):
img &amp;lt;- system.file(&amp;quot;extdata/corbetti.png&amp;quot;, package = &amp;quot;recolorize&amp;quot;)

# fit a color map (only provided parameter is a color similarity cutoff)
recolorize_obj &amp;lt;- recolorize2(img, cutoff = 45)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice what we didn’t have to input: we didn’t have to declare how many colors we expected (5), what we expect those colors to be (red, green, blue, black, and white), which pixels to include in each color patch, or where the boundaries of those patches are.&lt;/p&gt;
&lt;p&gt;This introduction is intended to get you up and running with the &lt;code&gt;recolorize&lt;/code&gt; package. Ideally, after reading it, you will have enough information to start to play around with the set of tools that it provides in a way that suits what you need it to do.&lt;/p&gt;
&lt;p&gt;I have tried not to assume too much about the reader&amp;rsquo;s background knowledge and needs, except that you are willing to use R and you have a color segmentation problem you have to solve before you can do something interesting with images. I primarily work with images of animals (beetles, fish, lizards, butterflies, snakes, birds, etc), and that will probably come through in the documentation. But it should work just as well for other kinds of images. Maybe better!&lt;/p&gt;
&lt;p&gt;I hope that this package will be helpful to you, and that if it is, you will share it with others who might find it helpful too. I had a lot of fun discussions with a lot of interesting people while I was making it, for which I&amp;rsquo;m very grateful.&lt;/p&gt;
&lt;p&gt;If something is unclear or you find a bug, please get in touch or &lt;a href=&#34;https://github.com/hiweller/recolorize/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;file an issue on the GitHub page&lt;/a&gt;. Suggestions for improvements are always welcome!&lt;/p&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick start&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The bare minimum to start toying around with the package.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The basic &lt;code&gt;recolorize&lt;/code&gt; workflow is initial clustering step &lt;code&gt;\(\rightarrow\)&lt;/code&gt; refinement step &lt;code&gt;\(\rightarrow\)&lt;/code&gt; manual tweaks.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Images should first be color-corrected and have any background masked out, ideally with transparency, as in the image above, for example (&lt;em&gt;Chrysochroa corbetti&lt;/em&gt;, taken by &lt;a href=&#34;https://www.thelordlab.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nathan P. Lord&lt;/a&gt;, used with permission and egregiously downsampled to ~250x150 pixels by me).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the initial clustering step, we bin all of the pixels into (in this case) 8 total clusters:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;init_fit &amp;lt;- recolorize(img, method = &amp;quot;hist&amp;quot;, bins = 2, 
                       color_space = &amp;quot;sRGB&amp;quot;)
#&amp;gt; 
#&amp;gt; Using 2^3 = 8 total bins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Followed by a refinement step where we combine clusters by their similarity:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;refined_fit &amp;lt;- recluster(init_fit, similarity_cutoff = 45)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# pretty big improvement!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;recolorize2&lt;/code&gt; function above calls these functions in sequence, since they tend to be pretty effective in combination.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Finally, we can do manual refinements to clean up the different color layers, for example absorbing the red speckles into the surrounding color patches:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;absorb_red &amp;lt;- absorbLayer(refined_fit, layer_idx = 3,
                          size_condition = function(s) s &amp;lt;= 15,
                          highlight_color = &amp;quot;cyan&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Or performing simple morphological operations on individual layers:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;final_fit &amp;lt;- editLayer(absorb_red, 3,
                        operation = &amp;quot;fill&amp;quot;, px_size = 4)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can also batch process images using the same parameters, although &lt;code&gt;recolorize&lt;/code&gt; functions only deal with one image at a time, so you will have to use a for loop or define a new function to call the appropriate functions in the right order:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# get all 5 beetle images:
images &amp;lt;- dir(system.file(&amp;quot;extdata&amp;quot;, package = &amp;quot;recolorize&amp;quot;), &amp;quot;png&amp;quot;, full.names = TRUE)

# make an empty list to store the results:
rc_list &amp;lt;- vector(&amp;quot;list&amp;quot;, length = length(images))

# run `recolorize2` on each image
# you would probably want to add more sophisticated steps in here as well, but you get the idea
for (i in 1:length(images)) {
  rc_list[[i]] &amp;lt;- suppressMessages(recolorize2(images[i], bins = 2, 
                              cutoff = 30, plotting = FALSE))
}

# plot for comparison:
layout(matrix(1:10, nrow = 2))
for (i in rc_list) {
  plotImageArray(i$original_img)
  plotImageArray(recoloredImage(i))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# given the variety of colors in the dataset, not too bad, 
# although you might go in and refine these individually
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you have a color map you&amp;rsquo;re happy with, you can export to a variety of formats. For instance, if I wanted to run Endler&amp;rsquo;s &lt;a href=&#34;https://rdrr.io/cran/pavo/man/adjacent.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;adjacency and boundary strength analysis&lt;/a&gt; in the &lt;code&gt;pavo&lt;/code&gt; package, using human perception:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;adj &amp;lt;- recolorize_adjacency(rc_list[[1]], coldist = &amp;quot;default&amp;quot;, hsl = &amp;quot;default&amp;quot;)
#&amp;gt; Using single set of coldists for all images.
#&amp;gt; Using single set of hsl values for all images.
print(adj[ , c(57:62)]) # just print the chromatic and achromatic boundary strength values
#&amp;gt;      m_dS     s_dS     cv_dS     m_dL     s_dL     cv_dL
#&amp;gt;  36.33178 11.90417 0.3276517 24.88669 17.80173 0.7153115
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you&amp;rsquo;d like a deeper explanation of each of these steps, as well as how to modify them to suit your needs, along with what else the package can do: read on!&lt;/p&gt;
&lt;h2 id=&#34;before-you-start&#34;&gt;Before you start&lt;/h2&gt;
&lt;p&gt;Color segmentation can be a real rabbit hole—that is, it can be pretty easy to become fixated on getting perfect results, or on trying to define some objective standard for what correct segmentation looks like. The problem with this mindset is that there’s no set of universal parameters that will give you perfect segmentation results for every image, because images alone don’t always contain all the relevant information: color variation due to poor lighting in one image could be just as distinct as color variation due to pattern striations in another.&lt;/p&gt;
&lt;p&gt;The correct output for color segmentation depends on your goal: are you concerned with identifying regions of structural vs. pigmented color? Does the intensity of the stain on your slide matter, or just presence/absence? If you have a few dozen stray pixels of the wrong color in an image with hundreds of thousands of correctly categorized pixels, will that meaningfully affect your calculations?&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take the jewel beetle (family Buprestidae) images that come with the package as an example. If I want to segment the lefthand image (&lt;em&gt;Chrysochroa fulgidissima&lt;/em&gt;), the solution depends on my question. If my question is &amp;ldquo;How does the placement and size of these red bands compare to that of closely related beetles?&amp;rdquo; then I really just want to separate the red bands from the rest of the body, so I would want the color map in the middle. If my question is &amp;ldquo;How much do these red bands stand out from the iridescent green base of the beetle?&amp;rdquo; then I care about the brighter orange borders of the bands, because these increase the boundary strength and overall contrast in the beetle&amp;rsquo;s visual appearance—so I would go with map 2 on the right.
&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So before you start, I highly recommend writing down &lt;em&gt;precisely&lt;/em&gt; what you want to measure at the end of your analysis, to avoid becoming weighed down by details that may not matter. It will save you a lot of time.&lt;/p&gt;
&lt;h2 id=&#34;step-0-image-acquisition--preparation&#34;&gt;Step 0: Image acquisition &amp;amp; preparation&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;What to do before you use recolorize.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Before we attempt image segmentation, we need segmentable images. &lt;code&gt;recolorize&lt;/code&gt; doesn’t process your images for you beyond a few basic things like resizing, rotating, and blurring (which can help with segmentation). You should do all image processing steps which are usually necessary for getting quantitative color data, like white balance correction, gradient correction, or background removal, before inputting them to &lt;code&gt;recolorize&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There are lots of software tools available for making these kinds of corrections: GIMP, FIJI/ImageJ, and even the imager package will provide options for some or all of these. If you really want to get pipeline-y, Python has a much more robust set of image processing libraries that will help with automatic color correction and background masking, which is well beyond the scope of this intro.&lt;/p&gt;
&lt;p&gt;If you are at all concerned with sensory biology and animal vision, I highly recommend &lt;a href=&#34;http://www.empiricalimaging.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;micaToolbox&lt;/a&gt;, which is a well-documented and comprehensive toolkit for creating images as animals see them (rather than as cameras and computers see them); see especially the instructions for creating false color &lt;a href=&#34;http://www.empiricalimaging.com/knowledge-base/creating-cone-catch-models/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cone-mapped images&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The corrections you have to make really depend on what you’re trying to do. If you just care about the regions but don’t really care about the final colors they end up being assigned, you probably don’t need to worry too much about color correction; if you’re working with histology slides, you probably don’t need to mask the background; if you have a really even and diffuse lighting setup, you probably won’t have to deal with shadows or gradients.&lt;/p&gt;
&lt;h3 id=&#34;background-masking-with-transparencies&#34;&gt;Background masking with transparencies&lt;/h3&gt;
&lt;p&gt;If you’re masking the background, use transparencies. This is pretty easy to do in GIMP, Photoshop, or ImageJ. The transparency layer (or alpha channel) is the fourth channel of an image (the other three being the R, G, and B channels), and &lt;code&gt;recolorize&lt;/code&gt; treats it like a binary mask: any pixel with an alpha value of 1 is retained, and any pixel with an alpha value of &amp;lt; 1 is ignored. This means you don’t have to worry about finding a uniform background color that is sufficiently different from your foreground object in every image, which can otherwise be a real pain.&lt;/p&gt;
&lt;p&gt;Using transparency is unambiguous, and has the bonus benefit of making for nicer plots, too, since you don’t have to worry about the corners of your images overlapping and blocking each other. All the images in this demo have transparent backgrounds. However, you can use the lower and upper arguments to set boundaries for excluding pixels as background based on their color (see documentation). Just know that these will be set to transparent internally.&lt;/p&gt;
&lt;h2 id=&#34;step-1-loading--processing-images&#34;&gt;Step 1: Loading &amp;amp; processing images&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;How to get images into R.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We can read in an image by passing the filepath to the &lt;code&gt;readImage&lt;/code&gt; function. This is a pretty generic function (almost every image processing package in R has something similar); the &lt;code&gt;recolorize&lt;/code&gt; version doesn&amp;rsquo;t even assign the output to a special class (so don&amp;rsquo;t try to print it).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# define image path - we&#39;re using an image that comes with the package
img_path &amp;lt;- system.file(&amp;quot;extdata/corbetti.png&amp;quot;, package = &amp;quot;recolorize&amp;quot;)

# load image
img &amp;lt;- readImage(img_path, resize = NULL, rotate = NULL)

# it&#39;s just an array with 4 channels:
dim(img)
#&amp;gt; [1] 243 116   4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An image is a numeric array with either 3 or 4 channels (R, G, B, and optionally alpha for transparency). JPG images will only have 3 channels; PNG images will have 4. This is quite a small image (243x116 pixels) with 4 channels.&lt;/p&gt;
&lt;p&gt;We can plot the whole array as an image, or plot one channel at a time. Notice that the red patches are bright in the R channel, same for blue-B channel, green-G channel, etc—and that the off-white patch is bright for all channels, while the black patches are dark in all channels. The alpha channel is essentially just a mask that tells us which parts of the image to ignore when processing it further.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;layout(matrix(1:5, nrow = 1))
plotImageArray(img, main = &amp;quot;RGB image&amp;quot;)
plotImageArray(img[ , , 1], main = &amp;quot;R channel&amp;quot;)
plotImageArray(img[ , , 2], main = &amp;quot;G channel&amp;quot;)
plotImageArray(img[ , , 3], main = &amp;quot;B channel&amp;quot;)
plotImageArray(img[ , , 4], main = &amp;quot;Alpha channel&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Optionally, when you load the image, you can resize it (highly recommended for large images) and rotate it. Image processing is computationally intensive, and R is not especially good at it, so downsampling it usually a good idea. A good rule of thumb for downsampling is that you want the smallest details you care about in the image (say, spots on a ladybug) to be about 5 pixels in diameter (so if your spots have a 20 pixel diameter, you can set &lt;code&gt;resize = 0.25&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;The only other thing you might do to your images before sending them to the main &lt;code&gt;recolorize&lt;/code&gt; functions is &lt;code&gt;blurImage&lt;/code&gt;. This is really useful for minimizing color variation due to texture (e.g. scales on a lizard, feathers on a bird, sensory hairs on an insect), and you can apply one of several smoothing algorithms from the &lt;code&gt;imager&lt;/code&gt; package, including edge-preserving blurs:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;blurred_img &amp;lt;- blurImage(img, blur_function = &amp;quot;blur_anisotropic&amp;quot;,
                         amplitude = 10, sharpness = 0.2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This step is optional: most of the &lt;code&gt;recolorize&lt;/code&gt; functions will accept a path to an image as well as an image array. But once you&amp;rsquo;re happy here, we can start defining color regions!&lt;/p&gt;
&lt;h2 id=&#34;step-2-initial-clustering&#34;&gt;Step 2: Initial clustering&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Go from thousands of colors to a manageable number for further refinement.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The color clustering in recolorize usually starts with an initial clustering step which produces more color clusters than the final color map will have, which are then edited and combined to form the final color map. We start with an over-clustering step because it is a quick way to go from an overwhelming number of colors (256^3 unique RGB colors) to a manageable number that can be manually inspected or automatically re-clustered. You’ll usually do this using the &lt;code&gt;recolorize&lt;/code&gt; function, which is the core of the package (go figure!):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;corbetti &amp;lt;- system.file(&amp;quot;extdata/corbetti.png&amp;quot;, package = &amp;quot;recolorize&amp;quot;)
recolorize_defaults &amp;lt;- recolorize(img = corbetti)
#&amp;gt; 
#&amp;gt; Using 2^3 = 8 total bins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This function does a lot under the hood: we read in the image as an array, binned every pixel in the image into one of eight bins in RGB color space, calculated the average color of all the pixels assigned to a given bin, recolored the image to show which pixel was assigned to which color center, and returned all of that information in the &lt;code&gt;recolorize_defaults&lt;/code&gt; object. Pretty much everything beyond this step will be a modification of one of those elements, so we&amp;rsquo;ll take a second to examine the contents of that output.&lt;/p&gt;
&lt;h3 id=&#34;the-recolorize-class&#34;&gt;The &lt;code&gt;recolorize&lt;/code&gt; class&lt;/h3&gt;
&lt;p&gt;Objects of S3 class &lt;code&gt;recolorize&lt;/code&gt; are lists with several elements:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;attributes(recolorize_defaults)
#&amp;gt; $names
#&amp;gt; [1] &amp;quot;original_img&amp;quot;      &amp;quot;centers&amp;quot;           &amp;quot;sizes&amp;quot;            
#&amp;gt; [4] &amp;quot;pixel_assignments&amp;quot;
#&amp;gt; 
#&amp;gt; $class
#&amp;gt; [1] &amp;quot;recolorize&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;original_img&lt;/code&gt; is a a &lt;code&gt;raster&lt;/code&gt; matrix, essentially a matrix of hex color codes. This is a more lightweight version of the 3D/4D color image array we loaded earlier, and can be plotted easily by running &lt;code&gt;plot(recolorize_defaults$original_img)&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;centers&lt;/code&gt; is a matrix of RGB centers (0-1 range) for each of the color patches. Their order matches the index values in the &lt;code&gt;pixel_assignments&lt;/code&gt; matrix.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;sizes&lt;/code&gt; is a vector of patch sizes, whose order matches the row order of &lt;code&gt;centers&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;pixel_assignments&lt;/code&gt; is a paint-by-numbers matrix, where each pixel is coded as the color center to which it was assigned. For example, cells with a &lt;code&gt;1&lt;/code&gt; have been assigned to the color represented by row 1 of &lt;code&gt;centers&lt;/code&gt;. Background pixels are marked as 0.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you plot the whole &lt;code&gt;recolorize&lt;/code&gt; object, you&amp;rsquo;ll get back the plot you see above: the original image, the color map (where each pixel has been recolored), and the color palette. You can also plot each of these individually:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;layout(matrix(1:3, nrow = 1), widths = c(0.45, 0.45, 0.1))
par(mar = rep(0, 4))
plot(recolorize_defaults$original_img)
plotImageArray(recolorize_defaults$pixel_assignments / 8)
plotColorPalette(recolorize_defaults$centers, recolorize_defaults$sizes,
                 horiz = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll notice this doesn&amp;rsquo;t look exactly like the function output above. Aside from some wonky scaling issues, the pixel assignment matrix plotted as a grayscale image (and we had to divide it by the number of colors in the image so it was in a 0-1 range). That&amp;rsquo;s because we didn&amp;rsquo;t tell R which colors to make each of those values, so layer 1 is the darkest color and layer 8 is the brightest color in the image.&lt;/p&gt;
&lt;p&gt;You can get the recolored image by calling &lt;code&gt;recoloredImage&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# type = raster gets you a raster (like original_img); type = array gets you an 
# image array
recolored_img &amp;lt;- recoloredImage(recolorize_defaults, type = &amp;quot;array&amp;quot;)
plotImageArray(recolored_img)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;192&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;recoloredImage&lt;/code&gt; is just a shortcut function for &lt;code&gt;constructImage&lt;/code&gt;, which lets you decide which colors to assign to each category in case you want to swap out the palette:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;colors &amp;lt;- c(&amp;quot;navy&amp;quot;, &amp;quot;lightblue&amp;quot;, &amp;quot;blueviolet&amp;quot;,
            &amp;quot;turquoise&amp;quot;, &amp;quot;slateblue&amp;quot;, &amp;quot;royalblue&amp;quot;, 
            &amp;quot;aquamarine&amp;quot;, &amp;quot;dodgerblue&amp;quot;)
blue_beetle &amp;lt;- constructImage(recolorize_defaults$pixel_assignments, 
               centers = t(col2rgb(colors) / 255))

# a very blue beetle indeed:
plotImageArray(blue_beetle)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;192&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now that you have a better understanding of what these objects contain and what to do with them, we can start to unpack exactly what this function is doing.&lt;/p&gt;
&lt;h3 id=&#34;the-recolorize-function&#34;&gt;The &lt;code&gt;recolorize&lt;/code&gt; function&lt;/h3&gt;
&lt;p&gt;The main &lt;code&gt;recolorize&lt;/code&gt; function has a simple goal: to take your image from a huge number of colors to a manageable number of color clusters. This falls under a category of methods for &lt;a href=&#34;https://en.wikipedia.org/wiki/Color_quantization&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;color quantization&lt;/a&gt;, although we have a slightly different goal here. The typical reason for doing color quantization is to simplify an image while making it look as visually similar as possible to the original; our goal is not to represent the original image, but to create a set of building blocks to combine and clean up so we can refer to whole color patches easily.&lt;/p&gt;
&lt;p&gt;If you look at the documentation for the &lt;code&gt;recolorize&lt;/code&gt; function, you’ll see a lot of user-specifiable parameters. There are only really 3 major ones:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the color space in which the clustering is done (&lt;code&gt;color_space&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;the clustering method (the &lt;code&gt;method&lt;/code&gt; argument)&lt;/li&gt;
&lt;li&gt;the number of color clusters (&lt;code&gt;bins&lt;/code&gt; for &lt;code&gt;method = hist&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt; for &lt;code&gt;method = kmeans&lt;/code&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can also map an image to an externally imposed set of colors using another function, &lt;code&gt;imposeColors&lt;/code&gt;, which can be useful for batch processing images.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll go over each of these parameters and what they do. I&amp;rsquo;ll give mild advice about how to navigate these options, but there&amp;rsquo;s a reason I&amp;rsquo;ve included all of theme here, which is that I think any combination of these parameters can be useful depending on the context.&lt;/p&gt;
&lt;h4 id=&#34;color-spaces&#34;&gt;Color spaces&lt;/h4&gt;
&lt;p&gt;Color spaces are ways to represent colors as points in multi-dimensional spaces, where each axis corresponds to some aspect of the color. You&amp;rsquo;re probably familiar with RGB (red-green-blue) color space and HSV (hue-saturation-value) color space. In RGB space, colors vary by the amount of red, green, and blue they have, where a coordinate of [0, 0, 1] would be pure blue (no red or green), [1, 1, 1] would be white, [0, 1, 1] would be cyan, etc. This is how most images are stored and displayed on computers, although it&amp;rsquo;s not always very intuitive.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;recolorize&lt;/code&gt; package gives you a variety of options for color spaces, but by far the two most commonly used are RGB (&lt;code&gt;color_space = sRGB&lt;/code&gt;) and CIE Lab (&lt;code&gt;color_space = Lab&lt;/code&gt;). CIE Lab is popular because it approximates perceptual uniformity, which means that the distances between colors in CIE Lab space are proportional to how different they actually seem to human beings. The axes represent luminance (L, 0 = black and 100 = white), red-green (a, negative values = more green and positive values = more red), and blue-yellow (b, negative values = more blue and positive values = more yellow). The idea is that something can be greenish-blue, or reddish-yellow, but not reddish-green, etc. This can be a little confusing, but the results it provides are really intuitive. For example, in RGB space, red is as similar to yellow as it is to black. In CIE Lab, red and yellow are close together, and are about equally far from black.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve written in more detail about color spaces for another package &lt;a href=&#34;https://cran.r-project.org/web/packages/colordistance/vignettes/color-spaces.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, which I would recommend reading for a more detailed overview, but let&amp;rsquo;s see what happens if we plot all of the non-background pixels from our &lt;em&gt;C. corbetti&lt;/em&gt; example in RGB compared to CIE Lab color space (forgive the crummy plotting):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-19-2.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can identify green, red, blue, black, and white pixels in both sets of plots, but their distributions are very different.&lt;/p&gt;
&lt;p&gt;In practice, I find myself toggling between these two color spaces depending on the color distributions in my images. For example, when dealing with &lt;em&gt;C. corbetti&lt;/em&gt;, I would use RGB, because the beetle is literally red, green, and blue. When dealing with the red and green &lt;em&gt;C. fulgidissima&lt;/em&gt; above, I found that CIE Lab produced better results, because it separates red and green pixels by much more distance. But in general, especially as you increase the number of initial clusters, this matters less at this stage than at the refinement stage (where you can switch between color spaces again). Because CIE Lab is not evenly distributed on all axes (i.e. is not a cube), you may need to use more bins in CIE Lab space than in RGB. (Try fitting the &lt;em&gt;C. corbetti&lt;/em&gt; image with CIE Lab space and see what happens for an idea of how much the choice of color space can matter.)&lt;/p&gt;
&lt;h4 id=&#34;clustering-methods&#34;&gt;Clustering methods&lt;/h4&gt;
&lt;p&gt;The two clustering methods in &lt;code&gt;recolorize&lt;/code&gt; are color histogram binning (fast, consistent, and deterministic) and k-means clustering (comparatively slower and heuristic, but more intuitive). The &lt;code&gt;bins&lt;/code&gt; argument is accessed by the histogram method, and &lt;code&gt;n&lt;/code&gt; goes with the kmeans method. I highly recommend the histogram binning unless you have a good reason not to use it, but there are good reasons to use k-means clustering sometimes.&lt;/p&gt;
&lt;p&gt;The histogram binning method is essentially just a 3-dimensional color histogram: we divide up each channel of a color space into a predetermined number of bins, then count the number of pixels that fall into that bin and calculate their average color. So, when we divide each of 3 color channels into 2 bins, we end up with &lt;code&gt;\(2^3 = 8\)&lt;/code&gt; total bins (which is why setting &lt;code&gt;bins = 2&lt;/code&gt; will produce 8 colors as above).&lt;/p&gt;
&lt;p&gt;k-means clustering, on the other hand, is a well-known method for partitioning data into n clusters. You just provide the number of clusters you want, and it will try to find the best locations for them, where ‘best’ means minimizing the squared Euclidean distances between pixels and color centers within each cluster.&lt;/p&gt;
&lt;p&gt;To appreciate these differences, we can fit the same number of colors (64) using the histogram method and the k-means method on the same image, then view the resulting color distributions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# fit 64 colors, both ways
r_hist &amp;lt;- recolorize(img_path, method = &amp;quot;hist&amp;quot;, bins = 4, plotting = FALSE)
#&amp;gt; 
#&amp;gt; Using 4^3 = 64 total bins
r_k &amp;lt;- recolorize(img_path, method = &amp;quot;k&amp;quot;, n = 64, plotting = FALSE)

plotColorClusters(r_hist$centers, r_hist$sizes, plus = .5,
                  xlab = &amp;quot;red&amp;quot;, ylab = &amp;quot;green&amp;quot;, zlab = &amp;quot;blue&amp;quot;, 
                  mar = c(3, 3, 2, 2),
                  main = &amp;quot;Histogram method&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plotColorClusters(r_k$centers, r_k$sizes, plus = .5,
                  xlab = &amp;quot;red&amp;quot;, ylab = &amp;quot;green&amp;quot;, zlab = &amp;quot;blue&amp;quot;,
                  mar = c(3, 3, 2, 2),
                  main = &amp;quot;k-means clustering&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-20-2.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The histogram method produced a lot of tiny, nearly-empty clusters that are evenly distributed in the color space, with only a few large clusters (like the black and white ones). The k-means clustering method, on the other hand, produced a lot more medium-sized clusters, as well as splitting the black and white patches across multiple clusters.&lt;/p&gt;
&lt;p&gt;A lot of color segmentation tools will &lt;em&gt;only&lt;/em&gt; use k-means clustering (or a similar method), because it’s relatively easy to implement and does produce good results if your images have clear color boundaries and very different colors (i.e. the pixels are far apart in color space). If you were going to stop at the initial clustering step, this would probably be a better option than the histogram binning for that reason. The main reason I recommend against it is that it is not deterministic: you will get different colors, and in a different order, every time you run it. For example, if we fit 10 colors three separate times, we get the following color palettes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;k_list &amp;lt;- lapply(1:3, function(i) recolorize(img_path, &amp;quot;k&amp;quot;, n = 10, plotting = F))

layout(1:3)
par(mar = rep(1, 4))
lapply(k_list, function(i) plotColorPalette(i$centers, i$sizes))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [[1]]
#&amp;gt; NULL
#&amp;gt; 
#&amp;gt; [[2]]
#&amp;gt; NULL
#&amp;gt; 
#&amp;gt; [[3]]
#&amp;gt; NULL
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The colors are similar, but not identical, and they are returned in an arbitrary order. If you run this code one day and pull out all the red clusters by their index, or merge the multiple green clusters, those values will change the next time you run the code. That and the need to specify cluster numbers for each image are more or less why I recommend not using this method unless you have a reason.&lt;/p&gt;
&lt;p&gt;Binning the colors (histograms) is usually more viable as a first step. It’s quite fast, since we’re not really doing any clustering; the bins we assign the pixels to will be the same for every image, and we’re not calculating the distances between the pixels and their assigned color. It’s also deterministic, which means you get the same result every single time you run it. The downside is that makes this approach almost guaranteed to over-split colors, since your color regions will rarely fall cleanly within the boundaries of these bins, and many of the bins you end up with will be empty or have very few pixels.&lt;/p&gt;
&lt;h3 id=&#34;number-of-clusters&#34;&gt;Number of clusters&lt;/h3&gt;
&lt;p&gt;Unlike the color space and binning method, this parameter is pretty intuitive: the more clusters you fit, the more the colors in your image will be split up. It’s convenient to use the same scheme for every image in your dataset, so you might end up using whatever values are needed for your most complex image and over-splitting most of your other images. That’s usually fine, because the next set of steps will try to lump colors together or remove minor details. You want to be just granular enough to capture the details you care about, and it’s okay if some colors are split up.&lt;/p&gt;
&lt;p&gt;One thing to note is that the &lt;code&gt;bins&lt;/code&gt; argument allows for a different number of bins for each channel. Setting &lt;code&gt;bins = 2&lt;/code&gt; will divide each channel into 2 bins, but you can also set &lt;code&gt;bins = c(5, 2, 2)&lt;/code&gt; to divide up the red channel into 5 bins and the blue and green channels into 2 bins (if in RGB space). This can be convenient if you have a lot of color diversity on only one axis, e.g. you have photographs of mammals which are shades of reddish-brown, and don&amp;rsquo;t need to waste computational time dividing up the blue channel.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# we can go from an unacceptable to an acceptable color map in 
# CIE Lab space by adding a single additional bin in the luminance channel:
r_hist_2 &amp;lt;- recolorize(img_path, method = &amp;quot;hist&amp;quot;, color_space = &amp;quot;Lab&amp;quot;, 
                     bins = 2)
#&amp;gt; 
#&amp;gt; Using 2^3 = 8 total bins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;r_hist_322 &amp;lt;- recolorize(img_path, 
                     method = &amp;quot;hist&amp;quot;,
                     bins = c(3, 2, 2))
#&amp;gt; 
#&amp;gt; Using 3*2*2 = 12 bins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-22-2.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;imposecolors&#34;&gt;&lt;code&gt;imposeColors()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Another option is to impose colors on an image, rather than using intrinsic image colors. Every pixel is assigned to the color it is closest to in some specified color space. Usually, this is useful for batch processing: you get colors from one image, then map them onto another image, so that the color centers correspond across all your images.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;im1 &amp;lt;- system.file(&amp;quot;extdata/ocellata.png&amp;quot;, package = &amp;quot;recolorize&amp;quot;)
im2 &amp;lt;- system.file(&amp;quot;extdata/ephippigera.png&amp;quot;, package = &amp;quot;recolorize&amp;quot;)

# fit the first image
fit1 &amp;lt;- recolorize(im1)
#&amp;gt; 
#&amp;gt; Using 2^3 = 8 total bins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
# fit the second image using colors from the first
# adjust_centers = TRUE would find the average color of all the pixels assigned to 
# the imposed colors to better match the raw image
fit2 &amp;lt;- imposeColors(im2, fit1$centers, adjust_centers = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-23-2.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-3-refinement&#34;&gt;Step 3: Refinement&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Using simple rules to improve the initial results.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Once we’ve reduced an image down to a tractable number of colors, we can define simple procedures for how to combine them based on similarity. &lt;code&gt;recolorize&lt;/code&gt; (currently) comes with two of these: &lt;code&gt;recluster&lt;/code&gt;, which merges colors by perceived similarity, and &lt;code&gt;thresholdRecolor&lt;/code&gt;, which drops minor colors. Both are simple, but surprisingly effective. They’re also built on top of some really simple functions we’ll see in a bit, so if you need to, you can build out a similar procedure tailored to your dataset—for example, combining layers based only on their brightness values, or only combining green layers.&lt;/p&gt;
&lt;h3 id=&#34;recluster-and-recolorize2&#34;&gt;&lt;code&gt;recluster()&lt;/code&gt; and &lt;code&gt;recolorize2()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;This is the one I use the most often, and its implementation is really simple. This function calculates the Euclidean distances between all the color centers in a recolorize object, clusters them hierarchically using &lt;code&gt;hclust&lt;/code&gt;, then uses a user-specified cutoff to combine the most similar colors. As with &lt;code&gt;recolorize&lt;/code&gt;, you can choose your color space, and that will make a big difference. Let’s see this in action:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;recluster_results &amp;lt;- recluster(recolorize_defaults, 
                               similarity_cutoff = 45)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-24-2.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice the color dendrogram: it lumped together clusters 4 &amp;amp; 7, clusters 3 &amp;amp; 5, and clusters 6 &amp;amp; 8, because their distance was less than 45. This is in CIE Lab space; if we use RGB space, the range of distances is 0-1:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;recluster_rgb &amp;lt;- recluster(recolorize_defaults, color_space = &amp;quot;sRGB&amp;quot;,
                           similarity_cutoff = 0.5)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-25-2.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this case, we get the same results, but this is always worth playing around with. Despite its simplicity, this function is highly effective at producing intuitive results. This is partly because, in only using color similarity to combine clusters, it does not penalize smaller color clusters that can still retain important details. I find myself using it so often that I included a wrapper function, &lt;code&gt;recolorize2&lt;/code&gt;, to run &lt;code&gt;recolorize&lt;/code&gt; and &lt;code&gt;recluster&lt;/code&gt; sequentially in a single step:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# let&#39;s use a different image:
img &amp;lt;- system.file(&amp;quot;extdata/chongi.png&amp;quot;, package = &amp;quot;recolorize&amp;quot;)

# this is identical to running:
# fit1 &amp;lt;- recolorize(img, bins = 3)
# fit2 &amp;lt;- recluster(fit1, similarity_cutoff = 50)
chongi_fit &amp;lt;- recolorize2(img, bins = 3, cutoff = 45)
#&amp;gt; 
#&amp;gt; Using 3^3 = 27 total bins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-26-2.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There’s also a lot of room for modification here: this is a pretty unsophisticated rule for combining color clusters (ignoring, for example, cluster size, proximity, geometry, and boundary strength), but it’s pretty simple to write better rules if you can think of them, because the functions that are called to implement this are also exported by the package.&lt;/p&gt;
&lt;h3 id=&#34;thresholdrecolor&#34;&gt;&lt;code&gt;thresholdRecolor()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;An even simpler rule: drop the smallest color clusters whose cumulative sum (as a proportion of total pixels assigned) is lower than some threshold, like 5% of the image. I thought this would be too simple to be useful, but every once in a while it’s just the thing, especially if you always end up with weird spurious details.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chongi_threshold &amp;lt;- thresholdRecolor(chongi_fit, pct = 0.1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-4-minor-edits&#34;&gt;Step 4: Minor edits&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Cleaning up the details.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;These are functions that can be called individually to address problem areas in specific images, or strung together as building blocks to do more complicated operations.&lt;/p&gt;
&lt;h3 id=&#34;absorblayer&#34;&gt;&lt;code&gt;absorbLayer&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&amp;ldquo;Absorbs&amp;rdquo; all or part of a layer into the surrounding colors, optionally according to a size or location condition.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;img &amp;lt;- system.file(&amp;quot;extdata/fulgidissima.png&amp;quot;, package = &amp;quot;recolorize&amp;quot;)
ful_init &amp;lt;- recolorize2(img, bins = 3, cutoff = 60, plotting = F)
#&amp;gt; 
#&amp;gt; Using 3^3 = 27 total bins
ful_absorb &amp;lt;- absorbLayer(ful_init, layer_idx = 3, 
                          function(s) s &amp;lt;= 250,
                          y_range = c(0, 0.8), 
                          highlight_color = &amp;quot;cyan&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This function is really useful, but fair warning: it can be quite slow. It works by finding the color patch with which each highlighted component shares the longest border and switching the highlighted component to that color, which is more sophisticated than simply switching the patch color, but requires many more calculations. If you find yourself using this a lot, it&amp;rsquo;s a good idea to make sure you&amp;rsquo;ve downsampled your images using the &lt;code&gt;resize&lt;/code&gt; argument.&lt;/p&gt;
&lt;h3 id=&#34;editlayereditlayers&#34;&gt;&lt;code&gt;editLayer&lt;/code&gt;/&lt;code&gt;editLayers&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Applies one of several morphological operations from &lt;code&gt;imager&lt;/code&gt; to a layer (or layers) of a &lt;code&gt;recolorize&lt;/code&gt; object. This can be used to despeckle, fill in holes, or uniformly grow or shrink a color patch. In practice, this is mostly only useful for fixing small imperfections; anything too drastic tends to alter the overall shape of the patch.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# cleans up some of the speckles in the above output
ful_clean &amp;lt;- editLayers(ful_absorb, layer_idx = c(2, 5),
                        operations = &amp;quot;fill&amp;quot;, px_sizes = 3, plotting = T)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This function is also easy to modify. Internally, it splits the color map into individual masks using &lt;code&gt;splitByColor()&lt;/code&gt; (another recolorize function), then converts those to pixsets for use in &lt;code&gt;imager&lt;/code&gt; before slotting them back in with the unchanged layers.&lt;/p&gt;
&lt;h3 id=&#34;mergelayers&#34;&gt;&lt;code&gt;mergeLayers&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Sometimes, you don’t want to define fancy rules for deciding which layers to combine; you just want to combine layers. That’s what this function is for. It takes in a list of numeric vectors for layers to combine (layers in the same vector are combined; those in different list elements are kept separate).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;merge_fit &amp;lt;- mergeLayers(recolorize_defaults, 
                         merge_list = list(1, 2, 
                                           c(3, 5),
                                           c(4, 7),
                                           c(6, 8)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-30-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You might notice this is a bit different than our &lt;code&gt;recluster&lt;/code&gt; results above. That’s because internally, &lt;code&gt;recluster&lt;/code&gt; actually uses &lt;code&gt;imposeColors&lt;/code&gt; to refit the color map, rather than just merging layers; I have found this often produces slightly nicer results, because pixels that were on the border of one cutoff or another don’t get stranded in the wrong layer. On the other hand, &lt;code&gt;mergeLayers&lt;/code&gt; is considerably faster.&lt;/p&gt;
&lt;h2 id=&#34;step-45-visualizations&#34;&gt;Step 4.5: Visualizations&lt;/h2&gt;
&lt;p&gt;Making color maps is an obviously visual process, so it’s good to use visual feedback as much as possible. We’ve already seen a few of these functions in action, specifically &lt;code&gt;plotColorPalette&lt;/code&gt; and &lt;code&gt;plotImageArray&lt;/code&gt;, which are used in almost every function that produces a &lt;code&gt;recolorize&lt;/code&gt; object. I’ll point out three others that I think are quite useful: &lt;code&gt;imDist&lt;/code&gt;, &lt;code&gt;plotColorClusters&lt;/code&gt;, and &lt;code&gt;splitByColor&lt;/code&gt; (which also doubles as an export function).&lt;/p&gt;
&lt;h3 id=&#34;imdist&#34;&gt;&lt;code&gt;imDist&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Compares two versions of the same image by calculating the color distance between the colors of each pair of pixels (&lt;code&gt;imDist&lt;/code&gt;), and gives you a few more options for plotting the results (&lt;code&gt;imHeatmap&lt;/code&gt;). You can use it to get the distances between the original image and the color map:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;layout(matrix(1:2, nrow = 1))

# calculates the distance matrix and plots the results
dist_original &amp;lt;- imDist(readImage(img),
                        recoloredImage(ful_clean), color_space = &amp;quot;sRGB&amp;quot;)

# more plotting options - setting the range is important for comparing 
# across images (max is sqrt(3) in sRGB space, ~120 in Lab)
imHeatmap(dist_original, viridisLite::inferno(100), range = c(0, sqrt(3)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The resulting object is a simple matrix of distances between each pair of pixels in the given color space. These are essentially residuals:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(dist_original, main = &amp;quot;sRGB distances&amp;quot;, xlab = &amp;quot;Distance&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A word of warning here: it is easy to look at this and decide to come up with a procedure for automatically fitting color maps using a kind of AIC metric, trying to get the lowest SSE with the minimum set of color centers. You’re welcome to try that, but given that this is discarding spatial information, it is probably not a general solution (I haven’t had much luck with it). But there is probably some room to play here.&lt;/p&gt;
&lt;h3 id=&#34;splitbycolor&#34;&gt;&lt;code&gt;splitByColor&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;This is a dual-use function: by splitting up the color map into individual layers, you not only can examine the individual layers and decide whether they need any editing or merging, but you also get out a binary mask representing each layer, so you can export individual patches.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;layout(matrix(1:10, nrow = 2, byrow = TRUE))

# &#39;overlay&#39; is not always the clearest option, but it is usually the prettiest:
layers &amp;lt;- splitByColor(recluster_results, plot_method = &amp;quot;overlay&amp;quot;)

# layers is a list of matrices, which we can just plot:
lapply(layers, plotImageArray)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-33-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; [[1]]
#&amp;gt; [[1]]$mar
#&amp;gt; [1] 0 0 2 0
#&amp;gt; 
#&amp;gt; 
#&amp;gt; [[2]]
#&amp;gt; [[2]]$mar
#&amp;gt; [1] 0 0 2 0
#&amp;gt; 
#&amp;gt; 
#&amp;gt; [[3]]
#&amp;gt; [[3]]$mar
#&amp;gt; [1] 0 0 2 0
#&amp;gt; 
#&amp;gt; 
#&amp;gt; [[4]]
#&amp;gt; [[4]]$mar
#&amp;gt; [1] 0 0 2 0
#&amp;gt; 
#&amp;gt; 
#&amp;gt; [[5]]
#&amp;gt; [[5]]$mar
#&amp;gt; [1] 0 0 2 0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;step-5-exporting&#34;&gt;Step 5: Exporting&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The whole point of this package is to make it easier to use other methods!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;exporting-to-aimges&#34;&gt;Exporting to aimges&lt;/h3&gt;
&lt;p&gt;The most direct thing you can do is simply export your recolored images as images, then pass those to whatever other tool you’d like to use, although obviously this doesn’t take full advantage of the format:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# export color map
png::writePNG(recoloredImage(recluster_results),
              target = &amp;quot;recolored_corbetti.png&amp;quot;)

# export individual layers from splitByColor
for (i in 1:length(layers)) {
  png::writePNG(layers[[i]],
                target = paste0(&amp;quot;layer_&amp;quot;, i, &amp;quot;.png&amp;quot;))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;pavohttpsrdrriocranpavomanpavo-packagehtml-package&#34;&gt;&lt;a href=&#34;https://rdrr.io/cran/pavo/man/pavo-package.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pavo&lt;/a&gt; package&lt;/h3&gt;
&lt;p&gt;You can also convert a recolorize object to a classify object in the wonderful &lt;code&gt;pavo&lt;/code&gt; package and then run an adjacency analysis. Bonus points if you have reflectance spectra for each of your color patches: by combining the spatial information in the color map with the &lt;code&gt;coldist&lt;/code&gt; object generated by spectral measurements, you can run adjacency analysis for the visual system(s) of your choice right out of the box!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# convert to a classify object
as_classify &amp;lt;- classify_recolorize(recluster_results, imgname = &amp;quot;corbetti&amp;quot;)
adj_analysis &amp;lt;- pavo::adjacent(as_classify, xscale = 10)

# run adjacent directly using human perceptual color distances (i.e. no spectral data - proceed with caution)
adj_human &amp;lt;- recolorize_adjacency(recluster_results)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also run an adjacency analysis with &lt;code&gt;recolorize_adjacency&lt;/code&gt;, but only as long as you keep your skeptic hat on. This function works by calculating a &lt;code&gt;coldist&lt;/code&gt; object right from the CIE Lab colors in the color maps, which are themselves probably derived from your RGB image, which is at best a very loose representation of how these colors appear to human eyes. The only reason this is at all reasonable is that it’s producing these values for human vision, so you will be able to see if it’s completely unreasonable. This is fine for getting some preliminary results or if you’re working with aggregate data from many sources and you’re content with specifically human (not just non-UV, but only human) vision. Otherwise, it’s probably a last resort.&lt;/p&gt;
&lt;h3 id=&#34;patternizehttpscranr-projectorgwebpackagespatternizeindexhtml&#34;&gt;&lt;a href=&#34;https://cran.r-project.org/web//packages/patternize/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;patternize&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Coming soon (pending a patternize update), and with many thanks to Steven van Belleghem for his help in making recolorize and patternize get along!&lt;/p&gt;
&lt;h2 id=&#34;some-advice&#34;&gt;Some advice&lt;/h2&gt;
&lt;h3 id=&#34;this-is-a-lot-of-options-how-do-i-choose-a-procedure&#34;&gt;This is a lot of options. How do I choose a procedure?&lt;/h3&gt;
&lt;p&gt;Most things will more or less work; if it looks reasonable, it is. Keep in mind that there is a big difference between getting slightly different color maps and getting qualitatively different results. Keep your final goal in mind. You can also try lots of different things and see if it makes a real difference.&lt;/p&gt;
&lt;p&gt;I wish I could write a single function that would do all of these steps in the correct sequence and produce perfect results; the reason that function does not exist is because I find I have to do experiment a fair amount with every image set, and I often end up with a different order of operations depending on the problem.&lt;/p&gt;
&lt;p&gt;Start with &lt;code&gt;recolorize2&lt;/code&gt; and identify the common problems you&amp;rsquo;re encountering. Does it make sense to batch process all of your images, then refine them individually? Is it better to choose a different cutoff for each image? Luckily, these functions are relatively fast, so you can test out different options.&lt;/p&gt;
&lt;p&gt;You can also get way fancier with cutoffs than I have here. This package is built on some pretty simple scaffolding: you get a starting set of clusters, then you modify them. If you have a better/more refined way of deciding which colors to cluster, then go for it. I will soon be adding some example workflows from collaborators which should be helpful.&lt;/p&gt;
&lt;p&gt;There is another very tempting option: make a small training set of nice color maps manually with recolorize, then use those to either fit a statistical model for other fits or use machine learning to do the rest. I think this is a really compelling idea; I just haven&amp;rsquo;t tested it yet. Maybe you want to try it out?&lt;/p&gt;
&lt;h3 id=&#34;can-you-define-an-optimality-condition-to-do-all-the-segmentation-automatically&#34;&gt;Can you define an optimality condition to do all the segmentation automatically?&lt;/h3&gt;
&lt;p&gt;As far as I can tell, no. This is because of the problem I pointed out at the beginning: the &amp;lsquo;correct&amp;rsquo; segmentation depends on your particular question more than anything else.&lt;/p&gt;
&lt;h3 id=&#34;how-should-you-store-the-code-used-to-generate-a-color-map&#34;&gt;How should you store the code used to generate a color map?&lt;/h3&gt;
&lt;p&gt;I like to use &lt;code&gt;rlang::enexpr&lt;/code&gt; to capture the code I run to generate a color map, and store it as another aspect of the recolorize object, like so:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rlang)

# run this code, then capture it in the brackets:
steps &amp;lt;- {
  fit &amp;lt;- recolorize2(img,bins = 3, cutoff = 50)
  fit2 &amp;lt;- editLayers(fit, c(2, 5),
                     operations = &amp;quot;fill&amp;quot;, px_sizes = 3)
  } %&amp;gt;% enexprs()

fit2$steps &amp;lt;- steps
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;what-about-batch-processing&#34;&gt;What about batch processing?&lt;/h3&gt;
&lt;p&gt;Every function in this package operates on a single image at a time. This is because I&amp;rsquo;ve found that there is so much variation in how people go about batch processing anything: if I tried to impose what I considered to be a useful batch processing structure, within a few months I would find that it was too inflexible for some new project structure I needed to use it for. So, instead, the idea is that you can write your own batch processing functions or for loops as needed to suit your data structure. Or maybe you come up with something better than I can think of, in which case, please let me add it to the package!&lt;/p&gt;
&lt;h3 id=&#34;what-about-machine-learning-approaches&#34;&gt;What about machine learning approaches?&lt;/h3&gt;
&lt;p&gt;Using machine learning could work, but only if you already have segmented images for use in training (which presumably you had to do by hand), and making that training set could be extremely time consuming; and the amount of modification required to get a generic algorithm to work might be unjustifiable given the size of (or variance in) your image set. This problem gets a lot worse the more images we have and the more different they are, especially if you have a lot of variance in a small dataset (pretty typical in comparative biology).&lt;/p&gt;
&lt;p&gt;That said, I don&amp;rsquo;t have much background in ML of any stripe. If you have a handy idea in this area, I would love to know about it.&lt;/p&gt;
&lt;h2 id=&#34;just-for-fun&#34;&gt;Just for fun&lt;/h2&gt;
&lt;p&gt;There are two fun functions in here: &lt;code&gt;wernerColor&lt;/code&gt; and &lt;code&gt;recolorizeVector&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;wernerColor&lt;/code&gt; remaps a recolorize object to the colors in Werner&amp;rsquo;s Nomenclature of Colors by Patrick Syme (1821), one of the first attempts at an objective color reference in western science, notably used by Charles Darwin. This is always fun to try out, especially given how many things get tagged as &amp;ldquo;veinous blood red&amp;rdquo; (delightful!):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rc_werner &amp;lt;- wernerColor(recluster_results)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally, &lt;code&gt;recolorizeVector&lt;/code&gt; converts a bitmap (i.e. pixel) image to a vector image.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rc_vector &amp;lt;- recolorizeVector(recluster_fit, 
                              size_filter = 0.15,
                              smoothness = 5, plotting = TRUE)

# to save as an SVG:
svg(filename = &amp;quot;corbett_vector.svg&amp;quot;, width = 2, height = 4)
plot(rc_vector)
dev.off()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/introduction-to-recolorize/index_files/figure-html/unnamed-chunk-39-1.png&#34; width=&#34;144&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This function is VERY experimental. If it gives you errors or looks too funky, try decreasing the size filter (which absorbs all components below some size to simplify the image) and the smoothness. Then again, sometimes you want things to look funky. If this is the case, &lt;code&gt;recolorizeVector&lt;/code&gt; will happily enable you.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Modifying pixel plots</title>
      <link>/post/modifying-pixel-plots/</link>
      <pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate>
      <guid>/post/modifying-pixel-plots/</guid>
      <description>&lt;script src=&#34;/post/modifying-pixel-plots/index_files/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/plotly-binding/plotly.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/typedarray/typedarray.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/jquery/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/post/modifying-pixel-plots/index_files/crosstalk/css/crosstalk.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/crosstalk/js/crosstalk.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/post/modifying-pixel-plots/index_files/plotly-htmlwidgets-css/plotly-htmlwidgets.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/plotly-main/plotly-latest.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/plotly-binding/plotly.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/typedarray/typedarray.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/jquery/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/post/modifying-pixel-plots/index_files/crosstalk/css/crosstalk.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/crosstalk/js/crosstalk.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/post/modifying-pixel-plots/index_files/plotly-htmlwidgets-css/plotly-htmlwidgets.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/post/modifying-pixel-plots/index_files/plotly-main/plotly-latest.min.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;The &lt;code&gt;plotPixels&lt;/code&gt; function in &lt;code&gt;colordistance&lt;/code&gt; is pretty inflexible. It was originally meant as a diagnostic tool, and the plots it produces are not exactly beautiful:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(colordistance)

# image from the &#39;recolorize&#39; package (github.com/hiweller/recolorize)
img &amp;lt;- system.file(&amp;quot;extdata/fulgidissima.png&amp;quot;, package = &amp;quot;recolorize&amp;quot;)

# load the image:
loaded_img &amp;lt;- loadImage(img)

# set the plot layout for opposing pixel plots
layout(matrix(1:3, nrow = 1), widths = c(0.46, 0.08, 0.46))

# plot the pixels in RGB color space from two angles:
plotPixels(loaded_img)

# plot the original image
par(mar = rep(0, 4)) # no margin
plotImage(loaded_img)

# and pixels from the opposite angle:
plotPixels(loaded_img, angle = -45)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/modifying-pixel-plots/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots are certainly &lt;em&gt;fine&lt;/em&gt; if you want to scope out the color distribution in the image, but I wouldn’t want to display them for communication: the axis text is too large and some of the tick marks overlap; the axis labels are oddly spaced; and depending on the intention of the graphic, I might not want the grid or the plot frame. The axis label thing in particular has always bothered me.&lt;/p&gt;
&lt;p&gt;Some of those changes are possible to make by passing additional parameters to the &lt;code&gt;plotPixels&lt;/code&gt; function itself, but in practice, I often want more flexibility than this provides. Luckily, the function itself has such simple building blocks that it’s pretty easy to unpack them to get more customized plots.&lt;/p&gt;
&lt;p&gt;This is how &lt;code&gt;plotPixels&lt;/code&gt; works:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It takes a dataframe of RGB colors, where pixels are rows and color channels are columns.&lt;/li&gt;
&lt;li&gt;It creates a vector of hex codes from the RGB colors to tell R which color to make each point.&lt;/li&gt;
&lt;li&gt;It uses &lt;a href=&#34;https://www.econstor.eu/handle/10419/77160&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;scatterplot3d&lt;/code&gt;&lt;/a&gt; to plot in the 3D color space indicated with the &lt;code&gt;color.space&lt;/code&gt; argument.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I chose the &lt;code&gt;scatterplot3d&lt;/code&gt; package because, of all the 3D plotting packages, it’s the most lightweight, and more or less just extends the base plotting syntax. It was also written in 2003, so there are a lot of newer packages that provide prettier output and more options, like &lt;a href=&#34;https://cran.r-project.org/web/packages/plot3D/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;plot3D&lt;/a&gt; by Karline Soetaert, or the &lt;a href=&#34;https://cran.r-project.org/web/packages/plotly/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;plotly&lt;/a&gt; library.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# load the plot3D library
library(plot3D)

# get the RGB pixel matrix
pixels &amp;lt;- loaded_img$filtered.rgb.2d

# make the hex color vector using the rgb() function
color_vector &amp;lt;- rgb(pixels); head(color_vector) # just a bunch of hex codes!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;#247872&amp;quot; &amp;quot;#006862&amp;quot; &amp;quot;#006B62&amp;quot; &amp;quot;#00776A&amp;quot; &amp;quot;#00645C&amp;quot; &amp;quot;#007B71&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# use the scatter3D function
scatter3D(x = pixels[ , 1], 
          y = pixels[ , 2],
          z = pixels[ , 3], 
          colvar = 1:nrow(pixels), # &amp;lt;- note we have to make a fake &#39;variable&#39; to assign each pixel a different color
          col = color_vector, 
          colkey = FALSE, # gets rid of the (in this case meaningless) legend
          xlab = &amp;quot;Red&amp;quot;, ylab = &amp;quot;Green&amp;quot;, zlab = &amp;quot;Blue&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/modifying-pixel-plots/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Even the default &lt;code&gt;scatter3D&lt;/code&gt; plot looks a lot better to me: the axis labels hug the axes, and the angle is nicer. We can get fancier with a lot of the options, too:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;scatter3D(x = pixels[ , 1], 
          y = pixels[ , 2],
          z = pixels[ , 3], 
          colvar = 1:nrow(pixels), 
          col = color_vector, colkey = F,
          xlab = &amp;quot;Red&amp;quot;, ylab = &amp;quot;Green&amp;quot;, zlab = &amp;quot;Blue&amp;quot;,
          xlim = 0:1, ylim = 0:1, zlim = 0:1, # RGB max and min
          pch = 19, # filled circles
          alpha = 0.5, # partially transparent
          theta = 115, phi = 25, # change viewing angle
          bty = &amp;quot;bl2&amp;quot;) # black grid background looks sort of cool
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/modifying-pixel-plots/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What if you want to plot in another color space besides RGB? The only difference is that you have to first convert your pixel matrix to a given color space, for which you have several options.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# convert pixels to CIE Lab coordinates
pixels_lab &amp;lt;- convertColor(pixels, from = &amp;quot;sRGB&amp;quot;, to = &amp;quot;Lab&amp;quot;)

# color vector remains the same!
color_vector &amp;lt;- rgb(pixels)

scatter3D(x = pixels_lab[ , 1], 
          y = pixels_lab[ , 2],
          z = pixels_lab[ , 3], 
          colvar = 1:nrow(pixels_lab), 
          col = color_vector, colkey = F,
          xlab = &amp;quot;Luminance&amp;quot;, ylab = &amp;quot;a (red-green)&amp;quot;, zlab = &amp;quot;b (yellow-blue)&amp;quot;,
          theta = 120, phi = -5,
          xlim = c(0, 100), 
          pch = 19, # filled circles
          alpha = 0.5, # partially transparent
          bty = &amp;quot;b2&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/modifying-pixel-plots/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As an aside, it’s good practice to set the axis limits thoughtfully. This is easy with RGB: all three channels have a 0-1 range. With CIE Lab, this depends on your reference white. The L channel will always be 0-100, and the outer limits for the a and b channels are -127 to 128 each, but for a given reference white converting from sRGB it will be a subset within that range. The axis limits will be set to the range of the data by default, which could be misleading if you’re comparing plots of multiple images.&lt;/p&gt;
&lt;p&gt;If you’d rather have an interactive plot (especially helpful for data exploration), you can use the &lt;code&gt;plotly&lt;/code&gt; package. I find I have to implement more workarounds to get these plots to behave how I’d expect, but once you get out an interactive plot, it’s pretty slick:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(plotly, quietly = TRUE)

# let&#39;s subsample down to 100 pixels just for this example
pixel_sub &amp;lt;- as.data.frame(pixels[sample(1:nrow(pixels), 100), ])
plotly_colors &amp;lt;- rgb(pixel_sub)

# and plot!
plot_ly(data = pixel_sub, 
        x = ~r, y = ~g, z = ~b, 
        type = &amp;quot;scatter3d&amp;quot;, mode = &amp;quot;markers&amp;quot;, 
        color = I(plotly_colors), # this is a bit of a hack and you&#39;ll get a warning...
        colors = plotly_colors)
&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:672px;height:480px;&#34; class=&#34;plotly html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;visdat&#34;:{&#34;948a74a44f66&#34;:[&#34;function () &#34;,&#34;plotlyVisDat&#34;]},&#34;cur_data&#34;:&#34;948a74a44f66&#34;,&#34;attrs&#34;:{&#34;948a74a44f66&#34;:{&#34;x&#34;:{},&#34;y&#34;:{},&#34;z&#34;:{},&#34;mode&#34;:&#34;markers&#34;,&#34;color&#34;:[&#34;#4D272F&#34;,&#34;#008173&#34;,&#34;#220C10&#34;,&#34;#DB4042&#34;,&#34;#402E2E&#34;,&#34;#6A2023&#34;,&#34;#342232&#34;,&#34;#578900&#34;,&#34;#31811C&#34;,&#34;#6B813F&#34;,&#34;#0092BA&#34;,&#34;#4B3842&#34;,&#34;#9F343D&#34;,&#34;#00AD7B&#34;,&#34;#52AA23&#34;,&#34;#51333D&#34;,&#34;#0B803A&#34;,&#34;#405D44&#34;,&#34;#549BC2&#34;,&#34;#709200&#34;,&#34;#559864&#34;,&#34;#67202C&#34;,&#34;#6E7600&#34;,&#34;#007E3A&#34;,&#34;#38A337&#34;,&#34;#676A20&#34;,&#34;#55423B&#34;,&#34;#85C400&#34;,&#34;#425F46&#34;,&#34;#009D42&#34;,&#34;#37833C&#34;,&#34;#31AC00&#34;,&#34;#539000&#34;,&#34;#C43628&#34;,&#34;#858F00&#34;,&#34;#9B1F2C&#34;,&#34;#009C3D&#34;,&#34;#B9202A&#34;,&#34;#50512C&#34;,&#34;#8A8884&#34;,&#34;#822122&#34;,&#34;#329D86&#34;,&#34;#6F661D&#34;,&#34;#008D3B&#34;,&#34;#006E45&#34;,&#34;#006E7A&#34;,&#34;#861A31&#34;,&#34;#339000&#34;,&#34;#427A0F&#34;,&#34;#BBC4E1&#34;,&#34;#29A234&#34;,&#34;#52781E&#34;,&#34;#049509&#34;,&#34;#877D00&#34;,&#34;#78131D&#34;,&#34;#509B35&#34;,&#34;#0084D4&#34;,&#34;#00B27B&#34;,&#34;#00697F&#34;,&#34;#7D272B&#34;,&#34;#44A212&#34;,&#34;#BA9E00&#34;,&#34;#6E303B&#34;,&#34;#325E3D&#34;,&#34;#288929&#34;,&#34;#781E21&#34;,&#34;#638B00&#34;,&#34;#1A1B20&#34;,&#34;#E47C00&#34;,&#34;#832330&#34;,&#34;#837F41&#34;,&#34;#546E0D&#34;,&#34;#611F22&#34;,&#34;#30822C&#34;,&#34;#66272E&#34;,&#34;#7A770C&#34;,&#34;#6E7600&#34;,&#34;#3B6E3D&#34;,&#34;#972931&#34;,&#34;#009658&#34;,&#34;#573B39&#34;,&#34;#1D963C&#34;,&#34;#00DCBE&#34;,&#34;#4A5786&#34;,&#34;#8B8E00&#34;,&#34;#006A85&#34;,&#34;#00852E&#34;,&#34;#4E803E&#34;,&#34;#006C82&#34;,&#34;#00972E&#34;,&#34;#009037&#34;,&#34;#4C711E&#34;,&#34;#531C29&#34;,&#34;#0072A8&#34;,&#34;#3B262B&#34;,&#34;#4C9628&#34;,&#34;#698A35&#34;,&#34;#658300&#34;,&#34;#B96612&#34;,&#34;#9F5918&#34;],&#34;colors&#34;:[&#34;#4D272F&#34;,&#34;#008173&#34;,&#34;#220C10&#34;,&#34;#DB4042&#34;,&#34;#402E2E&#34;,&#34;#6A2023&#34;,&#34;#342232&#34;,&#34;#578900&#34;,&#34;#31811C&#34;,&#34;#6B813F&#34;,&#34;#0092BA&#34;,&#34;#4B3842&#34;,&#34;#9F343D&#34;,&#34;#00AD7B&#34;,&#34;#52AA23&#34;,&#34;#51333D&#34;,&#34;#0B803A&#34;,&#34;#405D44&#34;,&#34;#549BC2&#34;,&#34;#709200&#34;,&#34;#559864&#34;,&#34;#67202C&#34;,&#34;#6E7600&#34;,&#34;#007E3A&#34;,&#34;#38A337&#34;,&#34;#676A20&#34;,&#34;#55423B&#34;,&#34;#85C400&#34;,&#34;#425F46&#34;,&#34;#009D42&#34;,&#34;#37833C&#34;,&#34;#31AC00&#34;,&#34;#539000&#34;,&#34;#C43628&#34;,&#34;#858F00&#34;,&#34;#9B1F2C&#34;,&#34;#009C3D&#34;,&#34;#B9202A&#34;,&#34;#50512C&#34;,&#34;#8A8884&#34;,&#34;#822122&#34;,&#34;#329D86&#34;,&#34;#6F661D&#34;,&#34;#008D3B&#34;,&#34;#006E45&#34;,&#34;#006E7A&#34;,&#34;#861A31&#34;,&#34;#339000&#34;,&#34;#427A0F&#34;,&#34;#BBC4E1&#34;,&#34;#29A234&#34;,&#34;#52781E&#34;,&#34;#049509&#34;,&#34;#877D00&#34;,&#34;#78131D&#34;,&#34;#509B35&#34;,&#34;#0084D4&#34;,&#34;#00B27B&#34;,&#34;#00697F&#34;,&#34;#7D272B&#34;,&#34;#44A212&#34;,&#34;#BA9E00&#34;,&#34;#6E303B&#34;,&#34;#325E3D&#34;,&#34;#288929&#34;,&#34;#781E21&#34;,&#34;#638B00&#34;,&#34;#1A1B20&#34;,&#34;#E47C00&#34;,&#34;#832330&#34;,&#34;#837F41&#34;,&#34;#546E0D&#34;,&#34;#611F22&#34;,&#34;#30822C&#34;,&#34;#66272E&#34;,&#34;#7A770C&#34;,&#34;#6E7600&#34;,&#34;#3B6E3D&#34;,&#34;#972931&#34;,&#34;#009658&#34;,&#34;#573B39&#34;,&#34;#1D963C&#34;,&#34;#00DCBE&#34;,&#34;#4A5786&#34;,&#34;#8B8E00&#34;,&#34;#006A85&#34;,&#34;#00852E&#34;,&#34;#4E803E&#34;,&#34;#006C82&#34;,&#34;#00972E&#34;,&#34;#009037&#34;,&#34;#4C711E&#34;,&#34;#531C29&#34;,&#34;#0072A8&#34;,&#34;#3B262B&#34;,&#34;#4C9628&#34;,&#34;#698A35&#34;,&#34;#658300&#34;,&#34;#B96612&#34;,&#34;#9F5918&#34;],&#34;alpha_stroke&#34;:1,&#34;sizes&#34;:[10,100],&#34;spans&#34;:[1,20],&#34;type&#34;:&#34;scatter3d&#34;}},&#34;layout&#34;:{&#34;margin&#34;:{&#34;b&#34;:40,&#34;l&#34;:60,&#34;t&#34;:25,&#34;r&#34;:10},&#34;scene&#34;:{&#34;xaxis&#34;:{&#34;title&#34;:&#34;r&#34;},&#34;yaxis&#34;:{&#34;title&#34;:&#34;g&#34;},&#34;zaxis&#34;:{&#34;title&#34;:&#34;b&#34;}},&#34;hovermode&#34;:&#34;closest&#34;,&#34;showlegend&#34;:false},&#34;source&#34;:&#34;A&#34;,&#34;config&#34;:{&#34;showSendToCloud&#34;:false},&#34;data&#34;:[{&#34;x&#34;:[0.301960784313725,0,0.133333333333333,0.858823529411765,0.250980392156863,0.415686274509804,0.203921568627451,0.341176470588235,0.192156862745098,0.419607843137255,0,0.294117647058824,0.623529411764706,0,0.32156862745098,0.317647058823529,0.0431372549019608,0.250980392156863,0.329411764705882,0.43921568627451,0.333333333333333,0.403921568627451,0.431372549019608,0,0.219607843137255,0.403921568627451,0.333333333333333,0.52156862745098,0.258823529411765,0,0.215686274509804,0.192156862745098,0.325490196078431,0.768627450980392,0.52156862745098,0.607843137254902,0,0.725490196078431,0.313725490196078,0.541176470588235,0.509803921568627,0.196078431372549,0.435294117647059,0,0,0,0.525490196078431,0.2,0.258823529411765,0.733333333333333,0.16078431372549,0.32156862745098,0.0156862745098039,0.529411764705882,0.470588235294118,0.313725490196078,0,0,0,0.490196078431373,0.266666666666667,0.729411764705882,0.431372549019608,0.196078431372549,0.156862745098039,0.470588235294118,0.388235294117647,0.101960784313725,0.894117647058824,0.513725490196078,0.513725490196078,0.329411764705882,0.380392156862745,0.188235294117647,0.4,0.47843137254902,0.431372549019608,0.231372549019608,0.592156862745098,0,0.341176470588235,0.113725490196078,0,0.290196078431373,0.545098039215686,0,0,0.305882352941176,0,0,0,0.298039215686275,0.325490196078431,0,0.231372549019608,0.298039215686275,0.411764705882353,0.396078431372549,0.725490196078431,0.623529411764706],&#34;y&#34;:[0.152941176470588,0.505882352941176,0.0470588235294118,0.250980392156863,0.180392156862745,0.125490196078431,0.133333333333333,0.537254901960784,0.505882352941176,0.505882352941176,0.572549019607843,0.219607843137255,0.203921568627451,0.67843137254902,0.666666666666667,0.2,0.501960784313725,0.364705882352941,0.607843137254902,0.572549019607843,0.596078431372549,0.125490196078431,0.462745098039216,0.494117647058824,0.63921568627451,0.415686274509804,0.258823529411765,0.768627450980392,0.372549019607843,0.615686274509804,0.513725490196078,0.674509803921569,0.564705882352941,0.211764705882353,0.56078431372549,0.12156862745098,0.611764705882353,0.125490196078431,0.317647058823529,0.533333333333333,0.129411764705882,0.615686274509804,0.4,0.552941176470588,0.431372549019608,0.431372549019608,0.101960784313725,0.564705882352941,0.47843137254902,0.768627450980392,0.635294117647059,0.470588235294118,0.584313725490196,0.490196078431373,0.0745098039215686,0.607843137254902,0.517647058823529,0.698039215686274,0.411764705882353,0.152941176470588,0.635294117647059,0.619607843137255,0.188235294117647,0.368627450980392,0.537254901960784,0.117647058823529,0.545098039215686,0.105882352941176,0.486274509803922,0.137254901960784,0.498039215686275,0.431372549019608,0.12156862745098,0.509803921568627,0.152941176470588,0.466666666666667,0.462745098039216,0.431372549019608,0.16078431372549,0.588235294117647,0.231372549019608,0.588235294117647,0.862745098039216,0.341176470588235,0.556862745098039,0.415686274509804,0.52156862745098,0.501960784313725,0.423529411764706,0.592156862745098,0.564705882352941,0.443137254901961,0.109803921568627,0.447058823529412,0.149019607843137,0.588235294117647,0.541176470588235,0.513725490196078,0.4,0.349019607843137],&#34;z&#34;:[0.184313725490196,0.450980392156863,0.0627450980392157,0.258823529411765,0.180392156862745,0.137254901960784,0.196078431372549,0,0.109803921568627,0.247058823529412,0.729411764705882,0.258823529411765,0.23921568627451,0.482352941176471,0.137254901960784,0.23921568627451,0.227450980392157,0.266666666666667,0.76078431372549,0,0.392156862745098,0.172549019607843,0,0.227450980392157,0.215686274509804,0.125490196078431,0.231372549019608,0,0.274509803921569,0.258823529411765,0.235294117647059,0,0,0.156862745098039,0,0.172549019607843,0.23921568627451,0.164705882352941,0.172549019607843,0.517647058823529,0.133333333333333,0.525490196078431,0.113725490196078,0.231372549019608,0.270588235294118,0.47843137254902,0.192156862745098,0,0.0588235294117647,0.882352941176471,0.203921568627451,0.117647058823529,0.0352941176470588,0,0.113725490196078,0.207843137254902,0.831372549019608,0.482352941176471,0.498039215686275,0.168627450980392,0.0705882352941176,0,0.231372549019608,0.23921568627451,0.16078431372549,0.129411764705882,0,0.125490196078431,0,0.188235294117647,0.254901960784314,0.0509803921568627,0.133333333333333,0.172549019607843,0.180392156862745,0.0470588235294118,0,0.23921568627451,0.192156862745098,0.345098039215686,0.223529411764706,0.235294117647059,0.745098039215686,0.525490196078431,0,0.52156862745098,0.180392156862745,0.243137254901961,0.509803921568627,0.180392156862745,0.215686274509804,0.117647058823529,0.16078431372549,0.658823529411765,0.168627450980392,0.156862745098039,0.207843137254902,0,0.0705882352941176,0.0941176470588235],&#34;mode&#34;:&#34;markers&#34;,&#34;type&#34;:&#34;scatter3d&#34;,&#34;marker&#34;:{&#34;color&#34;:[&#34;rgba(77,39,47,1)&#34;,&#34;rgba(0,129,115,1)&#34;,&#34;rgba(34,12,16,1)&#34;,&#34;rgba(219,64,66,1)&#34;,&#34;rgba(64,46,46,1)&#34;,&#34;rgba(106,32,35,1)&#34;,&#34;rgba(52,34,50,1)&#34;,&#34;rgba(87,137,0,1)&#34;,&#34;rgba(49,129,28,1)&#34;,&#34;rgba(107,129,63,1)&#34;,&#34;rgba(0,146,186,1)&#34;,&#34;rgba(75,56,66,1)&#34;,&#34;rgba(159,52,61,1)&#34;,&#34;rgba(0,173,123,1)&#34;,&#34;rgba(82,170,35,1)&#34;,&#34;rgba(81,51,61,1)&#34;,&#34;rgba(11,128,58,1)&#34;,&#34;rgba(64,93,68,1)&#34;,&#34;rgba(84,155,194,1)&#34;,&#34;rgba(112,146,0,1)&#34;,&#34;rgba(85,152,100,1)&#34;,&#34;rgba(103,32,44,1)&#34;,&#34;rgba(110,118,0,1)&#34;,&#34;rgba(0,126,58,1)&#34;,&#34;rgba(56,163,55,1)&#34;,&#34;rgba(103,106,32,1)&#34;,&#34;rgba(85,66,59,1)&#34;,&#34;rgba(133,196,0,1)&#34;,&#34;rgba(66,95,70,1)&#34;,&#34;rgba(0,157,66,1)&#34;,&#34;rgba(55,131,60,1)&#34;,&#34;rgba(49,172,0,1)&#34;,&#34;rgba(83,144,0,1)&#34;,&#34;rgba(196,54,40,1)&#34;,&#34;rgba(133,143,0,1)&#34;,&#34;rgba(155,31,44,1)&#34;,&#34;rgba(0,156,61,1)&#34;,&#34;rgba(185,32,42,1)&#34;,&#34;rgba(80,81,44,1)&#34;,&#34;rgba(138,136,132,1)&#34;,&#34;rgba(130,33,34,1)&#34;,&#34;rgba(50,157,134,1)&#34;,&#34;rgba(111,102,29,1)&#34;,&#34;rgba(0,141,59,1)&#34;,&#34;rgba(0,110,69,1)&#34;,&#34;rgba(0,110,122,1)&#34;,&#34;rgba(134,26,49,1)&#34;,&#34;rgba(51,144,0,1)&#34;,&#34;rgba(66,122,15,1)&#34;,&#34;rgba(187,196,225,1)&#34;,&#34;rgba(41,162,52,1)&#34;,&#34;rgba(82,120,30,1)&#34;,&#34;rgba(4,149,9,1)&#34;,&#34;rgba(135,125,0,1)&#34;,&#34;rgba(120,19,29,1)&#34;,&#34;rgba(80,155,53,1)&#34;,&#34;rgba(0,132,212,1)&#34;,&#34;rgba(0,178,123,1)&#34;,&#34;rgba(0,105,127,1)&#34;,&#34;rgba(125,39,43,1)&#34;,&#34;rgba(68,162,18,1)&#34;,&#34;rgba(186,158,0,1)&#34;,&#34;rgba(110,48,59,1)&#34;,&#34;rgba(50,94,61,1)&#34;,&#34;rgba(40,137,41,1)&#34;,&#34;rgba(120,30,33,1)&#34;,&#34;rgba(99,139,0,1)&#34;,&#34;rgba(26,27,32,1)&#34;,&#34;rgba(228,124,0,1)&#34;,&#34;rgba(131,35,48,1)&#34;,&#34;rgba(131,127,65,1)&#34;,&#34;rgba(84,110,13,1)&#34;,&#34;rgba(97,31,34,1)&#34;,&#34;rgba(48,130,44,1)&#34;,&#34;rgba(102,39,46,1)&#34;,&#34;rgba(122,119,12,1)&#34;,&#34;rgba(110,118,0,1)&#34;,&#34;rgba(59,110,61,1)&#34;,&#34;rgba(151,41,49,1)&#34;,&#34;rgba(0,150,88,1)&#34;,&#34;rgba(87,59,57,1)&#34;,&#34;rgba(29,150,60,1)&#34;,&#34;rgba(0,220,190,1)&#34;,&#34;rgba(74,87,134,1)&#34;,&#34;rgba(139,142,0,1)&#34;,&#34;rgba(0,106,133,1)&#34;,&#34;rgba(0,133,46,1)&#34;,&#34;rgba(78,128,62,1)&#34;,&#34;rgba(0,108,130,1)&#34;,&#34;rgba(0,151,46,1)&#34;,&#34;rgba(0,144,55,1)&#34;,&#34;rgba(76,113,30,1)&#34;,&#34;rgba(83,28,41,1)&#34;,&#34;rgba(0,114,168,1)&#34;,&#34;rgba(59,38,43,1)&#34;,&#34;rgba(76,150,40,1)&#34;,&#34;rgba(105,138,53,1)&#34;,&#34;rgba(101,131,0,1)&#34;,&#34;rgba(185,102,18,1)&#34;,&#34;rgba(159,89,24,1)&#34;],&#34;line&#34;:{&#34;color&#34;:[&#34;rgba(77,39,47,1)&#34;,&#34;rgba(0,129,115,1)&#34;,&#34;rgba(34,12,16,1)&#34;,&#34;rgba(219,64,66,1)&#34;,&#34;rgba(64,46,46,1)&#34;,&#34;rgba(106,32,35,1)&#34;,&#34;rgba(52,34,50,1)&#34;,&#34;rgba(87,137,0,1)&#34;,&#34;rgba(49,129,28,1)&#34;,&#34;rgba(107,129,63,1)&#34;,&#34;rgba(0,146,186,1)&#34;,&#34;rgba(75,56,66,1)&#34;,&#34;rgba(159,52,61,1)&#34;,&#34;rgba(0,173,123,1)&#34;,&#34;rgba(82,170,35,1)&#34;,&#34;rgba(81,51,61,1)&#34;,&#34;rgba(11,128,58,1)&#34;,&#34;rgba(64,93,68,1)&#34;,&#34;rgba(84,155,194,1)&#34;,&#34;rgba(112,146,0,1)&#34;,&#34;rgba(85,152,100,1)&#34;,&#34;rgba(103,32,44,1)&#34;,&#34;rgba(110,118,0,1)&#34;,&#34;rgba(0,126,58,1)&#34;,&#34;rgba(56,163,55,1)&#34;,&#34;rgba(103,106,32,1)&#34;,&#34;rgba(85,66,59,1)&#34;,&#34;rgba(133,196,0,1)&#34;,&#34;rgba(66,95,70,1)&#34;,&#34;rgba(0,157,66,1)&#34;,&#34;rgba(55,131,60,1)&#34;,&#34;rgba(49,172,0,1)&#34;,&#34;rgba(83,144,0,1)&#34;,&#34;rgba(196,54,40,1)&#34;,&#34;rgba(133,143,0,1)&#34;,&#34;rgba(155,31,44,1)&#34;,&#34;rgba(0,156,61,1)&#34;,&#34;rgba(185,32,42,1)&#34;,&#34;rgba(80,81,44,1)&#34;,&#34;rgba(138,136,132,1)&#34;,&#34;rgba(130,33,34,1)&#34;,&#34;rgba(50,157,134,1)&#34;,&#34;rgba(111,102,29,1)&#34;,&#34;rgba(0,141,59,1)&#34;,&#34;rgba(0,110,69,1)&#34;,&#34;rgba(0,110,122,1)&#34;,&#34;rgba(134,26,49,1)&#34;,&#34;rgba(51,144,0,1)&#34;,&#34;rgba(66,122,15,1)&#34;,&#34;rgba(187,196,225,1)&#34;,&#34;rgba(41,162,52,1)&#34;,&#34;rgba(82,120,30,1)&#34;,&#34;rgba(4,149,9,1)&#34;,&#34;rgba(135,125,0,1)&#34;,&#34;rgba(120,19,29,1)&#34;,&#34;rgba(80,155,53,1)&#34;,&#34;rgba(0,132,212,1)&#34;,&#34;rgba(0,178,123,1)&#34;,&#34;rgba(0,105,127,1)&#34;,&#34;rgba(125,39,43,1)&#34;,&#34;rgba(68,162,18,1)&#34;,&#34;rgba(186,158,0,1)&#34;,&#34;rgba(110,48,59,1)&#34;,&#34;rgba(50,94,61,1)&#34;,&#34;rgba(40,137,41,1)&#34;,&#34;rgba(120,30,33,1)&#34;,&#34;rgba(99,139,0,1)&#34;,&#34;rgba(26,27,32,1)&#34;,&#34;rgba(228,124,0,1)&#34;,&#34;rgba(131,35,48,1)&#34;,&#34;rgba(131,127,65,1)&#34;,&#34;rgba(84,110,13,1)&#34;,&#34;rgba(97,31,34,1)&#34;,&#34;rgba(48,130,44,1)&#34;,&#34;rgba(102,39,46,1)&#34;,&#34;rgba(122,119,12,1)&#34;,&#34;rgba(110,118,0,1)&#34;,&#34;rgba(59,110,61,1)&#34;,&#34;rgba(151,41,49,1)&#34;,&#34;rgba(0,150,88,1)&#34;,&#34;rgba(87,59,57,1)&#34;,&#34;rgba(29,150,60,1)&#34;,&#34;rgba(0,220,190,1)&#34;,&#34;rgba(74,87,134,1)&#34;,&#34;rgba(139,142,0,1)&#34;,&#34;rgba(0,106,133,1)&#34;,&#34;rgba(0,133,46,1)&#34;,&#34;rgba(78,128,62,1)&#34;,&#34;rgba(0,108,130,1)&#34;,&#34;rgba(0,151,46,1)&#34;,&#34;rgba(0,144,55,1)&#34;,&#34;rgba(76,113,30,1)&#34;,&#34;rgba(83,28,41,1)&#34;,&#34;rgba(0,114,168,1)&#34;,&#34;rgba(59,38,43,1)&#34;,&#34;rgba(76,150,40,1)&#34;,&#34;rgba(105,138,53,1)&#34;,&#34;rgba(101,131,0,1)&#34;,&#34;rgba(185,102,18,1)&#34;,&#34;rgba(159,89,24,1)&#34;]}},&#34;textfont&#34;:{&#34;color&#34;:[&#34;rgba(77,39,47,1)&#34;,&#34;rgba(0,129,115,1)&#34;,&#34;rgba(34,12,16,1)&#34;,&#34;rgba(219,64,66,1)&#34;,&#34;rgba(64,46,46,1)&#34;,&#34;rgba(106,32,35,1)&#34;,&#34;rgba(52,34,50,1)&#34;,&#34;rgba(87,137,0,1)&#34;,&#34;rgba(49,129,28,1)&#34;,&#34;rgba(107,129,63,1)&#34;,&#34;rgba(0,146,186,1)&#34;,&#34;rgba(75,56,66,1)&#34;,&#34;rgba(159,52,61,1)&#34;,&#34;rgba(0,173,123,1)&#34;,&#34;rgba(82,170,35,1)&#34;,&#34;rgba(81,51,61,1)&#34;,&#34;rgba(11,128,58,1)&#34;,&#34;rgba(64,93,68,1)&#34;,&#34;rgba(84,155,194,1)&#34;,&#34;rgba(112,146,0,1)&#34;,&#34;rgba(85,152,100,1)&#34;,&#34;rgba(103,32,44,1)&#34;,&#34;rgba(110,118,0,1)&#34;,&#34;rgba(0,126,58,1)&#34;,&#34;rgba(56,163,55,1)&#34;,&#34;rgba(103,106,32,1)&#34;,&#34;rgba(85,66,59,1)&#34;,&#34;rgba(133,196,0,1)&#34;,&#34;rgba(66,95,70,1)&#34;,&#34;rgba(0,157,66,1)&#34;,&#34;rgba(55,131,60,1)&#34;,&#34;rgba(49,172,0,1)&#34;,&#34;rgba(83,144,0,1)&#34;,&#34;rgba(196,54,40,1)&#34;,&#34;rgba(133,143,0,1)&#34;,&#34;rgba(155,31,44,1)&#34;,&#34;rgba(0,156,61,1)&#34;,&#34;rgba(185,32,42,1)&#34;,&#34;rgba(80,81,44,1)&#34;,&#34;rgba(138,136,132,1)&#34;,&#34;rgba(130,33,34,1)&#34;,&#34;rgba(50,157,134,1)&#34;,&#34;rgba(111,102,29,1)&#34;,&#34;rgba(0,141,59,1)&#34;,&#34;rgba(0,110,69,1)&#34;,&#34;rgba(0,110,122,1)&#34;,&#34;rgba(134,26,49,1)&#34;,&#34;rgba(51,144,0,1)&#34;,&#34;rgba(66,122,15,1)&#34;,&#34;rgba(187,196,225,1)&#34;,&#34;rgba(41,162,52,1)&#34;,&#34;rgba(82,120,30,1)&#34;,&#34;rgba(4,149,9,1)&#34;,&#34;rgba(135,125,0,1)&#34;,&#34;rgba(120,19,29,1)&#34;,&#34;rgba(80,155,53,1)&#34;,&#34;rgba(0,132,212,1)&#34;,&#34;rgba(0,178,123,1)&#34;,&#34;rgba(0,105,127,1)&#34;,&#34;rgba(125,39,43,1)&#34;,&#34;rgba(68,162,18,1)&#34;,&#34;rgba(186,158,0,1)&#34;,&#34;rgba(110,48,59,1)&#34;,&#34;rgba(50,94,61,1)&#34;,&#34;rgba(40,137,41,1)&#34;,&#34;rgba(120,30,33,1)&#34;,&#34;rgba(99,139,0,1)&#34;,&#34;rgba(26,27,32,1)&#34;,&#34;rgba(228,124,0,1)&#34;,&#34;rgba(131,35,48,1)&#34;,&#34;rgba(131,127,65,1)&#34;,&#34;rgba(84,110,13,1)&#34;,&#34;rgba(97,31,34,1)&#34;,&#34;rgba(48,130,44,1)&#34;,&#34;rgba(102,39,46,1)&#34;,&#34;rgba(122,119,12,1)&#34;,&#34;rgba(110,118,0,1)&#34;,&#34;rgba(59,110,61,1)&#34;,&#34;rgba(151,41,49,1)&#34;,&#34;rgba(0,150,88,1)&#34;,&#34;rgba(87,59,57,1)&#34;,&#34;rgba(29,150,60,1)&#34;,&#34;rgba(0,220,190,1)&#34;,&#34;rgba(74,87,134,1)&#34;,&#34;rgba(139,142,0,1)&#34;,&#34;rgba(0,106,133,1)&#34;,&#34;rgba(0,133,46,1)&#34;,&#34;rgba(78,128,62,1)&#34;,&#34;rgba(0,108,130,1)&#34;,&#34;rgba(0,151,46,1)&#34;,&#34;rgba(0,144,55,1)&#34;,&#34;rgba(76,113,30,1)&#34;,&#34;rgba(83,28,41,1)&#34;,&#34;rgba(0,114,168,1)&#34;,&#34;rgba(59,38,43,1)&#34;,&#34;rgba(76,150,40,1)&#34;,&#34;rgba(105,138,53,1)&#34;,&#34;rgba(101,131,0,1)&#34;,&#34;rgba(185,102,18,1)&#34;,&#34;rgba(159,89,24,1)&#34;]},&#34;line&#34;:{&#34;color&#34;:[&#34;rgba(77,39,47,1)&#34;,&#34;rgba(0,129,115,1)&#34;,&#34;rgba(34,12,16,1)&#34;,&#34;rgba(219,64,66,1)&#34;,&#34;rgba(64,46,46,1)&#34;,&#34;rgba(106,32,35,1)&#34;,&#34;rgba(52,34,50,1)&#34;,&#34;rgba(87,137,0,1)&#34;,&#34;rgba(49,129,28,1)&#34;,&#34;rgba(107,129,63,1)&#34;,&#34;rgba(0,146,186,1)&#34;,&#34;rgba(75,56,66,1)&#34;,&#34;rgba(159,52,61,1)&#34;,&#34;rgba(0,173,123,1)&#34;,&#34;rgba(82,170,35,1)&#34;,&#34;rgba(81,51,61,1)&#34;,&#34;rgba(11,128,58,1)&#34;,&#34;rgba(64,93,68,1)&#34;,&#34;rgba(84,155,194,1)&#34;,&#34;rgba(112,146,0,1)&#34;,&#34;rgba(85,152,100,1)&#34;,&#34;rgba(103,32,44,1)&#34;,&#34;rgba(110,118,0,1)&#34;,&#34;rgba(0,126,58,1)&#34;,&#34;rgba(56,163,55,1)&#34;,&#34;rgba(103,106,32,1)&#34;,&#34;rgba(85,66,59,1)&#34;,&#34;rgba(133,196,0,1)&#34;,&#34;rgba(66,95,70,1)&#34;,&#34;rgba(0,157,66,1)&#34;,&#34;rgba(55,131,60,1)&#34;,&#34;rgba(49,172,0,1)&#34;,&#34;rgba(83,144,0,1)&#34;,&#34;rgba(196,54,40,1)&#34;,&#34;rgba(133,143,0,1)&#34;,&#34;rgba(155,31,44,1)&#34;,&#34;rgba(0,156,61,1)&#34;,&#34;rgba(185,32,42,1)&#34;,&#34;rgba(80,81,44,1)&#34;,&#34;rgba(138,136,132,1)&#34;,&#34;rgba(130,33,34,1)&#34;,&#34;rgba(50,157,134,1)&#34;,&#34;rgba(111,102,29,1)&#34;,&#34;rgba(0,141,59,1)&#34;,&#34;rgba(0,110,69,1)&#34;,&#34;rgba(0,110,122,1)&#34;,&#34;rgba(134,26,49,1)&#34;,&#34;rgba(51,144,0,1)&#34;,&#34;rgba(66,122,15,1)&#34;,&#34;rgba(187,196,225,1)&#34;,&#34;rgba(41,162,52,1)&#34;,&#34;rgba(82,120,30,1)&#34;,&#34;rgba(4,149,9,1)&#34;,&#34;rgba(135,125,0,1)&#34;,&#34;rgba(120,19,29,1)&#34;,&#34;rgba(80,155,53,1)&#34;,&#34;rgba(0,132,212,1)&#34;,&#34;rgba(0,178,123,1)&#34;,&#34;rgba(0,105,127,1)&#34;,&#34;rgba(125,39,43,1)&#34;,&#34;rgba(68,162,18,1)&#34;,&#34;rgba(186,158,0,1)&#34;,&#34;rgba(110,48,59,1)&#34;,&#34;rgba(50,94,61,1)&#34;,&#34;rgba(40,137,41,1)&#34;,&#34;rgba(120,30,33,1)&#34;,&#34;rgba(99,139,0,1)&#34;,&#34;rgba(26,27,32,1)&#34;,&#34;rgba(228,124,0,1)&#34;,&#34;rgba(131,35,48,1)&#34;,&#34;rgba(131,127,65,1)&#34;,&#34;rgba(84,110,13,1)&#34;,&#34;rgba(97,31,34,1)&#34;,&#34;rgba(48,130,44,1)&#34;,&#34;rgba(102,39,46,1)&#34;,&#34;rgba(122,119,12,1)&#34;,&#34;rgba(110,118,0,1)&#34;,&#34;rgba(59,110,61,1)&#34;,&#34;rgba(151,41,49,1)&#34;,&#34;rgba(0,150,88,1)&#34;,&#34;rgba(87,59,57,1)&#34;,&#34;rgba(29,150,60,1)&#34;,&#34;rgba(0,220,190,1)&#34;,&#34;rgba(74,87,134,1)&#34;,&#34;rgba(139,142,0,1)&#34;,&#34;rgba(0,106,133,1)&#34;,&#34;rgba(0,133,46,1)&#34;,&#34;rgba(78,128,62,1)&#34;,&#34;rgba(0,108,130,1)&#34;,&#34;rgba(0,151,46,1)&#34;,&#34;rgba(0,144,55,1)&#34;,&#34;rgba(76,113,30,1)&#34;,&#34;rgba(83,28,41,1)&#34;,&#34;rgba(0,114,168,1)&#34;,&#34;rgba(59,38,43,1)&#34;,&#34;rgba(76,150,40,1)&#34;,&#34;rgba(105,138,53,1)&#34;,&#34;rgba(101,131,0,1)&#34;,&#34;rgba(185,102,18,1)&#34;,&#34;rgba(159,89,24,1)&#34;]},&#34;frame&#34;:null}],&#34;highlight&#34;:{&#34;on&#34;:&#34;plotly_click&#34;,&#34;persistent&#34;:false,&#34;dynamic&#34;:false,&#34;selectize&#34;:false,&#34;opacityDim&#34;:0.2,&#34;selected&#34;:{&#34;opacity&#34;:1},&#34;debounce&#34;:0},&#34;shinyEvents&#34;:[&#34;plotly_hover&#34;,&#34;plotly_click&#34;,&#34;plotly_selected&#34;,&#34;plotly_relayout&#34;,&#34;plotly_brushed&#34;,&#34;plotly_brushing&#34;,&#34;plotly_clickannotation&#34;,&#34;plotly_doubleclick&#34;,&#34;plotly_deselect&#34;,&#34;plotly_afterplot&#34;,&#34;plotly_sunburstclick&#34;],&#34;base_url&#34;:&#34;https://plot.ly&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;If you play around with this enough, you’ll realize that plotting all of your 3D data on a plot as individual points is kind of cumbersome when you have thousands of points; you can’t really tell which regions of your color space are more or less dense. It may better suit your purposes to cluster the data a bit first, and then plot the clusters:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;clusters &amp;lt;- extractClusters(getKMeanColors(img, color.space = &amp;quot;Lab&amp;quot;,
                                           ref.white = &amp;quot;D65&amp;quot;,
                                           n = 50, plotting = F))
colnames(clusters) &amp;lt;- c(&amp;quot;L&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;Pct&amp;quot;)

# We can do this with a colordistance function...
scatter3dclusters(clusters, color.space = &amp;quot;lab&amp;quot;, scaling = 100)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/modifying-pixel-plots/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# we can also use scatter3D, with a bit of a hack to get different point sizes
col_vector &amp;lt;- rgb(convertColor(clusters[ , 1:3], from = &amp;quot;Lab&amp;quot;, to = &amp;quot;sRGB&amp;quot;))

# make blank plot
scatter3D(clusters$L, clusters$a, clusters$b, 
          cex = 0, colkey = F, phi = 35, theta = 60,
          xlab = &amp;quot;L&amp;quot;, ylab = &amp;quot;a&amp;quot;, zlab = &amp;quot;b&amp;quot;)

# set scale multiplier for point sizes
scale &amp;lt;- 80

# add one point at a time, setting size with the cex argument
for (i in 1:nrow(clusters)) {
  scatter3D(x = clusters$L[i],
           y = clusters$a[i],
           z = clusters$b[i],
           cex = clusters$Pct[i] * scale, 
           pch = 19, alpha = 0.5,
           col = col_vector[i], add = TRUE)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/modifying-pixel-plots/index_files/figure-html/unnamed-chunk-6-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# or, we can just use plotly again
plot_ly(data = clusters,
        x = ~L, y = ~a, z = ~b, 
        type = &amp;quot;scatter3d&amp;quot;, mode = &amp;quot;markers&amp;quot;, 
        color = I(col_vector), # this is a bit of a hack and you&#39;ll get a warning...
        colors = col_vector, size = ~Pct)
&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-2&#34; style=&#34;width:672px;height:480px;&#34; class=&#34;plotly html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-2&#34;&gt;{&#34;x&#34;:{&#34;visdat&#34;:{&#34;948a2bab3c7f&#34;:[&#34;function () &#34;,&#34;plotlyVisDat&#34;]},&#34;cur_data&#34;:&#34;948a2bab3c7f&#34;,&#34;attrs&#34;:{&#34;948a2bab3c7f&#34;:{&#34;x&#34;:{},&#34;y&#34;:{},&#34;z&#34;:{},&#34;mode&#34;:&#34;markers&#34;,&#34;color&#34;:[&#34;#647933&#34;,&#34;#732429&#34;,&#34;#986516&#34;,&#34;#832128&#34;,&#34;#232023&#34;,&#34;#138233&#34;,&#34;#943E1F&#34;,&#34;#17AEAB&#34;,&#34;#0C8864&#34;,&#34;#499535&#34;,&#34;#384D39&#34;,&#34;#573F3B&#34;,&#34;#9F8008&#34;,&#34;#047579&#34;,&#34;#077C6D&#34;,&#34;#108DB0&#34;,&#34;#BA2E2C&#34;,&#34;#06667C&#34;,&#34;#0DD7B4&#34;,&#34;#86B20D&#34;,&#34;#8B8784&#34;,&#34;#5F780B&#34;,&#34;#766D2A&#34;,&#34;#C06012&#34;,&#34;#1860A9&#34;,&#34;#62512B&#34;,&#34;#B1A206&#34;,&#34;#545D2C&#34;,&#34;#37CA7A&#34;,&#34;#22587E&#34;,&#34;#3A9610&#34;,&#34;#55BC26&#34;,&#34;#66242C&#34;,&#34;#473037&#34;,&#34;#C34622&#34;,&#34;#038E51&#34;,&#34;#1EA43A&#34;,&#34;#C17C08&#34;,&#34;#4B8407&#34;,&#34;#10753B&#34;,&#34;#758F07&#34;,&#34;#15AA7C&#34;,&#34;#265F37&#34;,&#34;#7E1C32&#34;,&#34;#119846&#34;,&#34;#9C212B&#34;,&#34;#898609&#34;,&#34;#582531&#34;,&#34;#5E9706&#34;,&#34;#3F7624&#34;],&#34;size&#34;:{},&#34;colors&#34;:[&#34;#647933&#34;,&#34;#732429&#34;,&#34;#986516&#34;,&#34;#832128&#34;,&#34;#232023&#34;,&#34;#138233&#34;,&#34;#943E1F&#34;,&#34;#17AEAB&#34;,&#34;#0C8864&#34;,&#34;#499535&#34;,&#34;#384D39&#34;,&#34;#573F3B&#34;,&#34;#9F8008&#34;,&#34;#047579&#34;,&#34;#077C6D&#34;,&#34;#108DB0&#34;,&#34;#BA2E2C&#34;,&#34;#06667C&#34;,&#34;#0DD7B4&#34;,&#34;#86B20D&#34;,&#34;#8B8784&#34;,&#34;#5F780B&#34;,&#34;#766D2A&#34;,&#34;#C06012&#34;,&#34;#1860A9&#34;,&#34;#62512B&#34;,&#34;#B1A206&#34;,&#34;#545D2C&#34;,&#34;#37CA7A&#34;,&#34;#22587E&#34;,&#34;#3A9610&#34;,&#34;#55BC26&#34;,&#34;#66242C&#34;,&#34;#473037&#34;,&#34;#C34622&#34;,&#34;#038E51&#34;,&#34;#1EA43A&#34;,&#34;#C17C08&#34;,&#34;#4B8407&#34;,&#34;#10753B&#34;,&#34;#758F07&#34;,&#34;#15AA7C&#34;,&#34;#265F37&#34;,&#34;#7E1C32&#34;,&#34;#119846&#34;,&#34;#9C212B&#34;,&#34;#898609&#34;,&#34;#582531&#34;,&#34;#5E9706&#34;,&#34;#3F7624&#34;],&#34;alpha_stroke&#34;:1,&#34;sizes&#34;:[10,100],&#34;spans&#34;:[1,20],&#34;type&#34;:&#34;scatter3d&#34;}},&#34;layout&#34;:{&#34;margin&#34;:{&#34;b&#34;:40,&#34;l&#34;:60,&#34;t&#34;:25,&#34;r&#34;:10},&#34;scene&#34;:{&#34;xaxis&#34;:{&#34;title&#34;:&#34;L&#34;},&#34;yaxis&#34;:{&#34;title&#34;:&#34;a&#34;},&#34;zaxis&#34;:{&#34;title&#34;:&#34;b&#34;}},&#34;hovermode&#34;:&#34;closest&#34;,&#34;showlegend&#34;:false},&#34;source&#34;:&#34;A&#34;,&#34;config&#34;:{&#34;showSendToCloud&#34;:false},&#34;data&#34;:[{&#34;x&#34;:[47.6470370380395,26.9343668030093,47.1828825841296,29.6773078450699,12.7045820506114,47.424072153912,37.7095435680787,64.3966358719047,50.2170710701797,55.2008575013163,30.5639393862333,29.2352057210328,54.8739847444633,44.21651687503,46.4348311991777,54.3461739170174,42.2864967235475,39.4002815788575,77.246141494701,67.3417368584501,56.4821125357197,46.7293021620499,45.4986153446182,51.5290761538363,40.1338361320406,35.3775725076101,65.7951807953912,37.6049924843794,72.5005589738049,35.5332956130365,54.909869921715,68.0826258130497,24.7407170414244,22.5787090735333,47.2231676738661,51.6978881209399,58.9315019517576,57.9255190148564,49.6384118056201,42.7699221303017,55.5967406937468,61.8862757522115,35.7827664244431,28.3085165518734,55.1722752062099,34.8245048991748,54.4721552035387,22.5158972154844,56.5773369142028,44.269889046976],&#34;y&#34;:[-19.1560055874448,35.1558839259183,14.2720406280373,41.9759780318741,2.27151473468494,-46.9672270333645,34.3138626384862,-36.1794957895637,-40.2015036246707,-42.360763899665,-13.1006131883921,9.63830700679229,2.01930745644207,-25.3929355968667,-32.9400403387384,-18.7144718129058,55.1505786880039,-16.2512192026847,-52.1150378079515,-35.0058101398964,1.02962325971967,-23.1977287309345,-5.20162909915775,34.3707882925485,6.26556465863796,1.71232485126426,-8.39391101221517,-11.537025012239,-56.2902446947673,-4.37777177199427,-49.6422187683071,-55.1756294819106,30.2241914435395,11.7955865367038,48.1326705218909,-47.3050354036041,-56.1539990811367,19.1817983458343,-37.485801469206,-41.0176083687218,-25.7079300352572,-47.2926881095034,-28.8228745220873,42.6000075381491,-52.123231334113,50.0622436786647,-11.744290691161,24.877420489759,-38.5316644028869,-33.7940092938693],&#34;z&#34;:[35.0345104570875,15.8418904092597,48.9346846157969,20.9249840908074,-1.78570914036779,33.9657948063168,36.0165415746418,-9.12817187084792,10.7727716382048,42.0852089437363,9.12095630563548,6.53578709802711,58.7122851209248,-10.4896224844523,0.31534768082993,-27.1244338341843,35.7715089466191,-19.564988924393,5.09492563363152,66.8339063421687,1.77215759159408,49.418203672323,37.6199540518151,55.9747127260182,-45.4109435932669,24.7964325796627,67.9103022988535,26.7723537600718,28.8802186644586,-26.5501909597621,54.4569417630617,61.1975442753346,10.9134354860685,-0.242929238594548,46.7112900443923,23.6139098568036,43.9314187088593,62.7749914938315,51.9201408757226,24.0782770255091,57.8980119441862,13.286134167394,17.2635276892329,12.5309090043427,33.8323009989432,26.1273787908098,57.374791997851,4.05616250233049,58.1589172091652,37.9475390129431],&#34;mode&#34;:&#34;markers&#34;,&#34;type&#34;:&#34;scatter3d&#34;,&#34;marker&#34;:{&#34;color&#34;:[&#34;rgba(100,121,51,1)&#34;,&#34;rgba(115,36,41,1)&#34;,&#34;rgba(152,101,22,1)&#34;,&#34;rgba(131,33,40,1)&#34;,&#34;rgba(35,32,35,1)&#34;,&#34;rgba(19,130,51,1)&#34;,&#34;rgba(148,62,31,1)&#34;,&#34;rgba(23,174,171,1)&#34;,&#34;rgba(12,136,100,1)&#34;,&#34;rgba(73,149,53,1)&#34;,&#34;rgba(56,77,57,1)&#34;,&#34;rgba(87,63,59,1)&#34;,&#34;rgba(159,128,8,1)&#34;,&#34;rgba(4,117,121,1)&#34;,&#34;rgba(7,124,109,1)&#34;,&#34;rgba(16,141,176,1)&#34;,&#34;rgba(186,46,44,1)&#34;,&#34;rgba(6,102,124,1)&#34;,&#34;rgba(13,215,180,1)&#34;,&#34;rgba(134,178,13,1)&#34;,&#34;rgba(139,135,132,1)&#34;,&#34;rgba(95,120,11,1)&#34;,&#34;rgba(118,109,42,1)&#34;,&#34;rgba(192,96,18,1)&#34;,&#34;rgba(24,96,169,1)&#34;,&#34;rgba(98,81,43,1)&#34;,&#34;rgba(177,162,6,1)&#34;,&#34;rgba(84,93,44,1)&#34;,&#34;rgba(55,202,122,1)&#34;,&#34;rgba(34,88,126,1)&#34;,&#34;rgba(58,150,16,1)&#34;,&#34;rgba(85,188,38,1)&#34;,&#34;rgba(102,36,44,1)&#34;,&#34;rgba(71,48,55,1)&#34;,&#34;rgba(195,70,34,1)&#34;,&#34;rgba(3,142,81,1)&#34;,&#34;rgba(30,164,58,1)&#34;,&#34;rgba(193,124,8,1)&#34;,&#34;rgba(75,132,7,1)&#34;,&#34;rgba(16,117,59,1)&#34;,&#34;rgba(117,143,7,1)&#34;,&#34;rgba(21,170,124,1)&#34;,&#34;rgba(38,95,55,1)&#34;,&#34;rgba(126,28,50,1)&#34;,&#34;rgba(17,152,70,1)&#34;,&#34;rgba(156,33,43,1)&#34;,&#34;rgba(137,134,9,1)&#34;,&#34;rgba(88,37,49,1)&#34;,&#34;rgba(94,151,6,1)&#34;,&#34;rgba(63,118,36,1)&#34;],&#34;size&#34;:[55.8780487804878,100,19.8780487804878,68.609756097561,46.8780487804878,56.0975609756098,24.2682926829268,18.5609756097561,57.1951219512195,52.1463414634146,31.5121951219512,50.390243902439,39.6341463414634,60.2682926829268,56.7560975609756,10.6585365853659,48.4146341463415,61.3658536585366,13.5121951219512,21.4146341463415,17.2439024390244,54.5609756097561,50.1707317073171,34.8048780487805,10,33.2682926829268,18.1219512195122,53.2439024390244,11.7560975609756,28.4390243902439,74.3170731707317,24.4878048780488,83.3170731707317,67.9512195121951,42.4878048780488,70.3658536585366,56.5365853658537,26.9024390243902,74.9756097560976,40.9512195121951,59.609756097561,19.4390243902439,29.0975609756098,32.390243902439,75.4146341463415,60.7073170731707,51.0487804878049,49.7317073170732,55.219512195122,52.5853658536585],&#34;sizemode&#34;:&#34;area&#34;,&#34;line&#34;:{&#34;color&#34;:[&#34;rgba(100,121,51,1)&#34;,&#34;rgba(115,36,41,1)&#34;,&#34;rgba(152,101,22,1)&#34;,&#34;rgba(131,33,40,1)&#34;,&#34;rgba(35,32,35,1)&#34;,&#34;rgba(19,130,51,1)&#34;,&#34;rgba(148,62,31,1)&#34;,&#34;rgba(23,174,171,1)&#34;,&#34;rgba(12,136,100,1)&#34;,&#34;rgba(73,149,53,1)&#34;,&#34;rgba(56,77,57,1)&#34;,&#34;rgba(87,63,59,1)&#34;,&#34;rgba(159,128,8,1)&#34;,&#34;rgba(4,117,121,1)&#34;,&#34;rgba(7,124,109,1)&#34;,&#34;rgba(16,141,176,1)&#34;,&#34;rgba(186,46,44,1)&#34;,&#34;rgba(6,102,124,1)&#34;,&#34;rgba(13,215,180,1)&#34;,&#34;rgba(134,178,13,1)&#34;,&#34;rgba(139,135,132,1)&#34;,&#34;rgba(95,120,11,1)&#34;,&#34;rgba(118,109,42,1)&#34;,&#34;rgba(192,96,18,1)&#34;,&#34;rgba(24,96,169,1)&#34;,&#34;rgba(98,81,43,1)&#34;,&#34;rgba(177,162,6,1)&#34;,&#34;rgba(84,93,44,1)&#34;,&#34;rgba(55,202,122,1)&#34;,&#34;rgba(34,88,126,1)&#34;,&#34;rgba(58,150,16,1)&#34;,&#34;rgba(85,188,38,1)&#34;,&#34;rgba(102,36,44,1)&#34;,&#34;rgba(71,48,55,1)&#34;,&#34;rgba(195,70,34,1)&#34;,&#34;rgba(3,142,81,1)&#34;,&#34;rgba(30,164,58,1)&#34;,&#34;rgba(193,124,8,1)&#34;,&#34;rgba(75,132,7,1)&#34;,&#34;rgba(16,117,59,1)&#34;,&#34;rgba(117,143,7,1)&#34;,&#34;rgba(21,170,124,1)&#34;,&#34;rgba(38,95,55,1)&#34;,&#34;rgba(126,28,50,1)&#34;,&#34;rgba(17,152,70,1)&#34;,&#34;rgba(156,33,43,1)&#34;,&#34;rgba(137,134,9,1)&#34;,&#34;rgba(88,37,49,1)&#34;,&#34;rgba(94,151,6,1)&#34;,&#34;rgba(63,118,36,1)&#34;]}},&#34;textfont&#34;:{&#34;color&#34;:[&#34;rgba(100,121,51,1)&#34;,&#34;rgba(115,36,41,1)&#34;,&#34;rgba(152,101,22,1)&#34;,&#34;rgba(131,33,40,1)&#34;,&#34;rgba(35,32,35,1)&#34;,&#34;rgba(19,130,51,1)&#34;,&#34;rgba(148,62,31,1)&#34;,&#34;rgba(23,174,171,1)&#34;,&#34;rgba(12,136,100,1)&#34;,&#34;rgba(73,149,53,1)&#34;,&#34;rgba(56,77,57,1)&#34;,&#34;rgba(87,63,59,1)&#34;,&#34;rgba(159,128,8,1)&#34;,&#34;rgba(4,117,121,1)&#34;,&#34;rgba(7,124,109,1)&#34;,&#34;rgba(16,141,176,1)&#34;,&#34;rgba(186,46,44,1)&#34;,&#34;rgba(6,102,124,1)&#34;,&#34;rgba(13,215,180,1)&#34;,&#34;rgba(134,178,13,1)&#34;,&#34;rgba(139,135,132,1)&#34;,&#34;rgba(95,120,11,1)&#34;,&#34;rgba(118,109,42,1)&#34;,&#34;rgba(192,96,18,1)&#34;,&#34;rgba(24,96,169,1)&#34;,&#34;rgba(98,81,43,1)&#34;,&#34;rgba(177,162,6,1)&#34;,&#34;rgba(84,93,44,1)&#34;,&#34;rgba(55,202,122,1)&#34;,&#34;rgba(34,88,126,1)&#34;,&#34;rgba(58,150,16,1)&#34;,&#34;rgba(85,188,38,1)&#34;,&#34;rgba(102,36,44,1)&#34;,&#34;rgba(71,48,55,1)&#34;,&#34;rgba(195,70,34,1)&#34;,&#34;rgba(3,142,81,1)&#34;,&#34;rgba(30,164,58,1)&#34;,&#34;rgba(193,124,8,1)&#34;,&#34;rgba(75,132,7,1)&#34;,&#34;rgba(16,117,59,1)&#34;,&#34;rgba(117,143,7,1)&#34;,&#34;rgba(21,170,124,1)&#34;,&#34;rgba(38,95,55,1)&#34;,&#34;rgba(126,28,50,1)&#34;,&#34;rgba(17,152,70,1)&#34;,&#34;rgba(156,33,43,1)&#34;,&#34;rgba(137,134,9,1)&#34;,&#34;rgba(88,37,49,1)&#34;,&#34;rgba(94,151,6,1)&#34;,&#34;rgba(63,118,36,1)&#34;],&#34;size&#34;:[55.8780487804878,100,19.8780487804878,68.609756097561,46.8780487804878,56.0975609756098,24.2682926829268,18.5609756097561,57.1951219512195,52.1463414634146,31.5121951219512,50.390243902439,39.6341463414634,60.2682926829268,56.7560975609756,10.6585365853659,48.4146341463415,61.3658536585366,13.5121951219512,21.4146341463415,17.2439024390244,54.5609756097561,50.1707317073171,34.8048780487805,10,33.2682926829268,18.1219512195122,53.2439024390244,11.7560975609756,28.4390243902439,74.3170731707317,24.4878048780488,83.3170731707317,67.9512195121951,42.4878048780488,70.3658536585366,56.5365853658537,26.9024390243902,74.9756097560976,40.9512195121951,59.609756097561,19.4390243902439,29.0975609756098,32.390243902439,75.4146341463415,60.7073170731707,51.0487804878049,49.7317073170732,55.219512195122,52.5853658536585]},&#34;error_y&#34;:{&#34;width&#34;:[]},&#34;error_x&#34;:{&#34;width&#34;:[]},&#34;line&#34;:{&#34;color&#34;:[&#34;rgba(100,121,51,1)&#34;,&#34;rgba(115,36,41,1)&#34;,&#34;rgba(152,101,22,1)&#34;,&#34;rgba(131,33,40,1)&#34;,&#34;rgba(35,32,35,1)&#34;,&#34;rgba(19,130,51,1)&#34;,&#34;rgba(148,62,31,1)&#34;,&#34;rgba(23,174,171,1)&#34;,&#34;rgba(12,136,100,1)&#34;,&#34;rgba(73,149,53,1)&#34;,&#34;rgba(56,77,57,1)&#34;,&#34;rgba(87,63,59,1)&#34;,&#34;rgba(159,128,8,1)&#34;,&#34;rgba(4,117,121,1)&#34;,&#34;rgba(7,124,109,1)&#34;,&#34;rgba(16,141,176,1)&#34;,&#34;rgba(186,46,44,1)&#34;,&#34;rgba(6,102,124,1)&#34;,&#34;rgba(13,215,180,1)&#34;,&#34;rgba(134,178,13,1)&#34;,&#34;rgba(139,135,132,1)&#34;,&#34;rgba(95,120,11,1)&#34;,&#34;rgba(118,109,42,1)&#34;,&#34;rgba(192,96,18,1)&#34;,&#34;rgba(24,96,169,1)&#34;,&#34;rgba(98,81,43,1)&#34;,&#34;rgba(177,162,6,1)&#34;,&#34;rgba(84,93,44,1)&#34;,&#34;rgba(55,202,122,1)&#34;,&#34;rgba(34,88,126,1)&#34;,&#34;rgba(58,150,16,1)&#34;,&#34;rgba(85,188,38,1)&#34;,&#34;rgba(102,36,44,1)&#34;,&#34;rgba(71,48,55,1)&#34;,&#34;rgba(195,70,34,1)&#34;,&#34;rgba(3,142,81,1)&#34;,&#34;rgba(30,164,58,1)&#34;,&#34;rgba(193,124,8,1)&#34;,&#34;rgba(75,132,7,1)&#34;,&#34;rgba(16,117,59,1)&#34;,&#34;rgba(117,143,7,1)&#34;,&#34;rgba(21,170,124,1)&#34;,&#34;rgba(38,95,55,1)&#34;,&#34;rgba(126,28,50,1)&#34;,&#34;rgba(17,152,70,1)&#34;,&#34;rgba(156,33,43,1)&#34;,&#34;rgba(137,134,9,1)&#34;,&#34;rgba(88,37,49,1)&#34;,&#34;rgba(94,151,6,1)&#34;,&#34;rgba(63,118,36,1)&#34;]},&#34;frame&#34;:null}],&#34;highlight&#34;:{&#34;on&#34;:&#34;plotly_click&#34;,&#34;persistent&#34;:false,&#34;dynamic&#34;:false,&#34;selectize&#34;:false,&#34;opacityDim&#34;:0.2,&#34;selected&#34;:{&#34;opacity&#34;:1},&#34;debounce&#34;:0},&#34;shinyEvents&#34;:[&#34;plotly_hover&#34;,&#34;plotly_click&#34;,&#34;plotly_selected&#34;,&#34;plotly_relayout&#34;,&#34;plotly_brushed&#34;,&#34;plotly_brushing&#34;,&#34;plotly_clickannotation&#34;,&#34;plotly_doubleclick&#34;,&#34;plotly_deselect&#34;,&#34;plotly_afterplot&#34;,&#34;plotly_sunburstclick&#34;],&#34;base_url&#34;:&#34;https://plot.ly&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/currently/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      <guid>/currently/</guid>
      <description>&lt;h2 id=&#34;what-im-working-on-these-days&#34;&gt;What I&amp;rsquo;m working on these days&lt;/h2&gt;
&lt;br&gt;  
&lt;h3 id=&#34;pivoting-to-a-postdoc&#34;&gt;Pivoting to a postdoc!&lt;/h3&gt;
&lt;p&gt;I defended my PhD dissertation in April 2023, and am taking a slow summer to move, reset, and embark on my postdoctoral research. In September 2023 I am joining the Integrative Evolutionary Biology group led by Claudius Kratochwil at the University of Helsinki, Finland. Here I will study the evolution and development of color patterns in fishes, and focus especially on the interplay robustness (the persistence of a phenotype under perturbation) with evolutionary changes. So here&amp;rsquo;s an important Finnish sentence for you: tämä kala on jotenkin outo!&lt;/p&gt;
&lt;p&gt;Lab webpage &lt;a href=&#34;https://www.helsinki.fi/en/researchgroups/integrative-evolutionary-biology&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;the-evolution-of-mouthbrooding-in-fishes&#34;&gt;The evolution of mouthbrooding in fishes&lt;/h3&gt;
&lt;p&gt;Right now I&amp;rsquo;m studying the evolution of mouthbrooding (a kind of parental care where parents incubate offspring in their mouths), and how much feeding phenotypes influence that evolution. I think that mouthbrooding is a beautiful example of an extraordinary behavior (using a mouth as a nursery!) that arises from co-opting existing traits. Specifically, it seems like mouthbrooding is more likely to evolve in species whose feeding adaptations already make them good at mouthbrooding. And the further I dive into the whys and hows, the more I appreciate how much this behavior seems to be the result of the interplay of morphology, behavior, and environment. I have a somewhat out-there idea for why only some fishes in a given environment will evolve mouthbrooding, and it&amp;rsquo;s what I&amp;rsquo;m testing now.&lt;/p&gt;
&lt;p&gt;More &lt;a href=&#34;/category/mouthbrooding/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;color-analysis-software&#34;&gt;Color analysis software&lt;/h3&gt;
&lt;p&gt;I also work a lot on color pattern evolution, and have written a few R packages to make that easier for myself and others. I think that accessible, objective tools for color pattern research are an important part of making sure we&amp;rsquo;re being careful with the conclusions we draw about how much color matters to other living things. Current projects include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;recolorize&lt;/code&gt;, an R package for color segmentation, which integrates with the &lt;code&gt;pavo&lt;/code&gt; and &lt;code&gt;patternize&lt;/code&gt; packages as well as providing a variety of other output formats (vectorized images, individual layers, masks). More &lt;a href=&#34;/category/recolorize&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;colordistance&lt;/code&gt;, an R package for comparing images by quantitative color similarity:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;images/cdm_rec_tree.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;More &lt;a href=&#34;/category/colordistance&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;collaborations&#34;&gt;Collaborations&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;m lucky to have really delightful spread of collaborations with researchers at other universities, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UV in snakes (University of Michigan, Davis-Rabosky lab)&lt;/li&gt;
&lt;li&gt;The origin and diversity of color jewel beetles (Louisiana State University, Lord lab)&lt;/li&gt;
&lt;li&gt;Population structure and color variation in brook trout (Pennsylvania State University)&lt;/li&gt;
&lt;li&gt;The effect of mouthbrooding on the rate of craniofacial evolution (Clemson, Price lab)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Recolorize: Color-based image segmentation (for people with other things to do)</title>
      <link>/publication/sicb-2021/</link>
      <pubDate>Fri, 01 Jan 2021 20:57:23 -0400</pubDate>
      <guid>/publication/sicb-2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An XROMM Study of Food Transport and Swallowing in Channel Catfish</title>
      <link>/publication/catfish/</link>
      <pubDate>Mon, 01 Jun 2020 19:18:37 -0400</pubDate>
      <guid>/publication/catfish/</guid>
      <description></description>
    </item>
    
    <item>
      <title>colordistance</title>
      <link>/project/colordistance/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/project/colordistance/</guid>
      <description>&lt;p&gt;A package for implementing distance metrics to quantify color diversity across images. This is done by binning pixels by color using either data-dependent or automatically generated color bins, quantitatively measuring color similarity among images using one of several distance metrics for comparing pixel color clusters, and clustering images by object color similarity. Uses CIE Lab, RGB, or HSV color spaces. Originally written for use with organism coloration (reef fish color diversity, butterfly mimicry, etc), but easily applicable for any image set.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>recolorize</title>
      <link>/project/recolorize/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/project/recolorize/</guid>
      <description>&lt;p&gt;This is a package for making color maps, which are needed (or at least useful) for a wide range of color analysis techniques. It was born out of conversations with many biologists who found, to their surprise and mine, that generating color maps was the bottleneck step in their analyses. Fully automated methods rarely work all of the time, and are difficult to modify, while fully manual methods are subjective and time-consuming. This package tries to split the difference by giving you a mix of tools that will do a pretty good job with no user input, and then allow minor manual changes like merging and filtering layers or splitting components, before exporting them to the next step of your analysis. It&amp;rsquo;s also, for the most part, totally deterministic – no arbitrary seed-setting for repeatability.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Countcolors, an R package for quantification of the fluorescence emitted by Pseudogymnoascus destructans lesions on the wing membranes of hibernating bats</title>
      <link>/publication/countcolors/</link>
      <pubDate>Sat, 01 Feb 2020 19:36:14 -0400</pubDate>
      <guid>/publication/countcolors/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The spandrels of Satan&#39;s perches: evidence for the co-optation of feeding traits in the convergent evolution of mouthbrooding in Neotropical cichlids</title>
      <link>/publication/sicb-2020/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/publication/sicb-2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quantitative color profiling of digital images with earth mover’s distance using the R package colordistance</title>
      <link>/publication/colordistance/</link>
      <pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/publication/colordistance/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/cv/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate>
      <guid>/cv/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-download  pr-1 fa-fw&#34;&gt;&lt;/i&gt; &lt;a href=&#34;/media/cv.pdf&#34; target=&#34;_blank&#34;&gt;Click here to download.&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;hannah-weller&#34;&gt;Hannah Weller&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Research interests&lt;/strong&gt;: the role of biomechanical constraints in life  history evolution;
paths of least resistance in the evolution of new traits;  image processing in organismal
biology, with a focus on methods development for quantifying color and pattern.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;br&gt;  
&lt;h2 id=&#34;present-position&#34;&gt;Present Position&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;2023—2025&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Postdoctoral researcher, Integrative Evolutionary Biology Group&lt;/strong&gt;&lt;br&gt;
University of Helsinki (Helsinki, Finland)&lt;/dd&gt;
&lt;/dl&gt;
&lt;h2 id=&#34;education&#34;&gt;Education&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;2019—2023&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;PhD, Ecology and Evolutionary Biology&lt;/strong&gt;&lt;br&gt;
Brown University (Providence, RI) &lt;br&gt;
&lt;em&gt;Thesis: The opportunities of evolutionary constraint, with a focus on the evolution of mouthbrooding in cichlids&lt;/em&gt;&lt;/dd&gt;
&lt;dt&gt;2017—2019&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Transitional M.Sc., Ecology and Evolutionary Biology&lt;/strong&gt;&lt;br&gt;
Brown University (Providence, RI) &lt;br&gt;
&lt;em&gt;Thesis: How do feeding adaptations influence the convergent evolution of mouthbrooding?&lt;/em&gt;&lt;/dd&gt;
&lt;dt&gt;2012—2016&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Honors B.Sc., Biology&lt;/strong&gt;&lt;br&gt;
University of Chicago (Chicago, IL) &lt;br&gt;
&lt;em&gt;Thesis: Winnowing in the eartheater cichlids&lt;/em&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;br&gt;  
&lt;h2 id=&#34;awards-and-fellowships&#34;&gt;Awards and Fellowships&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;January 2022&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Doctoral Dissertation Enhancement Grant&lt;/strong&gt;&lt;br&gt;
$10,000, Bushnell Fund at Brown University&lt;/dd&gt;
&lt;dt&gt;May 2021&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Dean&amp;rsquo;s Excellence in Teaching Award&lt;/strong&gt;
Brown University, Alpert Medical School&lt;/dd&gt;
&lt;dt&gt;April 2019&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Graduate Research Fellowship&lt;/strong&gt;&lt;br&gt;
$138,000, National Science Foundation&lt;/dd&gt;
&lt;dt&gt;December 2018&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Field Museum Visiting Scientist Scholarship&lt;/strong&gt;&lt;br&gt;
$1,500, Field Museum of Natural History&lt;/dd&gt;
&lt;dt&gt;May 2017&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Presidential Fellowship&lt;/strong&gt;&lt;br&gt;
$108,000, Brown University&lt;/dd&gt;
&lt;dt&gt;June 2015&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Jeff Metcalf Undergraduate Research Fellowship&lt;/strong&gt;&lt;br&gt;
$5,000, Marine Biological Laboratory&lt;/dd&gt;
&lt;dt&gt;March 2015&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Elected to Phi Beta Kappa Society&lt;/strong&gt;&lt;/dd&gt;
&lt;dt&gt;September 2014&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Best Presentation, Undergraduate Research Symposium&lt;/strong&gt;&lt;br&gt;
$150, University of Chicago&lt;/dd&gt;
&lt;dt&gt;June 2014&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Elliott and Eileen Hinkes Research Fellowship&lt;/strong&gt;&lt;br&gt;
$4,000, University of Chicago&lt;/dd&gt;
&lt;/dl&gt;
&lt;br&gt;  
&lt;h2 id=&#34;peer-reviewed-publications&#34;&gt;Peer-reviewed publications&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, López-Fernández, H., McMahan, C.D., and Brainerd, E.L. (2022). Relaxed feeding constraints facilitate the evolution of mouthbrooding in Neotropical cichlids. &lt;em&gt;The American Naturalist&lt;/em&gt;. DOI: &lt;a href=&#34;https://doi.org/10.1086/719235&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1086/719235&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Capano, J.G., Boback, S.M., &lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Cieri, R.L., Zemer, C.F., and Brainerd, E.L.  (2022). Modular lung ventilation in &lt;em&gt;Boa constrictor&lt;/em&gt;. &lt;em&gt;Journal of Experimental Biology&lt;/em&gt;. DOI: &lt;a href=&#34;https://doi.org/10.1242/jeb.243119&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1242/jeb.243119&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Olsen, A., Camp, A.L., Hernandez, L.P., Manafzadeh, A.R., and Brainerd, E.L. (2020). An XROMM study of intra-oral transport and swallowing in catfish. &lt;em&gt;Integrative Organismal Biology&lt;/em&gt;. DOI: &lt;a href=&#34;https://doi.org/10.1093/iob/obaa018&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1093/iob/obaa018&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Cohen, K.E., &lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Westneat, M.W., and Summers, A.P (2020). The Evolutionary Continuum of Functional Homodonty to Heterodonty in the Dentition of &lt;em&gt;Halichoeres&lt;/em&gt; Wrasses. &lt;em&gt;Integrative and Comparative Biology&lt;/em&gt;. DOI: &lt;a href=&#34;https://doi.org/10.1093/icb/icaa137&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1093/icb/icaa137&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;*, Hooper, S.E.*, and Amelon, S.K* (2020). Countcolors, an R package for quantification of the fluorescence emitted by &lt;em&gt;Pseudogymnoascus destructans&lt;/em&gt; lesions on the wing membranes of hibernating bats. &lt;em&gt;Journal of Wildlife Diseases&lt;/em&gt;. DOI: &lt;a href=&#34;https://doi.org/10.7589/2019-09-231&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.7589/2019-09-231&lt;/a&gt;&lt;br&gt;
&lt;sup&gt;*These authors contributed equally to this work.&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Cohen, K.E., &lt;strong&gt;Weller, H.I.&lt;/strong&gt;, and Summers, A.P. (2020). Not your father’s homodonty—stress, tooth shape, and the functional homodont.* Journal of Anatomy*. DOI: &lt;a href=&#34;https://doi.org/10.1111/joa.13248&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1111/joa.13248&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;van Meer, N.M., &lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Manafzadeh, A.R., Kaczmarek, E.B., Scott, B., Gussekloo, S.W.S, Wilga, C.D., Brainerd, E.B., and Camp, A.L. (2019). Intra-oropharyngeal food transport and swallowing in white-spotted bamboo sharks. &lt;em&gt;Journal of Experimental Biology&lt;/em&gt;. DOI: &lt;a href=&#34;10.1242/jeb.201426&#34;&gt;10.1242/jeb.201426&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, and Westneat, M.W. (2019). Quantitative color profiling of digital images with earth mover’s distance using the R package colordistance. &lt;em&gt;PeerJ&lt;/em&gt;. DOI: &lt;a href=&#34;10.7717/peerj.6398&#34;&gt;10.7717/peerj.6398&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, McMahan, C.D., and Westneat, M.W. (2016). Dirt-sifting Devilfish: Winnowing in the geophagine cichlid &lt;em&gt;Satanoperca daemon&lt;/em&gt; and evolutionary implications. &lt;em&gt;Zoomorphology&lt;/em&gt;. DOI: &lt;a href=&#34;10.1007/s00435-016-0335-6&#34;&gt;10.1007/s00435-016-0335-6&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;  
&lt;h2 id=&#34;preprints-and-publications-in-review&#34;&gt;Preprints and publications in review&lt;/h2&gt;
&lt;p&gt;Paquette, S.E., Martin, N., Rodd, A., Manz, K.E., Camarillo, M., Allen, E., &lt;strong&gt;Weller, H.I&lt;/strong&gt;, Pennell, K., and Plavicki, J (2023). Neural dysregulation and aberrant microglial responses to brain injury following perfluorooctane sulfonate exposure in larval zebrafish. &lt;em&gt;Revised and resubmitted.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Hiller, A.E., Van Belleghem, S.M., and Lord, N.P. (2022). Recolorize: flexible color segmentation of biological images. &lt;em&gt;In revision&lt;/em&gt;. Preprint DOI: &lt;a href=&#34;https://doi.org/10.1101/2022.04.03.486906&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1101/2022.04.03.486906&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Tumulty, J.P., Miller, S.E., Van Belleghem, S.M., &lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Jernigan, C.M., Vincent, S., Staudenraus, R.J., Legan, A.W., Polnaszek, T.J., Uy, F.M.K, Walton, A., and Sheehan, M.J. (2021). Evidence for a selective link between cooperation and individual recognition. &lt;em&gt;In review&lt;/em&gt;. Preprint DOI: &lt;a href=&#34;https://doi.org/10.1101/2021.09.07.459327&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1101/2021.09.07.459327&lt;/a&gt;.&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;software&#34;&gt;Software&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt; (2021). recolorize: Simplify and Remap Image Colors for Biological Analysis (ver. 0.9.000). CRAN Repository. &lt;a href=&#34;https://CRAN.R-project.org/package=recolorize&#34;&gt;https://CRAN.R-project.org/package=recolorize&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;O&amp;rsquo;Sullivan, D., &lt;strong&gt;Weller, H.I.&lt;/strong&gt;, and Lord, N.P. Insect Color Database (ICDB). In development. &lt;a href=&#34;https://insectcolor.com/&#34;&gt;https://insectcolor.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt; (2019). colordistance: Distance Metrics for Image Color Similarity (ver. 1.1.0). CRAN repository. &lt;a href=&#34;https://CRAN.R-project.org/package=colordistance&#34;&gt;https://CRAN.R-project.org/package=colordistance&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt; (2018). countcolors: Locates and Counts Pixels Within Color Range(s) in Images (ver. 0.9.1). CRAN Repository. &lt;a href=&#34;https://CRAN.R-project.org/package=countcolors&#34;&gt;https://CRAN.R-project.org/package=countcolors&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;  
&lt;h2 id=&#34;presentations&#34;&gt;Presentations&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, and Van Belleghem, S. (January 2023). Poster: Flexible color segmentation of biological images with the R package recolorize. &lt;em&gt;Society for Integrative and Comparative Biology&lt;/em&gt;, Austin, TX, USA.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Weissman, M., and López-Fernández, H. (January 2023). Talk: Bet-hedging theory helps explain life history differences among mouthbrooding cichlids. &lt;em&gt;Society for Integrative and Comparative Biology&lt;/em&gt;, Austin, TX, USA.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt; and López-Fernández, H. (September 2022). Invited symposium talk: How (and how much) does feeding influence the evolution of mouthbrooding in Neotropical cichlids? &lt;em&gt;Encontra Brasileiro de Ictiologia&lt;/em&gt;, Gramado, Brazil.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Brainerd, E.L, and López-Fernández, H. (January 2022). Talk: Does feeding mediate life history tradeoffs in mouthbrooding cichlids? &lt;em&gt;Society for Integrative and Comparative Biology&lt;/em&gt;, virtual conference.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Wham, D., Ezray-Wham, B., and Lord, N.P. (August 2021). Talk: Greater than the sum of their parts? Unpacking the “black box” of perceptual similarity using classical color pattern metrics. &lt;em&gt;Living Light Early Career Researchers&lt;/em&gt;, virtual conference.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Schwartz, S.T., Karan, E., and Lord, N.P. (Jan. 2021). Talk: Recolorize: a flexible R package for color classification. &lt;em&gt;Society for Integrative and Comparative Biology&lt;/em&gt;, virtual conference.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;,  Karan, E., Schwartz, S. and Lord, N.P. (Jan. 2021). Talk: &lt;code&gt;recolorize&lt;/code&gt;: color-based image segmentation (for people with other things to do). &lt;em&gt;Society for Integrative and Comparative Biology (Virtual).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, López-Fernández, H., McMahan, C.D., and Brainerd, E.L. (Jan. 2020). Talk: The spandrels of Satan&amp;rsquo;s perches: evidence for the co-optation of feeding traits in the convergent evolution of mouthbrooding in Neotropical cichlids. &lt;em&gt;Society for Integrative and Comparative Biology, Austin, TX.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, López-Fernández, H., McMahan, C.D., and Brainerd, E.L. (Oct. 2019). Talk: Does mouthbrooding constrain or complement feeding morphology? &lt;em&gt;Regional Division of Vertebrate Morphology (Northeast), Newton, MA.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Olsen, A., Camp, A.L., Hernandez, L.P., Manafzadeh, A.R., and Brainerd, E.L. (Jan. 2019). Talk: 3D-Intra-oral Prey Trajectories Indicate Distinct Phases in how Channel Catfish (Ictalurus punctatus, Siluriformes: Ictaluridae) Swallow Food. &lt;em&gt;International Congress of Vertebrate Morphology, Prague, CZ.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Cohen, K.E., Gibb, A., and Brainerd, E.L. (Jan. 2019). Poster: Using tethers to measure food transport in a flatfish. &lt;em&gt;Society for Integrative and Comparative Biology, Tampa, FL.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, Olsen, A., Camp, A.L., Hernandez, L.P., Manafzadeh, A.R., and Brainerd, E.L.(Jan. 2019). Talk: An XROMM study of intra-oral transport and swallowing in catfish. &lt;em&gt;Society for Integrative and Comparative Biology, Tampa, FL.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt; and Brainerd, E.L. (Oct. 2017). Talk: How do fish swallow food? &lt;em&gt;Regional Division of Vertebrate Morphology (Northeast), Lowell, MA.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Weller, H.I.&lt;/strong&gt;, McMahan, C.D., and Westneat, M.W. (July 2016). Poster: Dirt-sifting devilfish: winnowing in eartheater cichlids. &lt;em&gt;American Society of Ichthyologists and Herpetologists, New Orleans, LA.&lt;/em&gt;&lt;/p&gt;
&lt;br&gt;  
&lt;h2 id=&#34;invited-talks-lectures--workshops&#34;&gt;Invited talks, lectures, &amp;amp; workshops&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;June 2022&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Workshop: Statistics for Biologists&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;University of Washington, Friday Harbor Laboratories&lt;/em&gt; (Friday Harbor, WA) &lt;br&gt;
R workshop focusing on practical statistical approaches to messy biological data. Instructors: Matthew Kolmann and Cassandra Donatelli.&lt;/dd&gt;
&lt;dt&gt;May 2022&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Podcast: Naturalist Selections&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;American Society of Naturalists&lt;/em&gt; &lt;br&gt;
Podcast interview about 2022 American Naturalist paper on the co-evolution of feeding and mouthbrooding in cichlids.&lt;/dd&gt;
&lt;dt&gt;July 2020&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Workshop: Phylogenetic Comparative Methods in R&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;University of Washington, Friday Harbor Laboratories&lt;/em&gt; (Friday Harbor, WA) &lt;br&gt;
R workshop focusing on phylogenetic and comparative methods. Instructors: Matthew Kolmann and Cassandra Donatelli.&lt;/dd&gt;
&lt;dt&gt;July 2020&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;A field guide to statistics in organismal biology&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;University of Washington, Friday Harbor Laboratories&lt;/em&gt; (Friday Harbor, WA)&lt;br&gt;
Guest lecture. Instructors: Matthew Kolmann and Cassandra Donatelli.&lt;/dd&gt;
&lt;dt&gt;July 2020&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Mouthbrooding morphologies in Neotropical cichlids&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;University of California Davis, Dept. of Ecology and Evolutionary Biology&lt;/em&gt; (Davis, CA)&lt;br&gt;
Virtual seminar. Host: Peter Wainwright.&lt;/dd&gt;
&lt;dt&gt;April 2020&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Special Topics: Light, Color, and Vision in Biology (BIOL 7901/ENTM 7008)&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;Louisiana State University, Dept. of Entomology and Dept. of Biology&lt;/em&gt; (Baton Rouge, LA)&lt;br&gt;
Guest lecturer (3 classes). Instructors: Nathan Lord (ENTM) &amp;amp; Brant Faircloth (BIOL).&lt;/dd&gt;
&lt;dt&gt;December 2019&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Workshop: R for Biologists&lt;/strong&gt;&lt;br&gt;
&lt;em&gt;Louisiana State University, Dept. of Entomology&lt;/em&gt; (Baton Rouge, LA)&lt;br&gt;
Organizer. Day-long workshop on data analysis and visualization in R.&lt;/dd&gt;
&lt;/dl&gt;
&lt;br&gt;  
&lt;h2 id=&#34;research-experience&#34;&gt;Research experience&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;2023—Present&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Postdoctoral researcher&lt;/strong&gt;; advisor: Claudius Kratochwil&lt;br&gt;
&lt;em&gt;University of Helsinki, HiLIFE Institute&lt;/em&gt;&lt;br&gt;
Evolution and development of color pattern robustness in colorful fishes.&lt;/dd&gt;
&lt;dt&gt;2017—2023&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;PhD candidate, Brainerd Lab&lt;/strong&gt;; advisor: Elizabeth Brainerd&lt;br&gt;
&lt;em&gt;Brown University, Dept. of Ecology &amp;amp; Evolutionary Biology&lt;/em&gt;&lt;br&gt;
Comparative morphology, kinematics, and biomechanics of mouthbrooding fishes; XROMM fish feeding and transport.&lt;/dd&gt;
&lt;dt&gt;September 2013—July 2017&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Research assistant&lt;/strong&gt;; advisor: Mark Westneat&lt;br&gt;
&lt;em&gt;University of Chicago, Dept. of Organismal Biology &amp;amp; Anatomy&lt;/em&gt;&lt;br&gt;
Quantitative color analysis; geometric morphometrics; high-speed video kinematics.&lt;/dd&gt;
&lt;dt&gt;June 2015—September 2015&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Jeff Metcalf Summer Research Fellow&lt;/strong&gt;; advisor: Roger Hanlon&lt;br&gt;
&lt;em&gt;Brown University, Dept. of Ecology &amp;amp; Evolutionary Biology&lt;/em&gt;&lt;br&gt;
Hyperspectral imaging; image analysis pipelines; camouflage analyses.&lt;/dd&gt;
&lt;dt&gt;June 2014—September 2014&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Summer Research Fellow, Westneat Lab&lt;/strong&gt;; advisor: Mark Westneat&lt;br&gt;
&lt;em&gt;University of Chicago, Dept. of Organismal Biology &amp;amp; Anatomy&lt;/em&gt;&lt;br&gt;
Ontogenetic scaling; biomechanical modeling; geometric morphometrics.&lt;/dd&gt;
&lt;/dl&gt;
&lt;br&gt;  
&lt;h2 id=&#34;teaching-and-outreach&#34;&gt;Teaching and outreach&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;June 2021 &amp;amp; July 2022&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Instructor&lt;/strong&gt;, &lt;em&gt;Brown University, Summer@Brown Program&lt;/em&gt; (Providence, RI)&lt;br&gt;
Anatomy, Behavior, and Evolution: Fishy Solutions to Life Underwater&lt;br&gt;
Intensive high school course including labs, assignments, and mentoring of final project (preparation of research proposals and presentations).&lt;/dd&gt;
&lt;dt&gt;August 2020—April 2020&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Teaching assistant&lt;/strong&gt;, &lt;em&gt;Brown University, Alpert Medical School&lt;/em&gt; (Providence, RI)&lt;br&gt;
COVID-modified Human Anatomy (lecture and lab)&lt;br&gt;
Restructuring the traditional gross anatomy curriculum, including remote/small group work and prosection-based staggered labs.&lt;/dd&gt;
&lt;dt&gt;September 2019—Present&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;R User Group&lt;/strong&gt;, &lt;em&gt;Brown University, Dept. of Ecology and Evolutionary Biology&lt;/em&gt; (Providence, RI)&lt;br&gt;
Organizing and running monthly R workshops for graduate and undergraduate students, focusing on techniques for biological analysis (e.g., data organization, statistics, and visualization).&lt;/dd&gt;
&lt;dt&gt;August 2019—April 2020&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Teaching assistant&lt;/strong&gt;, &lt;em&gt;Brown University, Alpert Medical School&lt;/em&gt; (Providence, RI)&lt;br&gt;
Human Anatomy (lecture and lab)&lt;br&gt;
Guiding medical students through cadaver-based human anatomy labs.&lt;/dd&gt;
&lt;dt&gt;September 2018—Present&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Marine Science Club&lt;/strong&gt;, &lt;em&gt;Paul Cuffee High School&lt;/em&gt; (Providence, RI)&lt;br&gt;
Collaborating with high school teachers for weekly science activities with high school students.&lt;/dd&gt;
&lt;dt&gt;September 2017—Dec. 2017&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Teaching assistant&lt;/strong&gt;, &lt;em&gt;Brown University, Dept. of Ecology &amp;amp; Evolutionary Biology&lt;/em&gt; (Providence, RI)&lt;br&gt;
Diversity of Life (lecture)&lt;/dd&gt;
&lt;dt&gt;January 2015—April 2017&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Teaching assistant&lt;/strong&gt;, &lt;em&gt;University of Chicago, Dept. of Biological Sciences&lt;/em&gt; (Chicago, IL)&lt;br&gt;
Presenting and supervising lab experiments; writing and grading assignments; lecturing; leading paper discussions and review sessions; guiding dissection-based anatomy labs.
&lt;p&gt;Genetic and Developmental Biology (lab &amp;amp; lecture)&lt;br&gt;
Multiscale Modeling of Biological Systems (lecture)&lt;br&gt;
Molecular Biology of the Cell (lab)&lt;br&gt;
Comparative Vertebrate Anatomy (lab &amp;amp; lecture)&lt;/p&gt;
&lt;/dd&gt;
&lt;dt&gt;June 2013—September 2013&lt;/dt&gt;
&lt;dd&gt;&lt;strong&gt;Animal care intern&lt;/strong&gt;, &lt;em&gt;New England Aquarium&lt;/em&gt; (Boston, MA)&lt;br&gt;
Daily animal care and maintenance; visitor outreach; collection trips.&lt;/dd&gt;
&lt;/dl&gt;
&lt;br&gt;  
&lt;h2 id=&#34;skills&#34;&gt;Skills&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Coding&lt;/dt&gt;
&lt;dd&gt;R, Python (OpenCV, Scrapy, &amp;amp; BioPython libraries), MATLAB, UNIX, MEL&lt;/dd&gt;
&lt;dt&gt;Software&lt;/dt&gt;
&lt;dd&gt;Latex, Maya, FIJI/ImageJ, Horos, 3DSlicer, XMALab, Mesquite, Pandoc, Microsoft Office&lt;/dd&gt;
&lt;dt&gt;Languages&lt;/dt&gt;
&lt;dd&gt;English (native), French (intermediate)&lt;/dd&gt;
&lt;/dl&gt;
&lt;hr&gt;
&lt;br&gt;  
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Lab&lt;/em&gt;: Biomedical Center 426, 171 Meeting St.,  Providence, RI 02906&lt;br&gt;
&lt;em&gt;Email&lt;/em&gt;: &lt;a href=&#34;mailto:hannahiweller@gmail.com&#34;&gt;hannahiweller@gmail.com&lt;/a&gt;&lt;br&gt;
&lt;em&gt;Website&lt;/em&gt;: &lt;a href=&#34;https://hiweller.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;hiweller.github.io&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Winnowing in the geophagine cichlid Satanoperca daemon</title>
      <link>/publication/winnowing/</link>
      <pubDate>Fri, 01 Sep 2017 19:05:49 -0400</pubDate>
      <guid>/publication/winnowing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Insect Color Database</title>
      <link>/project/icdb/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/project/icdb/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
